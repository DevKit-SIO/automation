{
  "id": 5111,
  "name": "Cr√©er un agent de chat adaptatif RAG avec Google Gemini et Qdrant",
  "views": 2127,
  "recentViews": 3,
  "totalViews": 2127,
  "createdAt": "2025-06-22T04:11:54.325Z",
  "description": "D√©bloquez un chat AI adaptatif et conscient du contexte dans vos automatisations‚Äîsans codage requis !\n\nCe mod√®le est un workflow n8n pr√™t √† l'emploi qui transforme la fa√ßon dont vos chatbots, agents de support et syst√®mes de connaissances r√©pondent aux utilisateurs. Aliment√© par Google Gemini et une base de donn√©es vectorielle Qdrant, il classe automatiquement chaque requ√™te entrante et applique une strat√©gie sur mesure pour les demandes factuelles, analytiques, d'opinion ou contextuelles‚Äîfournissant la bonne r√©ponse, √† chaque fois.\n\nüõ†Ô∏è Caract√©ristiques cl√©s\nClassification automatique des requ√™tes :\nD√©tecte sans effort si l'utilisateur veut des faits, une analyse approfondie, des opinions ou du contexte‚Äîpuis achemine chaque entr√©e vers la meilleure strat√©gie de r√©ponse.\n\nQuatre modes de r√©cup√©ration dynamiques :\n1) Factual : Fournit des informations pr√©cises et exactes\n2) Analytical : D√©compose des sujets complexes pour des analyses approfondies\n3) Opinion : Met en avant des points de vue et des perspectives divers\n4) Contextual : Relie les points en utilisant le contexte implicite ou sp√©cifique √† l'utilisateur\n\nPipeline RAG de bout en bout :\nUtilise Gemini pour classifier et r√©pondre, tandis que Qdrant alimente une r√©cup√©ration de connaissances rapide et intelligente.\n\n√âdition visuelle sans code :\nImportez dans n8n, connectez vos identifiants LLM et base de donn√©es vectorielle, et vous √™tes en direct‚Äîpersonnalisez, √©tendez et √©voluez sans code backend.\n\nR√©utilisable dans n'importe quel projet :\nParfait pour le support client, la recherche, les bots d'int√©gration, les bases de connaissances internes, ou toute interface de chat AI adaptative.\n\nüöÄ Comment √ßa fonctionne\n1) L'utilisateur soumet une requ√™te (via chat ou API)\n2) La requ√™te est auto-classifi√©e comme factuelle, analytique, d'opinion ou contextuelle\n3) La strat√©gie de r√©cup√©ration adaptative est d√©clench√©e\n(chacune avec sa propre logique de prompt et m√©moire tampon)\n4) Une recherche de connaissances intelligente est effectu√©e √† l'aide de Gemini et Qdrant\n5) La r√©ponse est g√©n√©r√©e et renvoy√©e √† l'utilisateur‚Äîadapt√©e au type de requ√™te !\n\nüß© Ce qui est inclus\n- Workflow n8n complet (.json)\n- Instructions de configuration √©tape par √©tape\n- Exemples de prompts et messages syst√®me pour chaque strat√©gie\n- Mises √† jour √† vie (au fur et √† mesure que le workflow √©volue)\n\nüí° Cas d'utilisation\n- Chatbots qui s'adaptent √† l'intention de chaque utilisateur\n- Automatisations FAQ et helpdesk internes/externes\n- Agents de recherche et de r√©sum√© AI\n- Flux de support produit et d'int√©gration\n\nTout sc√©nario o√π des r√©ponses plus intelligentes et plus pertinentes = meilleure exp√©rience utilisateur\n\nPr√™t √† construire des automatisations plus intelligentes ? Importez ce mod√®le, connectez vos comptes Gemini et Qdrant, et laissez votre agent AI s'adapter √† chaque conversation.",
  "workflow": {
    "id": "bU9BBKV0yadVVd30",
    "meta": {
      "instanceId": "315ec16104c52c82cc21fd9b6adb469e4bd7c2899d0990cb255788b78628ebf4"
    },
    "name": "Adaptive & Conditional AI Chat Agent - www.quantralabs.com",
    "tags": [],
    "nodes": [
      {
        "id": "6cccf7c5-9d8b-4f11-a7e1-c1bcf48bb9fe",
        "name": "Query Classification",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "notes": "Classify a query into one of four categories: Factual, Analytical, Opinion, or Contextual.\n        \nReturns:\nstr: Query category",
        "position": [
          -660,
          880
        ],
        "parameters": {
          "text": "=Classify this query: {{ $('Combined Fields').item.json.user_query }}",
          "options": {
            "systemMessage": "You are an expert at classifying questions. \n\nClassify the given query into exactly one of these categories:\n- Factual: Queries seeking specific, verifiable information.\n- Analytical: Queries requiring comprehensive analysis or explanation.\n- Opinion: Queries about subjective matters or seeking diverse viewpoints.\n- Contextual: Queries that depend on user-specific context.\n\nReturn ONLY the category name, without any explanation or additional text."
          },
          "promptType": "define"
        },
        "typeVersion": 1.8
      },
      {
        "id": "937104bc-5756-4adb-af0b-3e8741536e44",
        "name": "Switch",
        "type": "n8n-nodes-base.switch",
        "position": [
          -300,
          860
        ],
        "parameters": {
          "rules": {
            "values": [
              {
                "outputKey": "Factual",
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "87f3b50c-9f32-4260-ac76-19c05b28d0b4",
                      "operator": {
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.output.trim() }}",
                      "rightValue": "Factual"
                    }
                  ]
                },
                "renameOutput": true
              },
              {
                "outputKey": "Analytical",
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "f8651b36-79fa-4be4-91fb-0e6d7deea18f",
                      "operator": {
                        "name": "filter.operator.equals",
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.output.trim() }}",
                      "rightValue": "Analytical"
                    }
                  ]
                },
                "renameOutput": true
              },
              {
                "outputKey": "Opinion",
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "5dde06bc-5fe1-4dca-b6e2-6857c5e96d49",
                      "operator": {
                        "name": "filter.operator.equals",
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.output.trim() }}",
                      "rightValue": "Opinion"
                    }
                  ]
                },
                "renameOutput": true
              },
              {
                "outputKey": "Contextual",
                "conditions": {
                  "options": {
                    "version": 2,
                    "leftValue": "",
                    "caseSensitive": true,
                    "typeValidation": "strict"
                  },
                  "combinator": "and",
                  "conditions": [
                    {
                      "id": "bf97926d-7a0b-4e2f-aac0-a820f73344d8",
                      "operator": {
                        "name": "filter.operator.equals",
                        "type": "string",
                        "operation": "equals"
                      },
                      "leftValue": "={{ $json.output.trim() }}",
                      "rightValue": "Contextual"
                    }
                  ]
                },
                "renameOutput": true
              }
            ]
          },
          "options": {
            "fallbackOutput": 0
          }
        },
        "typeVersion": 3.2
      },
      {
        "id": "7346bf45-3f9b-4717-8cb5-52d829f0826c",
        "name": "Factual Strategy - Focus on Precision",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "notes": "Retrieval strategy for factual queries focusing on precision.",
        "position": [
          100,
          120
        ],
        "parameters": {
          "text": "=Enhance this factual query: {{ $('Combined Fields').item.json.user_query }}",
          "options": {
            "systemMessage": "=You are an expert at enhancing search queries.\n\nYour task is to reformulate the given factual query to make it more precise and specific for information retrieval. Focus on key entities and their relationships.\n\nProvide ONLY the enhanced query without any explanation."
          },
          "promptType": "define"
        },
        "typeVersion": 1.7
      },
      {
        "id": "ac1df57d-524c-4393-a81c-fb720f19b05e",
        "name": "Analytical Strategy - Comprehensive Coverage",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "notes": "Retrieval strategy for analytical queries focusing on comprehensive coverage.",
        "position": [
          100,
          660
        ],
        "parameters": {
          "text": "=Generate sub-questions for this analytical query: {{ $('Combined Fields').item.json.user_query }}",
          "options": {
            "systemMessage": "=You are an expert at breaking down complex questions.\n\nGenerate sub-questions that explore different aspects of the main analytical query.\nThese sub-questions should cover the breadth of the topic and help retrieve comprehensive information.\n\nReturn a list of exactly 3 sub-questions, one per line."
          },
          "promptType": "define"
        },
        "typeVersion": 1.7
      },
      {
        "id": "7df8350e-4f18-47fb-bd9a-c0238d218603",
        "name": "Opinion Strategy - Diverse Perspectives",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "notes": "Retrieval strategy for opinion queries focusing on diverse perspectives.",
        "position": [
          100,
          1200
        ],
        "parameters": {
          "text": "=Identify different perspectives on: {{ $('Combined Fields').item.json.user_query }}",
          "options": {
            "systemMessage": "=You are an expert at identifying different perspectives on a topic.\n\nFor the given query about opinions or viewpoints, identify different perspectives that people might have on this topic.\n\nReturn a list of exactly 3 different viewpoint angles, one per line."
          },
          "promptType": "define"
        },
        "typeVersion": 1.7
      },
      {
        "id": "0f9ef12d-7df4-4255-b5e2-27eb4e7ce982",
        "name": "Contextual Strategy - User Context Integration",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "notes": "Retrieval strategy for contextual queries integrating user context.",
        "position": [
          100,
          1740
        ],
        "parameters": {
          "text": "=Infer the implied context in this query: {{ $('Combined Fields').item.json.user_query }}",
          "options": {
            "systemMessage": "=You are an expert at understanding implied context in questions.\n\nFor the given query, infer what contextual information might be relevant or implied but not explicitly stated. Focus on what background would help answering this query.\n\nReturn a brief description of the implied context."
          },
          "promptType": "define"
        },
        "typeVersion": 1.7
      },
      {
        "id": "3c04f8e8-1304-436d-86eb-d905aa1cc261",
        "name": "Chat",
        "type": "@n8n/n8n-nodes-langchain.chatTrigger",
        "position": [
          -1320,
          1020
        ],
        "webhookId": "56f626b5-339e-48af-857f-1d4198fc8a4d",
        "parameters": {
          "options": {}
        },
        "typeVersion": 1.1
      },
      {
        "id": "e1daa9fc-62d2-4664-a9f3-dcdecf9071e6",
        "name": "Factual Prompt and Output",
        "type": "n8n-nodes-base.set",
        "position": [
          500,
          120
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced",
                "name": "output",
                "type": "string",
                "value": "={{ $json.output }}"
              },
              {
                "id": "7aa6ce13-afbf-4871-b81c-6e9c722a53dc",
                "name": "prompt",
                "type": "string",
                "value": "You are a helpful assistant providing factual information. Answer the question based on the provided context. Focus on accuracy and precision. If the context doesn't contain the information needed, acknowledge the limitations."
              }
            ]
          }
        },
        "typeVersion": 3.4
      },
      {
        "id": "1429dfd5-709d-4065-9134-05820fad871b",
        "name": "Contextual Prompt and Output",
        "type": "n8n-nodes-base.set",
        "position": [
          500,
          1740
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced",
                "name": "output",
                "type": "string",
                "value": "={{ $json.output }}"
              },
              {
                "id": "7aa6ce13-afbf-4871-b81c-6e9c722a53dc",
                "name": "prompt",
                "type": "string",
                "value": "You are a helpful assistant providing contextually relevant information. Answer the question considering both the query and its context. Make connections between the query context and the information in the provided documents. If the context doesn't fully address the specific situation, acknowledge the limitations."
              }
            ]
          }
        },
        "typeVersion": 3.4
      },
      {
        "id": "01c57856-4378-4085-bb67-2edf9b1164f9",
        "name": "Opinion Prompt and Output",
        "type": "n8n-nodes-base.set",
        "position": [
          500,
          1200
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced",
                "name": "output",
                "type": "string",
                "value": "={{ $json.output }}"
              },
              {
                "id": "7aa6ce13-afbf-4871-b81c-6e9c722a53dc",
                "name": "prompt",
                "type": "string",
                "value": "You are a helpful assistant discussing topics with multiple viewpoints. Based on the provided context, present different perspectives on the topic. Ensure fair representation of diverse opinions without showing bias. Acknowledge where the context presents limited viewpoints."
              }
            ]
          }
        },
        "typeVersion": 3.4
      },
      {
        "id": "3cb3f5e1-c85c-4481-a147-8b3c419526ee",
        "name": "Analytical Prompt and Output",
        "type": "n8n-nodes-base.set",
        "position": [
          500,
          660
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "a4a28ac2-4a56-46f6-8b86-f5d1a34b2ced",
                "name": "output",
                "type": "string",
                "value": "={{ $json.output }}"
              },
              {
                "id": "7aa6ce13-afbf-4871-b81c-6e9c722a53dc",
                "name": "prompt",
                "type": "string",
                "value": "You are a helpful assistant providing analytical insights. Based on the provided context, offer a comprehensive analysis of the topic. Cover different aspects and perspectives in your explanation. If the context has gaps, acknowledge them while providing the best analysis possible."
              }
            ]
          }
        },
        "typeVersion": 3.4
      },
      {
        "id": "34577e85-b067-49dd-90a6-048805de5118",
        "name": "Gemini Classification",
        "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
        "position": [
          -680,
          1080
        ],
        "parameters": {
          "options": {},
          "modelName": "models/gemini-2.0-flash-lite"
        },
        "typeVersion": 1
      },
      {
        "id": "7257c1dd-56bb-4f50-b206-2edd55fdd7cf",
        "name": "Gemini Factual",
        "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
        "position": [
          80,
          340
        ],
        "parameters": {
          "options": {},
          "modelName": "models/gemini-2.0-flash"
        },
        "typeVersion": 1
      },
      {
        "id": "47465499-74e8-4425-913a-2efd5c5e3441",
        "name": "Gemini Analytical",
        "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
        "position": [
          80,
          880
        ],
        "parameters": {
          "options": {},
          "modelName": "models/gemini-2.0-flash"
        },
        "typeVersion": 1
      },
      {
        "id": "a7273940-82c8-44a9-8890-b00c1a741015",
        "name": "Chat Buffer Memory Analytical",
        "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "position": [
          240,
          880
        ],
        "parameters": {
          "sessionKey": "={{ $('Combined Fields').item.json.chat_memory_key }}",
          "sessionIdType": "customKey",
          "contextWindowLength": 10
        },
        "typeVersion": 1.3
      },
      {
        "id": "6b573a7d-a6f0-4290-b3f1-3e36785bbee1",
        "name": "Chat Buffer Memory Factual",
        "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "position": [
          240,
          340
        ],
        "parameters": {
          "sessionKey": "={{ $('Combined Fields').item.json.chat_memory_key }}",
          "sessionIdType": "customKey",
          "contextWindowLength": 10
        },
        "typeVersion": 1.3
      },
      {
        "id": "9b20e2d9-9c67-45a0-9dfe-03bafb62f67f",
        "name": "Gemini Opinion",
        "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
        "position": [
          80,
          1420
        ],
        "parameters": {
          "options": {},
          "modelName": "models/gemini-2.0-flash"
        },
        "typeVersion": 1
      },
      {
        "id": "70489752-18b8-4676-a700-539c7b0fecb3",
        "name": "Chat Buffer Memory Opinion",
        "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "position": [
          240,
          1420
        ],
        "parameters": {
          "sessionKey": "={{ $('Combined Fields').item.json.chat_memory_key }}",
          "sessionIdType": "customKey",
          "contextWindowLength": 10
        },
        "typeVersion": 1.3
      },
      {
        "id": "e32a0ce3-2f72-43ca-b12a-03e3cf1b7818",
        "name": "Gemini Contextual",
        "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
        "position": [
          80,
          1960
        ],
        "parameters": {
          "options": {},
          "modelName": "models/gemini-2.0-flash"
        },
        "typeVersion": 1
      },
      {
        "id": "75c4f677-4c78-4a22-b0b4-44f3882c1a4e",
        "name": "Chat Buffer Memory Contextual",
        "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "position": [
          240,
          1960
        ],
        "parameters": {
          "sessionKey": "={{ $('Combined Fields').item.json.chat_memory_key }}",
          "sessionIdType": "customKey",
          "contextWindowLength": 10
        },
        "typeVersion": 1.3
      },
      {
        "id": "31d68f85-3cfc-4c93-81f7-c27070bf7307",
        "name": "Embeddings",
        "type": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
        "position": [
          1020,
          1100
        ],
        "parameters": {
          "modelName": "models/text-embedding-004"
        },
        "typeVersion": 1
      },
      {
        "id": "53910aea-7326-4d59-8585-693cb05afc3e",
        "name": "Sticky Note",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          0,
          0
        ],
        "parameters": {
          "color": 7,
          "width": 700,
          "height": 520,
          "content": "## Factual Strategy\n**Retrieve precise facts and figures.**"
        },
        "typeVersion": 1
      },
      {
        "id": "87015bf7-0bf1-490f-90b4-96346cc51b7c",
        "name": "Sticky Note1",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          0,
          540
        ],
        "parameters": {
          "color": 7,
          "width": 700,
          "height": 520,
          "content": "## Analytical Strategy\n**Provide comprehensive coverage of a topics and exploring different aspects.**"
        },
        "typeVersion": 1
      },
      {
        "id": "b14886e0-e513-405d-92d5-d4a417280546",
        "name": "Sticky Note2",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          0,
          1080
        ],
        "parameters": {
          "color": 7,
          "width": 700,
          "height": 520,
          "content": "## Opinion Strategy\n**Gather diverse viewpoints on a subjective issue.**"
        },
        "typeVersion": 1
      },
      {
        "id": "77cd1373-d547-462b-85cb-6799e7fbae84",
        "name": "Sticky Note3",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          0,
          1620
        ],
        "parameters": {
          "color": 7,
          "width": 700,
          "height": 520,
          "content": "## Contextual Strategy\n**Incorporate user-specific context to fine-tune the retrieval.**"
        },
        "typeVersion": 1
      },
      {
        "id": "edfe1620-b040-466c-a8b2-a6f2aae565c5",
        "name": "Concatenate Context",
        "type": "n8n-nodes-base.summarize",
        "position": [
          1400,
          880
        ],
        "parameters": {
          "options": {},
          "fieldsToSummarize": {
            "values": [
              {
                "field": "document.pageContent",
                "separateBy": "other",
                "aggregation": "concatenate",
                "customSeparator": "={{ \"\\n\\n---\\n\\n\" }}"
              }
            ]
          }
        },
        "typeVersion": 1.1
      },
      {
        "id": "059f5b2e-52db-49f6-bee8-9dfcd5fd1ea4",
        "name": "Retrieve Documents from Vector Store",
        "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
        "position": [
          1040,
          880
        ],
        "parameters": {
          "mode": "load",
          "topK": 10,
          "prompt": "={{ $json.prompt }}\n\nUser query: \n{{ $json.output }}",
          "options": {},
          "qdrantCollection": {
            "__rl": true,
            "mode": "id",
            "value": "={{ $('Combined Fields').item.json.vector_store_id }}"
          }
        },
        "typeVersion": 1.1
      },
      {
        "id": "d1a2de81-c92b-459a-a2b6-bb6d171ba712",
        "name": "Set Prompt and Output",
        "type": "n8n-nodes-base.set",
        "position": [
          840,
          880
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "1d782243-0571-4845-b8fe-4c6c4b55379e",
                "name": "output",
                "type": "string",
                "value": "={{ $json.output }}"
              },
              {
                "id": "547091fb-367c-44d4-ac39-24d073da70e0",
                "name": "prompt",
                "type": "string",
                "value": "={{ $json.prompt }}"
              }
            ]
          }
        },
        "typeVersion": 3.4
      },
      {
        "id": "aa7dede0-8241-4428-84db-7a403935a052",
        "name": "Gemini Answer",
        "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
        "position": [
          1680,
          1100
        ],
        "parameters": {
          "options": {},
          "modelName": "models/gemini-2.0-flash"
        },
        "typeVersion": 1
      },
      {
        "id": "5a33f53d-2297-46a1-9508-54c1e4f168be",
        "name": "Answer",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "position": [
          1720,
          880
        ],
        "parameters": {
          "text": "=User query: {{ $('Combined Fields').item.json.user_query }}",
          "options": {
            "systemMessage": "={{ $('Set Prompt and Output').item.json.prompt }}\n\nUse the following context (delimited by <ctx></ctx>) and the chat history to answer the user query.\n<ctx>\n{{ $json.concatenated_document_pageContent }}\n</ctx>"
          },
          "promptType": "define"
        },
        "typeVersion": 1.8
      },
      {
        "id": "888d1b5e-151f-4fb7-a201-fa8706af6ae8",
        "name": "Chat Buffer Memory",
        "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "position": [
          1860,
          1100
        ],
        "parameters": {
          "sessionKey": "={{ $('Combined Fields').item.json.chat_memory_key }}",
          "sessionIdType": "customKey",
          "contextWindowLength": 10
        },
        "typeVersion": 1.3
      },
      {
        "id": "573efafe-0dca-46d9-98a9-2684277d411d",
        "name": "Sticky Note4",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          760,
          680
        ],
        "parameters": {
          "color": 7,
          "width": 820,
          "height": 580,
          "content": "## Perform adaptive retrieval\n**Find document considering both query and context.**"
        },
        "typeVersion": 1
      },
      {
        "id": "f4219ef7-16ce-4cc6-8b03-a9480b2daf55",
        "name": "Sticky Note5",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          1600,
          680
        ],
        "parameters": {
          "color": 7,
          "width": 740,
          "height": 580,
          "content": "## Reply to the user integrating retrieval context"
        },
        "typeVersion": 1
      },
      {
        "id": "4fe79c8d-9670-4b2a-a7c7-5a2239906a14",
        "name": "Respond to Webhook",
        "type": "n8n-nodes-base.respondToWebhook",
        "position": [
          2080,
          880
        ],
        "parameters": {
          "options": {}
        },
        "typeVersion": 1.1
      },
      {
        "id": "ff99bc5a-bbbe-457d-b979-2ca1e04bd980",
        "name": "Sticky Note6",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -760,
          680
        ],
        "parameters": {
          "color": 7,
          "width": 700,
          "height": 580,
          "content": "## User query classification\n**Classify the query into one of four categories: Factual, Analytical, Opinion, or Contextual.**"
        },
        "typeVersion": 1
      },
      {
        "id": "c632a735-5a96-4a70-bf4c-6126e2e193f1",
        "name": "When Executed by Another Workflow",
        "type": "n8n-nodes-base.executeWorkflowTrigger",
        "position": [
          -1320,
          760
        ],
        "parameters": {
          "workflowInputs": {
            "values": [
              {
                "name": "user_query"
              },
              {
                "name": "chat_memory_key"
              },
              {
                "name": "vector_store_id"
              }
            ]
          }
        },
        "typeVersion": 1.1
      },
      {
        "id": "332b925d-0581-4b92-a7ce-83cbc8f66254",
        "name": "Combined Fields",
        "type": "n8n-nodes-base.set",
        "position": [
          -1000,
          880
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "90ab73a2-fe01-451a-b9df-bffe950b1599",
                "name": "user_query",
                "type": "string",
                "value": "={{ $json.user_query || $json.chatInput }}"
              },
              {
                "id": "36686ff5-09fc-40a4-8335-a5dd1576e941",
                "name": "chat_memory_key",
                "type": "string",
                "value": "={{ $json.chat_memory_key || $('Chat').item.json.sessionId }}"
              },
              {
                "id": "4230c8f3-644c-4985-b710-a4099ccee77c",
                "name": "vector_store_id",
                "type": "string",
                "value": "={{ $json.vector_store_id || \"<ID HERE>\" }}"
              }
            ]
          }
        },
        "typeVersion": 3.4
      },
      {
        "id": "eab0d609-5d9b-4794-adb5-fd8a784f34b0",
        "name": "Sticky Note7",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -1340,
          1300
        ],
        "parameters": {
          "width": 1280,
          "height": 1300,
          "content": "# Adaptive RAG Workflow\n\nThis n8n workflow implements a version of the Adaptive Retrieval-Augmented Generation (RAG) approach. It classifies user queries and applies different retrieval and generation strategies based on the query type (Factual, Analytical, Opinion, or Contextual) to provide more relevant and tailored answers from a knowledge base stored in a Qdrant vector store.\n\n## How it Works\n\n1.  **Input Trigger:**\n    * The workflow can be initiated via the built-in Chat interface or triggered by another n8n workflow.\n    * It expects inputs: `user_query`, `chat_memory_key` (for conversation history), and `vector_store_id` (specifying the Qdrant collection).\n    * A `Set` node (`Combined Fields`) standardizes these inputs.\n\n2.  **Query Classification:**\n    * A Google Gemini agent (`Query Classification`) analyzes the `user_query`.\n    * It classifies the query into one of four categories:\n        * **Factual:** Seeking specific, verifiable information.\n        * **Analytical:** Requiring comprehensive analysis or explanation.\n        * **Opinion:** Asking about subjective matters or seeking diverse viewpoints.\n        * **Contextual:** Depending on user-specific or implied context.\n\n3.  **Adaptive Strategy Routing:**\n    * A `Switch` node routes the workflow based on the classification result from the previous step.\n\n4.  **Strategy Implementation (Query Adaptation):**\n    * Depending on the route, a specific Google Gemini agent adapts the query or approach:\n        * **Factual Strategy:** Rewrites the query for better precision, focusing on key entities (`Factual Strategy - Focus on Precision`).\n        * **Analytical Strategy:** Breaks down the main query into multiple sub-questions to ensure comprehensive coverage (`Analytical Strategy - Comprehensive Coverage`).\n        * **Opinion Strategy:** Identifies different potential perspectives or angles related to the query (`Opinion Strategy - Diverse Perspectives`).\n        * **Contextual Strategy:** Infers implied context needed to answer the query effectively (`Contextual Strategy - User Context Integration`).\n    * Each strategy path uses its own chat memory buffer for the adaptation step.\n\n5.  **Retrieval Prompt & Output Setup:**\n    * Based on the *original* query classification, a `Set` node (`Factual/Analytical/Opinion/Contextual Prompt and Output`, combined via connections to `Set Prompt and Output`) prepares:\n        * The output from the strategy step (e.g., rewritten query, sub-questions, perspectives).\n        * A tailored system prompt for the final answer generation agent, instructing it how to behave based on the query type (e.g., focus on precision for Factual, present diverse views for Opinion).\n\n6.  **Document Retrieval (RAG):**\n    * The `Retrieve Documents from Vector Store` node uses the adapted query/output from the strategy step to search the specified Qdrant collection (`vector_store_id`).\n    * It retrieves the top relevant document chunks using Google Gemini embeddings.\n\n7.  **Context Preparation:**\n    * The content from the retrieved document chunks is concatenated (`Concatenate Context`) to form a single context block for the final answer generation.\n\n8.  **Answer Generation:**\n    * The final `Answer` agent (powered by Google Gemini) generates the response.\n    * It uses:\n        * The tailored system prompt set in step 5.\n        * The concatenated context from retrieved documents (step 7).\n        * The original `user_query`.\n        * The shared chat history (`Chat Buffer Memory` using `chat_memory_key`).\n\n9.  **Response:**\n    * The generated answer is sent back to the user via the `Respond to Webhook` node."
        },
        "typeVersion": 1
      },
      {
        "id": "1580b44f-bd48-43f8-b9ef-dbfd58042e68",
        "name": "Sticky Note8",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -1100,
          680
        ],
        "parameters": {
          "color": 7,
          "width": 320,
          "height": 580,
          "content": "## ‚ö†Ô∏è  If using in Chat mode\n\nUpdate the `vector_store_id` variable to the corresponding Qdrant ID needed to perform the documents retrieval."
        },
        "typeVersion": 1
      },
      {
        "id": "df475a3d-cec6-4a29-8d33-cfe8a1ae3d6c",
        "name": "Sticky Note9",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -1720,
          1300
        ],
        "parameters": {
          "color": 5,
          "width": 360,
          "height": 200,
          "content": "## Quantra Labs \nFollow Us\nhttps://www.x.com/quantralabs\n\nConnect with Us\nhttps://www.linkedin.com/company/quantra-labs\n\nwww.quantralabs.com"
        },
        "typeVersion": 1
      }
    ],
    "active": false,
    "pinData": {},
    "settings": {
      "executionOrder": "v1"
    },
    "versionId": "c562673d-bddb-4abd-adef-59c2fb61e716",
    "connections": {
      "Chat": {
        "main": [
          [
            {
              "node": "Combined Fields",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Answer": {
        "main": [
          [
            {
              "node": "Respond to Webhook",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Switch": {
        "main": [
          [
            {
              "node": "Factual Strategy - Focus on Precision",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Analytical Strategy - Comprehensive Coverage",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Opinion Strategy - Diverse Perspectives",
              "type": "main",
              "index": 0
            }
          ],
          [
            {
              "node": "Contextual Strategy - User Context Integration",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Embeddings": {
        "ai_embedding": [
          [
            {
              "node": "Retrieve Documents from Vector Store",
              "type": "ai_embedding",
              "index": 0
            }
          ]
        ]
      },
      "Gemini Answer": {
        "ai_languageModel": [
          [
            {
              "node": "Answer",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Gemini Factual": {
        "ai_languageModel": [
          [
            {
              "node": "Factual Strategy - Focus on Precision",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Gemini Opinion": {
        "ai_languageModel": [
          [
            {
              "node": "Opinion Strategy - Diverse Perspectives",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Combined Fields": {
        "main": [
          [
            {
              "node": "Query Classification",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Gemini Analytical": {
        "ai_languageModel": [
          [
            {
              "node": "Analytical Strategy - Comprehensive Coverage",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Gemini Contextual": {
        "ai_languageModel": [
          [
            {
              "node": "Contextual Strategy - User Context Integration",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Chat Buffer Memory": {
        "ai_memory": [
          [
            {
              "node": "Answer",
              "type": "ai_memory",
              "index": 0
            }
          ]
        ]
      },
      "Concatenate Context": {
        "main": [
          [
            {
              "node": "Answer",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Query Classification": {
        "main": [
          [
            {
              "node": "Switch",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Gemini Classification": {
        "ai_languageModel": [
          [
            {
              "node": "Query Classification",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Set Prompt and Output": {
        "main": [
          [
            {
              "node": "Retrieve Documents from Vector Store",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Factual Prompt and Output": {
        "main": [
          [
            {
              "node": "Set Prompt and Output",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Opinion Prompt and Output": {
        "main": [
          [
            {
              "node": "Set Prompt and Output",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Chat Buffer Memory Factual": {
        "ai_memory": [
          [
            {
              "node": "Factual Strategy - Focus on Precision",
              "type": "ai_memory",
              "index": 0
            }
          ]
        ]
      },
      "Chat Buffer Memory Opinion": {
        "ai_memory": [
          [
            {
              "node": "Opinion Strategy - Diverse Perspectives",
              "type": "ai_memory",
              "index": 0
            }
          ]
        ]
      },
      "Analytical Prompt and Output": {
        "main": [
          [
            {
              "node": "Set Prompt and Output",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Contextual Prompt and Output": {
        "main": [
          [
            {
              "node": "Set Prompt and Output",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Chat Buffer Memory Analytical": {
        "ai_memory": [
          [
            {
              "node": "Analytical Strategy - Comprehensive Coverage",
              "type": "ai_memory",
              "index": 0
            }
          ]
        ]
      },
      "Chat Buffer Memory Contextual": {
        "ai_memory": [
          [
            {
              "node": "Contextual Strategy - User Context Integration",
              "type": "ai_memory",
              "index": 0
            }
          ]
        ]
      },
      "When Executed by Another Workflow": {
        "main": [
          [
            {
              "node": "Combined Fields",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Retrieve Documents from Vector Store": {
        "main": [
          [
            {
              "node": "Concatenate Context",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Factual Strategy - Focus on Precision": {
        "main": [
          [
            {
              "node": "Factual Prompt and Output",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Opinion Strategy - Diverse Perspectives": {
        "main": [
          [
            {
              "node": "Opinion Prompt and Output",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Analytical Strategy - Comprehensive Coverage": {
        "main": [
          [
            {
              "node": "Analytical Prompt and Output",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Contextual Strategy - User Context Integration": {
        "main": [
          [
            {
              "node": "Contextual Prompt and Output",
              "type": "main",
              "index": 0
            }
          ]
        ]
      }
    }
  },
  "lastUpdatedBy": 29,
  "workflowInfo": {
    "nodeCount": 40,
    "nodeTypes": {
      "n8n-nodes-base.set": {
        "count": 6
      },
      "n8n-nodes-base.switch": {
        "count": 1
      },
      "n8n-nodes-base.summarize": {
        "count": 1
      },
      "n8n-nodes-base.stickyNote": {
        "count": 10
      },
      "@n8n/n8n-nodes-langchain.agent": {
        "count": 6
      },
      "n8n-nodes-base.respondToWebhook": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.chatTrigger": {
        "count": 1
      },
      "n8n-nodes-base.executeWorkflowTrigger": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.vectorStoreQdrant": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.lmChatGoogleGemini": {
        "count": 6
      },
      "@n8n/n8n-nodes-langchain.memoryBufferWindow": {
        "count": 5
      },
      "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini": {
        "count": 1
      }
    }
  },
  "user": {
    "name": "Brandon Crenshaw",
    "username": "brandononchain",
    "bio": "Founder & Systems Architect | Quantra Labs Engineering scalable solutions across AI, Blockchain, and Fintech.",
    "verified": false,
    "links": [
      "https://x.com/brandononchain"
    ],
    "avatar": "https://gravatar.com/avatar/1d13369ea9032efb196bb587337880897d627d93308033a6263ecbd336c2af31?r=pg&d=retro&size=200"
  },
  "nodes": [
    {
      "id": 38,
      "icon": "fa:pen",
      "name": "n8n-nodes-base.set",
      "codex": {
        "data": {
          "alias": [
            "Set",
            "JS",
            "JSON",
            "Filter",
            "Transform",
            "Map"
          ],
          "resources": {
            "generic": [
              {
                "url": "https://n8n.io/blog/learn-to-automate-your-factorys-incident-reporting-a-step-by-step-guide/",
                "icon": "üè≠",
                "label": "Learn to Automate Your Factory's Incident Reporting: A Step by Step Guide"
              },
              {
                "url": "https://n8n.io/blog/2021-the-year-to-automate-the-new-you-with-n8n/",
                "icon": "‚òÄÔ∏è",
                "label": "2021: The Year to Automate the New You with n8n"
              },
              {
                "url": "https://n8n.io/blog/automatically-pulling-and-visualizing-data-with-n8n/",
                "icon": "üìà",
                "label": "Automatically pulling and visualizing data with n8n"
              },
              {
                "url": "https://n8n.io/blog/database-monitoring-and-alerting-with-n8n/",
                "icon": "üì°",
                "label": "Database Monitoring and Alerting with n8n"
              },
              {
                "url": "https://n8n.io/blog/automatically-adding-expense-receipts-to-google-sheets-with-telegram-mindee-twilio-and-n8n/",
                "icon": "üßæ",
                "label": "Automatically Adding Expense Receipts to Google Sheets with Telegram, Mindee, Twilio, and n8n"
              },
              {
                "url": "https://n8n.io/blog/no-code-ecommerce-workflow-automations/",
                "icon": "store",
                "label": "6 e-commerce workflows to power up your Shopify s"
              },
              {
                "url": "https://n8n.io/blog/how-to-build-a-low-code-self-hosted-url-shortener/",
                "icon": "üîó",
                "label": "How to build a low-code, self-hosted URL shortener in 3 steps"
              },
              {
                "url": "https://n8n.io/blog/automate-your-data-processing-pipeline-in-9-steps-with-n8n/",
                "icon": "‚öôÔ∏è",
                "label": "Automate your data processing pipeline in 9 steps"
              },
              {
                "url": "https://n8n.io/blog/how-to-get-started-with-crm-automation-and-no-code-workflow-ideas/",
                "icon": "üë•",
                "label": "How to get started with CRM automation (with 3 no-code workflow ideas"
              },
              {
                "url": "https://n8n.io/blog/5-tasks-you-can-automate-with-notion-api/",
                "icon": "‚ö°Ô∏è",
                "label": "5 tasks you can automate with the new Notion API "
              },
              {
                "url": "https://n8n.io/blog/automate-google-apps-for-productivity/",
                "icon": "üí°",
                "label": "15 Google apps you can combine and automate to increase productivity"
              },
              {
                "url": "https://n8n.io/blog/how-uproc-scraped-a-multi-page-website-with-a-low-code-workflow/",
                "icon": " üï∏Ô∏è",
                "label": "How uProc scraped a multi-page website with a low-code workflow"
              },
              {
                "url": "https://n8n.io/blog/building-an-expense-tracking-app-in-10-minutes/",
                "icon": "üì±",
                "label": "Building an expense tracking app in 10 minutes"
              },
              {
                "url": "https://n8n.io/blog/the-ultimate-guide-to-automate-your-video-collaboration-with-whereby-mattermost-and-n8n/",
                "icon": "üìπ",
                "label": "The ultimate guide to automate your video collaboration with Whereby, Mattermost, and n8n"
              },
              {
                "url": "https://n8n.io/blog/5-workflow-automations-for-mattermost-that-we-love-at-n8n/",
                "icon": "ü§ñ",
                "label": "5 workflow automations for Mattermost that we love at n8n"
              },
              {
                "url": "https://n8n.io/blog/learn-to-build-powerful-api-endpoints-using-webhooks/",
                "icon": "üß∞",
                "label": "Learn to Build Powerful API Endpoints Using Webhooks"
              },
              {
                "url": "https://n8n.io/blog/how-a-membership-development-manager-automates-his-work-and-investments/",
                "icon": "üìà",
                "label": "How a Membership Development Manager automates his work and investments"
              },
              {
                "url": "https://n8n.io/blog/a-low-code-bitcoin-ticker-built-with-questdb-and-n8n-io/",
                "icon": "üìà",
                "label": "A low-code bitcoin ticker built with QuestDB and n8n.io"
              },
              {
                "url": "https://n8n.io/blog/how-to-set-up-a-ci-cd-pipeline-with-no-code/",
                "icon": "üé°",
                "label": "How to set up a no-code CI/CD pipeline with GitHub and TravisCI"
              },
              {
                "url": "https://n8n.io/blog/benefits-of-automation-and-n8n-an-interview-with-hubspots-hugh-durkin/",
                "icon": "üéñ",
                "label": "Benefits of automation and n8n: An interview with HubSpot's Hugh Durkin"
              },
              {
                "url": "https://n8n.io/blog/how-goomer-automated-their-operations-with-over-200-n8n-workflows/",
                "icon": "üõµ",
                "label": "How Goomer automated their operations with over 200 n8n workflows"
              },
              {
                "url": "https://n8n.io/blog/aws-workflow-automation/",
                "label": "7 no-code workflow automations for Amazon Web Services"
              }
            ],
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.set/"
              }
            ]
          },
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Data Transformation"
            ]
          }
        }
      },
      "group": "[\"input\"]",
      "defaults": {
        "name": "Modifier les champs"
      },
      "iconData": {
        "icon": "pen",
        "type": "icon"
      },
      "displayName": "Edit Fields (Set)",
      "typeVersion": 3,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 112,
      "icon": "fa:map-signs",
      "name": "n8n-nodes-base.switch",
      "codex": {
        "data": {
          "alias": [
            "Router",
            "If",
            "Path",
            "Filter",
            "Condition",
            "Logic",
            "Branch",
            "Case"
          ],
          "resources": {
            "generic": [
              {
                "url": "https://n8n.io/blog/2021-the-year-to-automate-the-new-you-with-n8n/",
                "icon": "‚òÄÔ∏è",
                "label": "2021: The Year to Automate the New You with n8n"
              },
              {
                "url": "https://n8n.io/blog/how-to-get-started-with-crm-automation-and-no-code-workflow-ideas/",
                "icon": "üë•",
                "label": "How to get started with CRM automation (with 3 no-code workflow ideas"
              },
              {
                "url": "https://n8n.io/blog/build-your-own-virtual-assistant-with-n8n-a-step-by-step-guide/",
                "icon": "üë¶",
                "label": "Build your own virtual assistant with n8n: A step by step guide"
              },
              {
                "url": "https://n8n.io/blog/automation-for-maintainers-of-open-source-projects/",
                "icon": "üè∑Ô∏è",
                "label": "How to automatically manage contributions to open-source projects"
              }
            ],
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.switch/"
              }
            ]
          },
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Flow"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Interrupteur",
        "color": "#506000"
      },
      "iconData": {
        "icon": "map-signs",
        "type": "icon"
      },
      "displayName": "Switch",
      "typeVersion": 3,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 535,
      "icon": "file:webhook.svg",
      "name": "n8n-nodes-base.respondToWebhook",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.respondtowebhook/"
              }
            ]
          },
          "categories": [
            "Core Nodes",
            "Utility"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "R√©pondre au Webhook"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0OCIgaGVpZ2h0PSI0OCI+PHBhdGggZmlsbD0iIzM3NDc0ZiIgZD0iTTM1IDM3Yy0yLjIgMC00LTEuOC00LTRzMS44LTQgNC00IDQgMS44IDQgNC0xLjggNC00IDQiLz48cGF0aCBmaWxsPSIjMzc0NzRmIiBkPSJNMzUgNDNjLTMgMC01LjktMS40LTcuOC0zLjdsMy4xLTIuNWMxLjEgMS40IDIuOSAyLjMgNC43IDIuMyAzLjMgMCA2LTIuNyA2LTZzLTIuNy02LTYtNmMtMSAwLTIgLjMtMi45LjdsLTEuNyAxTDIzLjMgMTZsMy41LTEuOSA1LjMgOS40YzEtLjMgMi0uNSAzLS41IDUuNSAwIDEwIDQuNSAxMCAxMFM0MC41IDQzIDM1IDQzIi8+PHBhdGggZmlsbD0iIzM3NDc0ZiIgZD0iTTE0IDQzQzguNSA0MyA0IDM4LjUgNCAzM2MwLTQuNiAzLjEtOC41IDcuNS05LjdsMSAzLjlDOS45IDI3LjkgOCAzMC4zIDggMzNjMCAzLjMgMi43IDYgNiA2czYtMi43IDYtNnYtMmgxNXY0SDIzLjhjLS45IDQuNi01IDgtOS44IDgiLz48cGF0aCBmaWxsPSIjZTkxZTYzIiBkPSJNMTQgMzdjLTIuMiAwLTQtMS44LTQtNHMxLjgtNCA0LTQgNCAxLjggNCA0LTEuOCA0LTQgNCIvPjxwYXRoIGZpbGw9IiMzNzQ3NGYiIGQ9Ik0yNSAxOWMtMi4yIDAtNC0xLjgtNC00czEuOC00IDQtNCA0IDEuOCA0IDQtMS44IDQtNCA0Ii8+PHBhdGggZmlsbD0iI2U5MWU2MyIgZD0ibTE1LjcgMzQtMy40LTIgNS45LTkuN2MtMi0xLjktMy4yLTQuNS0zLjItNy4zIDAtNS41IDQuNS0xMCAxMC0xMHMxMCA0LjUgMTAgMTBjMCAuOS0uMSAxLjctLjMgMi41bC0zLjktMWMuMS0uNS4yLTEgLjItMS41IDAtMy4zLTIuNy02LTYtNnMtNiAyLjctNiA2YzAgMi4xIDEuMSA0IDIuOSA1LjFsMS43IDF6Ii8+PC9zdmc+"
      },
      "displayName": "Respond to Webhook",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 7,
          "name": "Utility"
        },
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 565,
      "icon": "fa:sticky-note",
      "name": "n8n-nodes-base.stickyNote",
      "codex": {
        "data": {
          "alias": [
            "Comments",
            "Notes",
            "Sticky"
          ],
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"input\"]",
      "defaults": {
        "name": "Note autocollante",
        "color": "#FFD233"
      },
      "iconData": {
        "icon": "sticky-note",
        "type": "icon"
      },
      "displayName": "Sticky Note",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 837,
      "icon": "fa:sign-out-alt",
      "name": "n8n-nodes-base.executeWorkflowTrigger",
      "codex": {
        "data": {
          "resources": {
            "generic": [],
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executeworkflowtrigger/"
              }
            ]
          },
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"trigger\"]",
      "defaults": {
        "name": "Lorsqu'ex√©cut√© par un autre workflow",
        "color": "#ff6d5a"
      },
      "iconData": {
        "icon": "sign-out-alt",
        "type": "icon"
      },
      "displayName": "Execute Workflow Trigger",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Agent AI",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1163,
      "icon": "fa:database",
      "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Memory"
            ],
            "Memory": [
              "For beginners"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "M√©moire simple"
      },
      "iconData": {
        "icon": "database",
        "type": "icon"
      },
      "displayName": "Simple Memory",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1241,
      "icon": "file:summarize.svg",
      "name": "n8n-nodes-base.summarize",
      "codex": {
        "data": {
          "alias": [
            "Append",
            "Array",
            "Average",
            "Concatenate",
            "Count",
            "Group",
            "Item",
            "List",
            "Max",
            "Min",
            "Pivot",
            "Sum",
            "Summarise",
            "Summarize",
            "Transform",
            "Unique"
          ],
          "details": "",
          "resources": {
            "generic": [],
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.summarize/"
              }
            ]
          },
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Data Transformation"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "R√©sumer"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "Summarize",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 1247,
      "icon": "fa:comments",
      "name": "@n8n/n8n-nodes-langchain.chatTrigger",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
              }
            ]
          },
          "categories": [
            "Core Nodes",
            "Langchain"
          ]
        }
      },
      "group": "[\"trigger\"]",
      "defaults": {
        "name": "Lorsqu'un message de chat est re√ßu"
      },
      "iconData": {
        "icon": "comments",
        "type": "icon"
      },
      "displayName": "Chat Trigger",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1248,
      "icon": "file:qdrant.svg",
      "name": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreqdrant/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Vector Stores",
              "Tools",
              "Root Nodes"
            ],
            "Tools": [
              "Other Tools"
            ],
            "Vector Stores": [
              "Other Vector Stores"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Magasin de vecteurs Qdrant"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "Qdrant Vector Store",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1261,
      "icon": "file:google.svg",
      "name": "@n8n/n8n-nodes-langchain.embeddingsGoogleGemini",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsgooglegemini/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Embeddings"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Embeddings Google Gemini"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+"
      },
      "displayName": "Embeddings Google Gemini",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1262,
      "icon": "file:google.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Mod√®le de chat Google Gemini"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+"
      },
      "displayName": "Google Gemini Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ],
  "categories": [
    {
      "id": 40,
      "name": "Chatbot de support"
    },
    {
      "id": 48,
      "name": "AI RAG"
    }
  ],
  "image": []
}