{
  "id": 4972,
  "name": "Surveiller les interactions de chat AI avec Gemini 2.5 et le tra√ßage Langfuse",
  "views": 754,
  "recentViews": 1,
  "totalViews": 754,
  "createdAt": "2025-06-16T14:01:56.103Z",
  "description": "Ce flux de travail contient des n≈ìuds communautaires qui ne sont compatibles qu'avec la version auto-h√©berg√©e de n8n.\n\n# Comment √ßa fonctionne\n\nCe flux de travail est un agent AI simple qui se connecte √† Langfuse pour envoyer des donn√©es de tra√ßage afin d'aider √† surveiller les interactions LLM.\n\nL'id√©e principale est de cr√©er un mod√®le LLM personnalis√© qui permet la configuration de rappels, utilis√©s par langchain pour connecter des applications telles que Langfuse.\n\nCela est r√©alis√© en utilisant le n≈ìud \"langchain code\" :\n- Connecte un sous-n≈ìud de mod√®le LLM pour obtenir les variables du mod√®le (nom du mod√®le, temp et fournisseur) - Cr√©e un initChatModel langchain g√©n√©rique avec les param√®tres du mod√®le.\n- Retourne le LLM √† utiliser par le n≈ìud Agent AI.\n\n\n## üìã Pr√©requis\n- Instance Langfuse (cloud ou auto-h√©berg√©e) avec des identifiants API\n- Cl√© API LLM (Gemini, OpenAI, Anthropic, etc.)\n- n8n &gt;= 1.98.0 (n√©cessaire pour le support du n≈ìud de code LangChain dans l'Agent AI)\n\n## ‚öôÔ∏è Configuration\n\n1. Ajoutez ceci √† votre instance n8n :\n```bash\n# Configuration Langfuse\nLANGFUSE_SECRET_KEY=your_secret_key\nLANGFUSE_PUBLIC_KEY=your_public_key\nLANGFUSE_BASEURL=https://cloud.langfuse.com  # ou votre URL auto-h√©berg√©e\n\n# Cl√© API LLM (exemple pour Gemini)\nGOOGLE_API_KEY=your_api_key\n```\n\nAlternative : Configurez cela directement dans le n≈ìud de code LangChain si vous pr√©f√©rez ne pas utiliser de variables d'environnement\n\n2. Importez le JSON du flux de travail\n\n3. Connectez votre n≈ìud de mod√®le LLM pr√©f√©r√©\n\n4. Envoyez un message de test pour v√©rifier que le tra√ßage appara√Æt dans Langfuse\n",
  "workflow": {
    "meta": {
      "instanceId": "b1926f93e76612afd634dd6dc19dbaa8cf351113b4888b572f3e1d29a5bec617",
      "templateCredsSetupCompleted": true
    },
    "nodes": [
      {
        "id": "c26d363f-53d2-446b-98db-d68a4b947bc5",
        "name": "When chat message received",
        "type": "@n8n/n8n-nodes-langchain.chatTrigger",
        "position": [
          880,
          540
        ],
        "webhookId": "3917af54-131f-41c5-a250-b32e0ff9dc5f",
        "parameters": {
          "options": {}
        },
        "typeVersion": 1.1
      },
      {
        "id": "01f4841f-2e4d-4beb-8f19-258cb4e8f988",
        "name": "gemini-2.5",
        "type": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
        "position": [
          1188,
          960
        ],
        "parameters": {
          "options": {
            "temperature": 0.4
          },
          "modelName": "models/gemini-2.5-flash-preview-05-20"
        },
        "credentials": {
          "googlePalmApi": {
            "id": "XmPj4vZ604DaosrU",
            "name": "gemini-personal"
          }
        },
        "typeVersion": 1
      },
      {
        "id": "f63d8101-0b24-4917-9126-ceccc926cb3c",
        "name": "mem",
        "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "position": [
          1396,
          760
        ],
        "parameters": {
          "contextWindowLength": 100
        },
        "typeVersion": 1.3
      },
      {
        "id": "c5c637fd-962d-4c2c-bb7a-c35faae85ee1",
        "name": "Langfuse LLM",
        "type": "@n8n/n8n-nodes-langchain.code",
        "position": [
          1100,
          762.5
        ],
        "parameters": {
          "code": {
            "supplyData": {
              "code": "const { CallbackHandler } = require(\"langfuse-langchain\");\nconst { initChatModel } = require(\"langchain/chat_models/universal\");\n\n// Get connected model\nconst model = await this.getInputConnectionData(\"ai_languageModel\", 0);\nconst modelProvider = model.lc_namespace[2].replace(\"_\", \"-\");\nconst modelName = model.model;\nconst temperature = model.temperature;\n\n// Initialize Langfuse callback handler\nconst sessionId = $input.item.json.sessionId;\nconst langfuseHandler = new CallbackHandler({\n  sessionId,\n});\n\nconst llm = await initChatModel(modelName, {\n  temperature,\n  modelProvider,\n  callbacks: [langfuseHandler],\n});\n\nreturn llm;\n"
            }
          },
          "inputs": {
            "input": [
              {
                "type": "ai_languageModel",
                "required": true,
                "maxConnections": 1
              }
            ]
          },
          "outputs": {
            "output": [
              {
                "type": "ai_languageModel"
              }
            ]
          }
        },
        "typeVersion": 1
      },
      {
        "id": "c5f53fbe-5603-4384-b4fa-076a69a1f6aa",
        "name": "AI Agent",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "position": [
          1204,
          540
        ],
        "parameters": {
          "options": {}
        },
        "typeVersion": 2
      }
    ],
    "pinData": {},
    "connections": {
      "mem": {
        "ai_memory": [
          [
            {
              "node": "AI Agent",
              "type": "ai_memory",
              "index": 0
            }
          ]
        ]
      },
      "AI Agent": {
        "main": [
          []
        ]
      },
      "gemini-2.5": {
        "ai_languageModel": [
          [
            {
              "node": "Langfuse LLM",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Langfuse LLM": {
        "ai_languageModel": [
          [
            {
              "node": "AI Agent",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "When chat message received": {
        "main": [
          [
            {
              "node": "AI Agent",
              "type": "main",
              "index": 0
            }
          ]
        ]
      }
    }
  },
  "lastUpdatedBy": 51,
  "workflowInfo": {
    "nodeCount": 5,
    "nodeTypes": {
      "@n8n/n8n-nodes-langchain.code": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.agent": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.chatTrigger": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.lmChatGoogleGemini": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.memoryBufferWindow": {
        "count": 1
      }
    }
  },
  "user": {
    "name": "Eduardo Hales",
    "username": "ehales",
    "bio": "Full Stack Developer with 8+ years building web applications, now focused on AI engineering and cybersecurity. I integrate LLMs into production systems, conduct security audits, and help teams build safer, smarter software. Particularly interested in making AI applications both powerful and secure.",
    "verified": false,
    "links": [
      ""
    ],
    "avatar": "https://gravatar.com/avatar/e66357d2e395080b10b4bce9323106ba84f3e31da6a305badee6159c7cc77127?r=pg&d=retro&size=200"
  },
  "nodes": [
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Agent AI",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1127,
      "icon": "fa:code",
      "name": "@n8n/n8n-nodes-langchain.code",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.code/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Miscellaneous"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Code LangChain"
      },
      "iconData": {
        "icon": "code",
        "type": "icon"
      },
      "displayName": "LangChain Code",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1163,
      "icon": "fa:database",
      "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Memory"
            ],
            "Memory": [
              "For beginners"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "M√©moire Simple"
      },
      "iconData": {
        "icon": "database",
        "type": "icon"
      },
      "displayName": "Simple Memory",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1247,
      "icon": "fa:comments",
      "name": "@n8n/n8n-nodes-langchain.chatTrigger",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
              }
            ]
          },
          "categories": [
            "Core Nodes",
            "Langchain"
          ]
        }
      },
      "group": "[\"trigger\"]",
      "defaults": {
        "name": "Lorsque le message de chat est re√ßu"
      },
      "iconData": {
        "icon": "comments",
        "type": "icon"
      },
      "displayName": "Chat Trigger",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1262,
      "icon": "file:google.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatGoogleGemini",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatgooglegemini/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Mod√®le de chat Google Gemini"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDggNDgiPjxkZWZzPjxwYXRoIGlkPSJhIiBkPSJNNDQuNSAyMEgyNHY4LjVoMTEuOEMzNC43IDMzLjkgMzAuMSAzNyAyNCAzN2MtNy4yIDAtMTMtNS44LTEzLTEzczUuOC0xMyAxMy0xM2MzLjEgMCA1LjkgMS4xIDguMSAyLjlsNi40LTYuNEMzNC42IDQuMSAyOS42IDIgMjQgMiAxMS44IDIgMiAxMS44IDIgMjRzOS44IDIyIDIyIDIyYzExIDAgMjEtOCAyMS0yMiAwLTEuMy0uMi0yLjctLjUtNCIvPjwvZGVmcz48Y2xpcFBhdGggaWQ9ImIiPjx1c2UgeGxpbms6aHJlZj0iI2EiIG92ZXJmbG93PSJ2aXNpYmxlIi8+PC9jbGlwUGF0aD48cGF0aCBmaWxsPSIjRkJCQzA1IiBkPSJNMCAzN1YxMWwxNyAxM3oiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiNFQTQzMzUiIGQ9Im0wIDExIDE3IDEzIDctNi4xTDQ4IDE0VjBIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiMzNEE4NTMiIGQ9Im0wIDM3IDMwLTIzIDcuOSAxTDQ4IDB2NDhIMHoiIGNsaXAtcGF0aD0idXJsKCNiKSIvPjxwYXRoIGZpbGw9IiM0Mjg1RjQiIGQ9Ik00OCA0OCAxNyAyNGwtNC0zIDM1LTEweiIgY2xpcC1wYXRoPSJ1cmwoI2IpIi8+PC9zdmc+"
      },
      "displayName": "Google Gemini Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ],
  "categories": [
    {
      "id": 5,
      "name": "Ing√©nierie"
    },
    {
      "id": 47,
      "name": "Chatbot AI"
    }
  ],
  "image": []
}