{
  "id": 4237,
  "name": "Routeur dynamique de mod√®le IA pour l'optimisation des requ√™tes avec OpenRouter",
  "views": 4039,
  "recentViews": 3,
  "totalViews": 4039,
  "createdAt": "2025-05-20T07:40:19.495Z",
  "description": "Le **D√©cideur d'Agent** est un syst√®me de routage dynamique aliment√© par l'IA qui s√©lectionne automatiquement le mod√®le de langage large (LLM) le plus appropri√© pour r√©pondre √† la requ√™te d'un utilisateur en fonction du contenu et de l'objectif de la requ√™te.\n\nCe flux de travail garantit des **r√©ponses IA dynamiques et optimis√©es** en dirigeant intelligemment les requ√™tes vers le mod√®le le mieux adapt√©.\n\n---\n\n### **Avantages**\n\n* **üîÅ Routage Automatique des Mod√®les :**\n  S√©lectionne automatiquement le meilleur mod√®le pour le travail, am√©liorant l'efficacit√© et la pertinence des r√©ponses.\n\n* **üéØ Utilisation Optimis√©e des Ressources :**\n  √âvite le surco√ªt des mod√®les co√ªteux comme GPT-4 en dirigeant les requ√™tes plus simples vers des mod√®les l√©gers.\n\n* **üìö Raisonnement Connaissant le Mod√®le :**\n  Utilise des m√©tadonn√©es d√©taill√©es sur les capacit√©s des mod√®les (par exemple, raisonnement, codage, recherche web) pour une s√©lection intelligente.\n\n* **üì• Modulaire et Extensible :**\n  Facile √† int√©grer avec d'autres outils ou √† √©tendre en ajoutant plus de mod√®les ou une logique de d√©cision personnalis√©e.\n\n* **üë®‚Äçüíª Id√©al pour les Syst√®mes RAG et Multi-Agents :**\n  Peut servir de cerveau derri√®re des cadres d'agents plus complexes ou des pipelines de G√©n√©ration Augment√©e par R√©cup√©ration.\n\n---\n\n\n### **Comment √ßa fonctionne**  \n\n1. **D√©clencheur de Chat** : Le flux de travail commence lorsqu'un utilisateur envoie un message, d√©clenchant l'**Agent de Routage**.  \n2. **S√©lection du Mod√®le** : L'**Agent IA** analyse la requ√™te et s√©lectionne le mod√®le le mieux adapt√© parmi les options disponibles (par exemple, Claude 3.7 Sonnet pour le codage, Perplexity/Sonar pour les recherches web, GPT-4o Mini pour le raisonnement).  \n3. **Sortie Structur√©e** : L'agent renvoie une **r√©ponse JSON** avec le prompt de l'utilisateur et le mod√®le choisi.  \n4. **Ex√©cution** : Le mod√®le s√©lectionn√© traite la requ√™te et g√©n√®re une r√©ponse, garantissant des performances optimales pour la t√¢che.  \n\n### **√âtapes de Configuration**  \n\n1. **Configurer les N≈ìuds** :  \n   - **D√©clencheur de Chat** : Configurez le webhook pour recevoir les messages des utilisateurs.  \n   - **Agent de Routage (Agent IA)** : D√©finissez le message syst√®me avec les forces des mod√®les et les r√®gles de sortie JSON.  \n   - **Mod√®le de Chat OpenRouter** : Connectez-vous √† OpenRouter pour l'acc√®s au mod√®le.  \n   - **Analyseur de Sortie Structur√©e** : Assurez-vous qu'il valide le format de r√©ponse JSON (`prompt` + `model`).  \n   - **Agent d'Ex√©cution (Agent IA1)** : Configurez-le pour transmettre le prompt au mod√®le s√©lectionn√©.  \n\n2. **Connecter les N≈ìuds** :  \n   - Liez le **D√©clencheur de Chat** √† l'**Agent de Routage**.  \n   - Connectez le **Mod√®le de Chat OpenRouter** et l'**Analyseur de Sortie** √† l'**Agent de Routage**.  \n   - Dirigez le JSON analys√© vers l'**Agent d'Ex√©cution**, qui utilise le mod√®le choisi via **Mod√®le de Chat OpenRouter1**.  \n\n3. **Identifiants** :  \n   - Assurez-vous que les **identifiants API OpenRouter** sont correctement configur√©s pour les deux n≈ìuds de mod√®le de chat.  \n\n4. **Tester et D√©ployer** :  \n   - Activez le flux de travail et testez avec des requ√™tes d'exemple pour v√©rifier la logique de s√©lection du mod√®le.  \n   - Ajustez les r√®gles de routage si n√©cessaire pour une meilleure pr√©cision.  \n\n---\n\n### **Besoin d'aide pour la personnalisation ?**  \n[Contactez-moi](mailto:info@n3w.it) pour des conseils et du soutien ou ajoutez-moi sur [Linkedin](https://www.linkedin.com/in/davideboizza/).",
  "workflow": {
    "id": "uNLWQ7BSozpoehpU",
    "meta": {
      "instanceId": "a4bfc93e975ca233ac45ed7c9227d84cf5a2329310525917adaf3312e10d5462",
      "templateCredsSetupCompleted": true
    },
    "name": "Automated AI Routing with OpenRouter",
    "tags": [],
    "nodes": [
      {
        "id": "25903a04-24d2-41f9-bf34-5d6234e642e5",
        "name": "When chat message received",
        "type": "@n8n/n8n-nodes-langchain.chatTrigger",
        "position": [
          -180,
          -180
        ],
        "webhookId": "a0032740-26d8-491b-93f9-2250906d0e17",
        "parameters": {
          "options": {}
        },
        "typeVersion": 1.1
      },
      {
        "id": "fabffdee-3c1e-47db-a4e9-f6473a6e9257",
        "name": "OpenRouter Chat Model",
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
        "position": [
          0,
          40
        ],
        "parameters": {
          "options": {}
        },
        "credentials": {
          "openRouterApi": {
            "id": "pb06rfB4xmxzVe3Q",
            "name": "OpenRouter"
          }
        },
        "typeVersion": 1
      },
      {
        "id": "c53fe672-92cb-4d88-b4f6-f413fb00ad6a",
        "name": "Structured Output Parser",
        "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
        "position": [
          340,
          280
        ],
        "parameters": {
          "schemaType": "manual",
          "inputSchema": "{\n\t\"type\": \"object\",\n\t\"properties\": {\n\t\t\"prompt\": {\n\t\t\t\"type\": \"string\"\n\t\t},\n\t\t\"model\": {\n\t\t\t\"type\": \"string\"\n\t\t}\n\t}\n}"
        },
        "typeVersion": 1.2
      },
      {
        "id": "d60a9d61-c611-4813-bf85-e8f8faaa21b6",
        "name": "OpenRouter Chat Model1",
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
        "position": [
          420,
          40
        ],
        "parameters": {
          "model": "={{ $json.output.model }}",
          "options": {}
        },
        "credentials": {
          "openRouterApi": {
            "id": "pb06rfB4xmxzVe3Q",
            "name": "OpenRouter"
          }
        },
        "typeVersion": 1
      },
      {
        "id": "ef9ceacb-55e4-4795-aa18-976997ec3717",
        "name": "Sticky Note",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -180,
          -420
        ],
        "parameters": {
          "width": 840,
          "height": 180,
          "content": "## Dynamic Model Selector for Optimal AI Responses\n\nThe **Agent Decisioner** is a dynamic, AI-powered routing system that automatically selects the most appropriate large language model (LLM) to respond to a user's query based on the query‚Äôs content and purpose.\n\nThis workflow ensures **dynamic, optimized AI responses** by intelligently routing queries to the best-suited model."
        },
        "typeVersion": 1
      },
      {
        "id": "4d688ad7-b463-4e72-9b79-4b9142f022d2",
        "name": "Routing Agent",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "position": [
          40,
          -180
        ],
        "parameters": {
          "options": {
            "systemMessage": "=You are a **Routing Agent**.\n\nYour task is to analyze user queries and determine the most appropriate model to handle each specific use case.\n\n## Available Models\n\nYou have access to the following models:\n\n1. **perplexity/sonar**\n2. **openai/gpt-4o-mini**\n3. **anthropic/claude-3.7-sonnet**\n4. **meta-llama/llama-3-70b-instruct**\n5. **google/gemini-2.5-pro-preview**\n6. **qwen/qwen-qwq-32b**\n7. **openai/codex-mini**\n8. **openai/o1-pro**\n\n## Model Strengths\n\n### 1. perplexity/sonar\n- Built-in web search capability\n- Provides citations and customizable sources\n- Ideal for retrieving live, up-to-date information from the web\n\n### 2. openai/gpt-4o-mini\n- Cost-efficient language model optimized for advanced reasoning tasks\n- Excels in science and mathematics\n- Best suited for problems requiring careful, well-thought-out responses involving multiple variables or connections\n\n### 3. anthropic/claude-3.7-sonnet\n- High proficiency in coding tasks, scoring ~94% on SWE-Bench Verified\n- Enhances data science expertise by navigating unstructured data and utilizing multiple tools for insights\n- Handles very long documents and maintains coherence over extended conversations or analyses\n- Performs well in creative writing tasks such as storytelling, dialogue generation, and summarization\n- Tends to produce responses that are more aligned with safety and ethical guidelines\n\n### 4. meta-llama/llama-3-70b-instruct\n- Strong performance in coding and reasoning tasks\n- Suitable for complex programming and technical problem-solving\n- Supports long context windows, making it ideal for extended analyses\n\n### 5. google/gemini-2.5-pro-preview\n- Advanced multimodal capabilities, handling both text and images\n- Excels in tasks requiring integration of visual and textual information\n- Ideal for complex problem-solving involving diverse data types\n\n### 6. qwen/qwen-qwq-32b\n- Specialized in reasoning and problem-solving tasks\n- Effective in handling logical puzzles and complex analytical queries\n\n### 7. openai/codex-mini\n- Optimized for code generation and completion tasks\n- Suitable for lightweight coding tasks and quick code snippets\n\n### 8. openai/o1-pro\n- Designed for complex reasoning with enhanced computational resources\n- Performs well in STEM-related tasks, including physics, chemistry, and biology\n- Capable of handling large context windows, making it suitable for in-depth analyses\n\n## Output Format\n\nYour output must always be a valid JSON object in the following format:\n\n```json\n{\n  \"prompt\": \"user query goes here\",\n  \"model\": \"selected-model-name\"\n}\n```\n\n- The **\"prompt\"** field should contain the exact query to be sent to the selected model.\n- The **\"model\"** field should contain the model name (one of: perplexity/sonar, openai/gpt-4o-mini, anthropic/claude-3.7-sonnet, meta-llama/llama-3-70b-instruct, google/gemini-2.5-pro-preview, qwen/qwen-qwq-32b, openai/codex-mini, openai/o1-pro).\n\n**Important:** Only return the JSON object. Do not include any explanations or additional text."
          },
          "hasOutputParser": true
        },
        "typeVersion": 1.9
      },
      {
        "id": "94c49c22-9697-4230-ba35-5159041cfdc7",
        "name": "AI Agent",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "position": [
          400,
          -180
        ],
        "parameters": {
          "text": "={{ $json.output.prompt }}",
          "options": {},
          "promptType": "define"
        },
        "typeVersion": 1.9
      },
      {
        "id": "54c4278e-c185-4ab4-b21e-d8e837b14818",
        "name": "Auto-fixing Output Parser",
        "type": "@n8n/n8n-nodes-langchain.outputParserAutofixing",
        "position": [
          140,
          60
        ],
        "parameters": {
          "options": {
            "prompt": "Instructions:\n--------------\n{instructions}\n--------------\nCompletion:\n--------------\n{completion}\n--------------\n\nAbove, the Completion did not satisfy the constraints given in the Instructions.\nError:\n--------------\n{error}\n--------------\n\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:"
          }
        },
        "typeVersion": 1
      },
      {
        "id": "2813da6b-423b-41d6-8eb4-664f616ca8d5",
        "name": "OpenAI Chat Model",
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "position": [
          140,
          220
        ],
        "parameters": {
          "model": {
            "__rl": true,
            "mode": "list",
            "value": "gpt-4o-mini"
          },
          "options": {}
        },
        "credentials": {
          "openAiApi": {
            "id": "TefveNaDaMERl1hY",
            "name": "OpenAi account (Eure)"
          }
        },
        "typeVersion": 1.2
      }
    ],
    "active": false,
    "pinData": {},
    "settings": {
      "executionOrder": "v1"
    },
    "versionId": "bb8e8d46-ce32-49e0-a843-496c6e026902",
    "connections": {
      "Routing Agent": {
        "main": [
          [
            {
              "node": "AI Agent",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "OpenAI Chat Model": {
        "ai_languageModel": [
          [
            {
              "node": "Auto-fixing Output Parser",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "OpenRouter Chat Model": {
        "ai_languageModel": [
          [
            {
              "node": "Routing Agent",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "OpenRouter Chat Model1": {
        "ai_languageModel": [
          [
            {
              "node": "AI Agent",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Structured Output Parser": {
        "ai_outputParser": [
          [
            {
              "node": "Auto-fixing Output Parser",
              "type": "ai_outputParser",
              "index": 0
            }
          ]
        ]
      },
      "Auto-fixing Output Parser": {
        "ai_outputParser": [
          [
            {
              "node": "Routing Agent",
              "type": "ai_outputParser",
              "index": 0
            }
          ]
        ]
      },
      "When chat message received": {
        "main": [
          [
            {
              "node": "Routing Agent",
              "type": "main",
              "index": 0
            }
          ]
        ]
      }
    }
  },
  "lastUpdatedBy": 29,
  "workflowInfo": {
    "nodeCount": 9,
    "nodeTypes": {
      "n8n-nodes-base.stickyNote": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.agent": {
        "count": 2
      },
      "@n8n/n8n-nodes-langchain.chatTrigger": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.lmChatOpenRouter": {
        "count": 2
      },
      "@n8n/n8n-nodes-langchain.outputParserAutofixing": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.outputParserStructured": {
        "count": 1
      }
    }
  },
  "user": {
    "name": "Davide",
    "username": "n3witalia",
    "bio": "Full-stack Web Developer based in Italy specialising in Marketing & AI-powered automations. For business enquiries, send me an email at info@n3w.it or add me on Linkedin.com/in/davideboizza",
    "verified": true,
    "links": [
      "https://n3w.it"
    ],
    "avatar": "https://gravatar.com/avatar/d41b8a0aa81139243509c58870f5b4be292824a507ab57d10ed066d8628ed8da?r=pg&d=retro&size=200"
  },
  "nodes": [
    {
      "id": 565,
      "icon": "fa:sticky-note",
      "name": "n8n-nodes-base.stickyNote",
      "codex": {
        "data": {
          "alias": [
            "Comments",
            "Notes",
            "Sticky"
          ],
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"input\"]",
      "defaults": {
        "name": "Note Collante",
        "color": "#FFD233"
      },
      "iconData": {
        "icon": "sticky-note",
        "type": "icon"
      },
      "displayName": "Sticky Note",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Agent IA",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1153,
      "icon": "file:openAiLight.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Mod√®le de Chat OpenAI"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "OpenAI Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1175,
      "icon": "fa:tools",
      "name": "@n8n/n8n-nodes-langchain.outputParserAutofixing",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserautofixing/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Output Parsers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Analyseur de Sortie Auto-correctif"
      },
      "iconData": {
        "icon": "tools",
        "type": "icon"
      },
      "displayName": "Auto-fixing Output Parser",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1179,
      "icon": "fa:code",
      "name": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "codex": {
        "data": {
          "alias": [
            "json",
            "zod"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Output Parsers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Analyseur de Sortie Structur√©e"
      },
      "iconData": {
        "icon": "code",
        "type": "icon"
      },
      "displayName": "Structured Output Parser",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1247,
      "icon": "fa:comments",
      "name": "@n8n/n8n-nodes-langchain.chatTrigger",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
              }
            ]
          },
          "categories": [
            "Core Nodes",
            "Langchain"
          ]
        }
      },
      "group": "[\"trigger\"]",
      "defaults": {
        "name": "Lorsque le message de chat est re√ßu"
      },
      "iconData": {
        "icon": "comments",
        "type": "icon"
      },
      "displayName": "Chat Trigger",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1281,
      "icon": "file:openrouter.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenrouter/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Mod√®le de Chat OpenRouter"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjOTRBM0I4IiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIHdpZHRoPSI0MCIgaGVpZ2h0PSI0MCIgdmlld0JveD0iMCAwIDI0IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjx0aXRsZT5PcGVuUm91dGVyPC90aXRsZT48cGF0aCBkPSJNMTYuODA0IDEuOTU3bDcuMjIgNC4xMDV2LjA4N0wxNi43MyAxMC4yMWwuMDE3LTIuMTE3LS44MjEtLjAzYy0xLjA1OS0uMDI4LTEuNjExLjAwMi0yLjI2OC4xMS0xLjA2NC4xNzUtMi4wMzguNTc3LTMuMTQ3IDEuMzUyTDguMzQ1IDExLjAzYy0uMjg0LjE5NS0uNDk1LjMzNi0uNjguNDU1bC0uNTE1LjMyMi0uMzk3LjIzNC4zODUuMjMuNTMuMzM4Yy40NzYuMzE0IDEuMTcuNzk2IDIuNzAxIDEuODY2IDEuMTEuNzc1IDIuMDgzIDEuMTc3IDMuMTQ3IDEuMzUybC4zLjA0NWMuNjk0LjA5MSAxLjM3NS4wOTQgMi44MjUuMDMzbC4wMjItMi4xNTkgNy4yMiA0LjEwNXYuMDg3TDE2LjU4OSAyMmwuMDE0LTEuODYyLS42MzUuMDIyYy0xLjM4Ni4wNDItMi4xMzcuMDAyLTMuMTM4LS4xNjItMS42OTQtLjI4LTMuMjYtLjkyNi00Ljg4MS0yLjA1OWwtMi4xNTgtMS41YTIxLjk5NyAyMS45OTcgMCAwMC0uNzU1LS40OThsLS40NjctLjI4YTU1LjkyNyA1NS45MjcgMCAwMC0uNzYtLjQzQzIuOTA4IDE0LjczLjU2MyAxNC4xMTYgMCAxNC4xMTZWOS44ODhsLjE0LjAwNGMuNTY0LS4wMDcgMi45MS0uNjIyIDMuODA5LTEuMTI0bDEuMDE2LS41OC40MzgtLjI3NGMuNDI4LS4yOCAxLjA3Mi0uNzI2IDIuNjg2LTEuODUzIDEuNjIxLTEuMTMzIDMuMTg2LTEuNzggNC44ODEtMi4wNTkgMS4xNTItLjE5IDEuOTc0LS4yMTMgMy44MTQtLjEzOGwuMDItMS45MDd6Ij48L3BhdGg+PC9zdmc+Cg=="
      },
      "displayName": "OpenRouter Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ],
  "categories": [
    {
      "id": 5,
      "name": "Ing√©nierie"
    },
    {
      "id": 47,
      "name": "Chatbot IA"
    }
  ],
  "image": []
}