{
  "id": 3885,
  "name": "Automatiser le raccourcissement d'URL avec Bitly en utilisant l'interface de chat Llama3",
  "views": 206,
  "recentViews": 0,
  "totalViews": 206,
  "createdAt": "2025-05-06T06:21:57.919Z",
  "description": "## À qui cela s'adresse-t-il ?\nCe flux de travail est destiné aux utilisateurs en ligne qui souhaitent et ont besoin d'une automatisation des flux de travail qui minimise le temps de création de liens et raccourcit les liens. Cela a un impact sur la rapidité du temps de travail et de l'énergie. En réalité, les liens créés un par un et très longs sont très chronophages et peu pratiques, surtout si nous devons d'abord les compiler et les envoyer. C'est aussi une forme de service à la communauté n8n et à l'entreprise n8n, afin que cette réalité ne soit plus fatigante et puisse répondre aux problèmes de réalité existants. Cela peut également être utilisé pour apprendre comment fonctionne la création automatique de liens.\n\n## Comment ça fonctionne ?\nExplication facile :\n\n1) Tout d'abord, le chat ouvert est destiné à déclencher des commandes qui sont envoyées au modèle d'IA et aux outils Bitly, vous pouvez faire n'importe quelle commande et simplement inclure le lien. Plus tard, ici nous allons également créer un lien.\n2) Deuxièmement, les agents IA enverront des modèles d'IA pour travailler selon les commandes d'entrée et produire une sortie via le chat ouvert.\n3) Troisièmement, l'outil Bitly qui est configuré pour créer des liens fera son travail. Parce qu'il est lié à l'agent IA et au modèle d'IA.\n4) Enfin, vous pouvez immédiatement voir et ouvrir le lien qui a été créé.\n\nC'est très simple et très facile. Cela facilite la vie de tout le monde.\n\n\n## Instructions de configuration\nComplétez ce qui est dans les nœuds comme indiqué dans la colonne des notes.\n\n1) Tout d'abord, téléchargez Ollama, en utilisant le guide qui a été fourni. Ensuite, après avoir exécuté le modèle, vous pouvez créer et connecter un \"Compte d'identification\".\n2) Deuxièmement, vous avez besoin d'un nœud de déclenchement de chat ouvert ou vous pouvez également utiliser d'autres déclencheurs.\n\n3) Troisièmement, l'agent IA sélectionne le modèle Ollama, et les outils Bitly qui ont été préparés sont configurés ici.\n\n4) Quatrièmement, il suffit de l'exécuter et cela fonctionne.\n\nC'est très simple et très pratique.\n\n## Exigences\nPour rappel :\n\nCela doit être configuré dans chaque nœud, comme ce que votre objectif est, également selon les conditions de votre objectif.\nIl doit y avoir (si ce n'est pas le cas, assurez-vous qu'il est enregistré) dans chaque \"Compte d'identification\" en suivant le guide sur comment le faire, le guide n8n est très complet.\nN'oubliez pas de sauvegarder et assurez-vous que le flux de travail est actif.\n\n## Comment personnaliser ce flux de travail selon vos besoins\nVous pouvez immédiatement ajouter d'autres nœuds ou d'autres déclencheurs pour pouvoir envoyer ce lien, comme un e-mail, etc., ce qui fournira des connaissances pour vos besoins dans des nœuds supplémentaires, afin que la précision soit également élevée lors de l'exécution des tâches, des objectifs de tâches et des responsabilités.\n\n## Félicitations pour cette automatisation et merci à n8n et à la communauté n8n",
  "workflow": {
    "id": "djEQhBoL2sh0ojdA",
    "meta": {
      "instanceId": "54985dca90e764ba04ed8f61efe057163f128af85943567c62c5761f48d1c878",
      "templateCredsSetupCompleted": true
    },
    "name": "Using Bitly With Ollama Chat Model and Open Chat",
    "tags": [],
    "nodes": [
      {
        "id": "9376c577-706a-4e37-808a-30c800120f1a",
        "name": "Create Link",
        "type": "n8n-nodes-base.bitlyTool",
        "position": [
          360,
          380
        ],
        "parameters": {},
        "typeVersion": 1
      },
      {
        "id": "550c40ae-6638-41b1-ab72-e007e490904f",
        "name": "Ollama Chat Model",
        "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
        "position": [
          60,
          380
        ],
        "parameters": {},
        "typeVersion": 1
      },
      {
        "id": "64ceba81-c42a-41b3-b5af-84cf3d1bf3da",
        "name": "AI Agent",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "position": [
          180,
          20
        ],
        "parameters": {},
        "typeVersion": 1.9
      },
      {
        "id": "c6b0a8c8-7d45-409d-a1a0-953eeddbf5a5",
        "name": "Sticky Note6",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -540,
          -100
        ],
        "parameters": {
          "content": ""
        },
        "typeVersion": 1
      },
      {
        "id": "3a2bab82-1c1f-4ab7-b5e7-a242910dec00",
        "name": "Sticky Note",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -140,
          -100
        ],
        "parameters": {
          "content": ""
        },
        "typeVersion": 1
      },
      {
        "id": "665b7e23-c3aa-40c1-9556-6ebd7dbbcc41",
        "name": "Sticky Note1",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          140,
          -100
        ],
        "parameters": {
          "content": ""
        },
        "typeVersion": 1
      },
      {
        "id": "7a6d0601-5d5e-47bb-bd96-d2fe81d77e91",
        "name": "Sticky Note2",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -140,
          220
        ],
        "parameters": {
          "content": ""
        },
        "typeVersion": 1
      },
      {
        "id": "fdc20ba4-6181-4163-88e8-768bb713ad80",
        "name": "Sticky Note3",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          280,
          220
        ],
        "parameters": {
          "content": ""
        },
        "typeVersion": 1
      },
      {
        "id": "15df35ea-63dc-4cc7-9f5f-d84f4944c807",
        "name": "Open Chat",
        "type": "@n8n/n8n-nodes-langchain.chatTrigger",
        "position": [
          -60,
          20
        ],
        "webhookId": "447cba79-509e-4bd9-aaa9-5ee8c182fb21",
        "parameters": {},
        "typeVersion": 1.1
      }
    ],
    "active": false,
    "pinData": {},
    "settings": {
      "executionOrder": "v1"
    },
    "versionId": "848186e0-bd85-4fcb-aa35-5fde47943340",
    "connections": {
      "AI Agent": {
        "main": [
          []
        ]
      },
      "Open Chat": {
        "main": [
          [
            {
              "node": "AI Agent",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Create Link": {
        "ai_tool": [
          [
            {
              "node": "AI Agent",
              "type": "ai_tool",
              "index": 0
            }
          ]
        ]
      },
      "Ollama Chat Model": {
        "ai_languageModel": [
          [
            {
              "node": "AI Agent",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      }
    }
  },
  "lastUpdatedBy": 29,
  "workflowInfo": {
    "nodeCount": 9,
    "nodeTypes": {
      "n8n-nodes-base.bitlyTool": {
        "count": 1
      },
      "n8n-nodes-base.stickyNote": {
        "count": 5
      },
      "@n8n/n8n-nodes-langchain.agent": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.chatTrigger": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.lmChatOllama": {
        "count": 1
      }
    }
  },
  "user": {
    "name": "Ghufran Ridhawi",
    "username": "ghufran-ridhawi",
    "bio": "Hi! I'm Ghufran. I am the creator of AI Agent/Agentic AI System, AI Automation, and Automation System which has strong, practical, easy-to-use characteristics and is full of logic and unique taste. Enjoy! \n\nThanks for using and viewing my workflow. Hope it helps guys!\n\nFor inquiries and cooperations, please contact the available link. Have a Wonderful Day!\n\nWarm regards to n8n company and n8n community.",
    "verified": true,
    "links": [
      "https://t.ly/ghufranridhawi"
    ],
    "avatar": "https://gravatar.com/avatar/4f7ed8a9d39b56838c4446c3dce354853d12e0e8e19f63d27d7f7f50d89a2413?r=pg&d=retro&size=200"
  },
  "nodes": [
    {
      "id": 565,
      "icon": "fa:sticky-note",
      "name": "n8n-nodes-base.stickyNote",
      "codex": {
        "data": {
          "alias": [
            "Comments",
            "Notes",
            "Sticky"
          ],
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"input\"]",
      "defaults": {
        "name": "Note autocollante",
        "color": "#FFD233"
      },
      "iconData": {
        "icon": "sticky-note",
        "type": "icon"
      },
      "displayName": "Sticky Note",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Agent IA",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1151,
      "icon": "file:ollama.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatollama/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Modèle de chat Ollama"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "Ollama Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1247,
      "icon": "fa:comments",
      "name": "@n8n/n8n-nodes-langchain.chatTrigger",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
              }
            ]
          },
          "categories": [
            "Core Nodes",
            "Langchain"
          ]
        }
      },
      "group": "[\"trigger\"]",
      "defaults": {
        "name": "Lorsque le message de chat est reçu"
      },
      "iconData": {
        "icon": "comments",
        "type": "icon"
      },
      "displayName": "Chat Trigger",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ],
  "categories": [
    {
      "id": 43,
      "name": "Productivité personnelle"
    },
    {
      "id": 47,
      "name": "Chatbot IA"
    }
  ],
  "image": []
}