{
  "id": 6829,
  "name": "Construire une m√©moire de chat persistante avec GPT-4o-mini et la base de donn√©es vectorielle Qdrant",
  "views": 566,
  "recentViews": 2,
  "totalViews": 566,
  "createdAt": "2025-08-02T00:28:33.640Z",
  "description": "## üß† Syst√®me de m√©moire √† long terme pour agents IA avec base de donn√©es vectorielle\n\nTransformez vos assistants IA en agents intelligents avec des capacit√©s de m√©moire persistante. Ce flux de travail pr√™t pour la production met en ≈ìuvre un syst√®me de m√©moire √† long terme sophistiqu√© utilisant des bases de donn√©es vectorielles, permettant aux agents IA de se souvenir des conversations, des pr√©f√©rences des utilisateurs et des informations contextuelles √† travers des sessions illimit√©es.\n\n### üéØ Ce que fait ce mod√®le\n\nCe flux de travail cr√©e un assistant IA qui n'oublie jamais. Contrairement aux chatbots traditionnels qui perdent le contexte apr√®s chaque session, cette mise en ≈ìuvre utilise la technologie des bases de donn√©es vectorielles pour stocker et r√©cup√©rer l'historique des conversations de mani√®re s√©mantique, fournissant une v√©ritable m√©moire persistante pour vos agents IA.\n\n### üîë Caract√©ristiques cl√©s\n\n- **Stockage de contexte persistant** : Stocke automatiquement toutes les conversations dans une base de donn√©es vectorielle pour une r√©cup√©ration permanente\n- **Recherche de m√©moire s√©mantique** : Utilise des mod√®les d'embedding avanc√©s pour trouver des interactions pass√©es pertinentes en fonction du sens, pas seulement des mots-cl√©s\n- **Reranking intelligent** : Utilise le mod√®le de reranking de Cohere pour s'assurer que les souvenirs les plus pertinents sont utilis√©s pour le contexte\n- **Gestion des donn√©es structur√©es** : Formate et stocke les conversations avec des m√©tadonn√©es pour une r√©cup√©ration optimale\n- **Architecture √©volutive** : G√®re des conversations et des utilisateurs illimit√©s avec des performances constantes\n- **Pas de limitations de fen√™tre de contexte** : Contourne efficacement les limites de tokens LLM gr√¢ce √† une r√©cup√©ration intelligente\n\n### üí° Cas d'utilisation\n\n- **Bots de support client** : Se souvenir de l'historique des clients, des pr√©f√©rences et des probl√®mes pr√©c√©dents\n- **Assistants IA personnels** : Maintenir les pr√©f√©rences des utilisateurs et la continuit√© des conversations sur des mois ou des ann√©es\n- **Syst√®mes de gestion des connaissances** : Construire des bases de connaissances accumul√©es √† partir des interactions des utilisateurs\n- **Tuteurs √©ducatifs** : Suivre les progr√®s des √©tudiants et adapter l'enseignement en fonction de l'historique\n- **Chatbots d'entreprise** : Maintenir le contexte √† travers les d√©partements et les projets √† long terme\n\n### üõ†Ô∏è Comment √ßa fonctionne\n\n1. **Entr√©e utilisateur** : Re√ßoit des messages via l'interface de chat d'n8n\n2. **R√©cup√©ration de m√©moire** : Recherche dans la base de donn√©es vectorielle des conversations pass√©es pertinentes\n3. **Int√©gration du contexte** : L'agent IA utilise les souvenirs r√©cup√©r√©s pour g√©n√©rer des r√©ponses contextuelles\n4. **G√©n√©ration de r√©ponse** : Cr√©e des r√©ponses inform√©es bas√©es sur le contexte historique\n5. **Stockage de m√©moire** : Stocke de nouvelles donn√©es de conversation pour une r√©cup√©ration future\n\n### üìã Exigences\n\n- **Cl√© API OpenAI** : Pour les embeddings et les compl√©tions de chat\n- **Instance Qdrant** : Base de donn√©es vectorielle cloud ou auto-h√©berg√©e\n- **Cl√© API Cohere** : Optionnelle, pour une pr√©cision de r√©cup√©ration am√©lior√©e\n- **Instance n8n** : Version 1.0+ avec des n≈ìuds LangChain\n\n### üöÄ Configuration rapide\n\n1. Importez ce flux de travail dans votre instance n8n\n2. Configurez les identifiants pour OpenAI, Qdrant et Cohere\n3. Cr√©ez une collection Qdrant nomm√©e 'ltm' avec 1024 dimensions\n4. Activez le flux de travail et commencez √† discuter !\n\n### üìä M√©triques de performance\n\n- **Temps de r√©ponse** : 2-3 secondes en moyenne\n- **Pr√©cision de rappel de m√©moire** : 95%+\n- **Utilisation des tokens** : R√©duction de 50-70% par rapport √† l'inclusion compl√®te du contexte\n- **√âvolutivit√©** : Test√© avec plus de 100k conversations stock√©es\n\n### üí∞ Optimisation des co√ªts\n\n- Utilise GPT-4o-mini pour un √©quilibre optimal co√ªt/performance\n- Met en ≈ìuvre des strat√©gies de d√©coupage efficaces pour minimiser les co√ªts d'embedding\n- Le reranking peut √™tre d√©sactiv√© pour √©conomiser sur les co√ªts de l'API Cohere\n- Co√ªt moyen : ~0,01 $ par conversation\n\n### üìñ En savoir plus\n\nPour une explication d√©taill√©e de l'architecture et des d√©tails de mise en ≈ìuvre, consultez le guide complet : [M√©moire √† long terme pour LLMs utilisant le magasin vectoriel - Une approche pratique avec n8n et Qdrant](https://dev.to/einarcesar/long-term-memory-for-llms-using-vector-store-a-practical-approach-with-n8n-and-qdrant-2ha7)\n\n### ü§ù Support\n\n- **Documentation** : Guide de configuration complet dans l'article ci-dessus\n- **Communaut√©** : Partagez vos exp√©riences et obtenez de l'aide dans les forums communautaires d'n8n\n- **Probl√®mes** : Signalez des bugs ou demandez des fonctionnalit√©s sur la page du flux de travail\n\n---\n\n**Tags** : #IA #LangChain #BaseDeDonn√©esVectorielle #M√©moire√ÄLongTerme #RAG #OpenAI #Qdrant #ChatBot #Syst√®meDeM√©moire #IntelligenceArtificielle",
  "workflow": {
    "id": "EDZcm0r7Lp2uIkTn",
    "meta": {
      "instanceId": "48f9e8e7598a73c86aec19069eefaf1e83b51b8858cbb8999ee59d6fa3d9a3f2",
      "templateCredsSetupCompleted": true
    },
    "name": "LLM_TEMPLATE",
    "tags": [],
    "nodes": [
      {
        "id": "265bbb29-3ae9-49dd-9d77-4a8230af5f3e",
        "name": "Embeddings OpenAI",
        "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
        "position": [
          816,
          672
        ],
        "parameters": {
          "options": {
            "dimensions": 1024
          }
        },
        "credentials": {
          "openAiApi": {
            "id": "uHrKvsqlQYyImnjO",
            "name": "openai - einarcesar@gmail.com"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "8e8d619d-8356-485e-9ba5-26489e7ef46c",
        "name": "Sticky Note",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          560,
          800
        ],
        "parameters": {
          "width": 324,
          "height": 416,
          "content": "## üî§ TEXT VECTORIZATION\n\nConverts conversation text into 1024-dimensional vectors for semantic storage.\n\n### ‚öôÔ∏è Configuration:\n- **Model**: text-embedding-3-small\n- **Dimensions**: 1024 (must match vector DB)\n\n### üí° Pro tip: \nThis model offers the best balance between performance and cost for most applications.\n\n### üí∞ Costs:\n- ~$0.02 per 1M tokens"
        },
        "typeVersion": 1
      },
      {
        "id": "ae0a96a7-6cd5-4868-aadb-2b91e3e8f448",
        "name": "Default Data Loader",
        "type": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
        "position": [
          944,
          672
        ],
        "parameters": {
          "options": {}
        },
        "typeVersion": 1
      },
      {
        "id": "f8685c76-dde4-400a-a359-e52348d9f0ae",
        "name": "Sticky Note 2",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          944,
          1024
        ],
        "parameters": {
          "width": 324,
          "height": 371,
          "content": "## üìÑ DOCUMENT PROCESSOR\n\nPrepares conversation data for vector storage by converting it into a format suitable for chunking.\n\n### üéØ Purpose:\n- Standardizes data format\n- Prepares for text splitting\n- Maintains metadata integrity\n\n### ‚ö° Performance:\n- Processing time: ~10ms per conversation"
        },
        "typeVersion": 1
      },
      {
        "id": "fd60c06d-0c22-40fc-ab62-7f87b4c6f29a",
        "name": "Recursive Character Text Splitter",
        "type": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
        "position": [
          1040,
          880
        ],
        "parameters": {
          "options": {},
          "chunkSize": 200,
          "chunkOverlap": 40
        },
        "typeVersion": 1
      },
      {
        "id": "487e7425-4d1e-48be-9d92-5398e6328279",
        "name": "Sticky Note 3",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          1296,
          848
        ],
        "parameters": {
          "width": 340,
          "height": 392,
          "content": "## ‚úÇÔ∏è TEXT CHUNKING STRATEGY\n\n### üîß Settings:\n- **Chunk Size**: 200 chars\n- **Overlap**: 40 chars\n\n### üìä Why these values?\n- Small chunks = Better context precision\n- 20% overlap = Maintains context continuity\n- Optimized for conversation snippets\n\n### ‚ö° Performance: \nIdeal for real-time chat applications"
        },
        "typeVersion": 1
      },
      {
        "id": "922bfcdb-14ce-40cc-a3df-e89be2d59635",
        "name": "When chat message received",
        "type": "@n8n/n8n-nodes-langchain.chatTrigger",
        "position": [
          -112,
          448
        ],
        "webhookId": "ef238f10-3af1-409d-b7e8-3bf61cd357e4",
        "parameters": {
          "options": {}
        },
        "typeVersion": 1.1
      },
      {
        "id": "a8f24cf0-077f-43ea-a5b6-885ef7069948",
        "name": "Sticky Note 4",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -464,
          320
        ],
        "parameters": {
          "width": 340,
          "height": 428,
          "content": "## üí¨ CHAT INTERFACE\n\n### üöÄ Entry point for user interactions\n\n### üìù Features:\n- Real-time message processing\n- Session management\n- Context preservation\n\n### üîó Integration: \nCan be embedded in websites, apps, or used via n8n's chat widget\n\n### üåê Webhook URL:\nAvailable after workflow activation"
        },
        "typeVersion": 1
      },
      {
        "id": "58538d83-7b62-47ea-a099-143517886719",
        "name": "Embeddings for Retrieval",
        "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
        "position": [
          208,
          896
        ],
        "parameters": {
          "options": {
            "dimensions": 1024
          }
        },
        "credentials": {
          "openAiApi": {
            "id": "uHrKvsqlQYyImnjO",
            "name": "openai - einarcesar@gmail.com"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "64ee54af-4f43-4b8a-a73b-f0fb02a69fca",
        "name": "Sticky Note 5",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          208,
          1024
        ],
        "parameters": {
          "color": 6,
          "width": 340,
          "height": 260,
          "content": "## üîç RETRIEVAL EMBEDDINGS\n\nGenerates vectors for semantic search in the memory database.\n\n### ‚ö†Ô∏è Important: \nMust use the SAME model and dimensions as storage embeddings!\n\n### üéØ Used for:\n- Query vectorization\n- Similarity search\n- Context retrieval"
        },
        "typeVersion": 1
      },
      {
        "id": "b86d86d8-8595-4c27-bc9f-45e706d08623",
        "name": "Reranker Cohere",
        "type": "@n8n/n8n-nodes-langchain.rerankerCohere",
        "position": [
          464,
          1328
        ],
        "parameters": {},
        "credentials": {
          "cohereApi": {
            "id": "7GqfOJcuJFHWeOpS",
            "name": "CohereApi account"
          }
        },
        "typeVersion": 1
      },
      {
        "id": "43ef1754-fe7a-4435-be5f-5cc912ef7590",
        "name": "Sticky Note 6",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          576,
          1248
        ],
        "parameters": {
          "color": 5,
          "width": 340,
          "height": 396,
          "content": "## üéØ RELEVANCE OPTIMIZER\n\nRe-ranks retrieved memories by relevance to current context.\n\n### ‚ú® Benefits:\n- Improves retrieval accuracy by 30-40%\n- Reduces hallucinations\n- Ensures most relevant context is used\n\n### üí∞ Cost: \n~$1 per 1000 re-rankings\n\n### üîß Optional:\nCan be disabled for cost savings"
        },
        "typeVersion": 1
      },
      {
        "id": "9df9f1e4-b067-4ec8-8ee1-1d64f256081a",
        "name": "RAG_MEMORY",
        "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
        "onError": "continueRegularOutput",
        "position": [
          160,
          688
        ],
        "parameters": {
          "mode": "retrieve-as-tool",
          "topK": 20,
          "options": {},
          "toolName": "RAG_MEMORY",
          "useReranker": true,
          "toolDescription": "Long-term memory storage for maintaining context across conversations. Use this to recall previous interactions, user preferences, and historical context.",
          "qdrantCollection": {
            "__rl": true,
            "mode": "list",
            "value": "ltm",
            "cachedResultName": "ltm"
          }
        },
        "credentials": {
          "qdrantApi": {
            "id": "IMqj7iGvb0Ko0nCj",
            "name": "Qdrant - einar.qzz.io"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "a2f24b1e-df0f-4c10-b525-4eeea31edf7e",
        "name": "Sticky Note 7",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -160,
          784
        ],
        "parameters": {
          "color": 3,
          "width": 340,
          "height": 428,
          "content": "## üß† MEMORY RETRIEVAL SYSTEM\n\n### üìä Configuration:\n- **Collection**: 'ltm' (long-term memory)\n- **Top K**: 20 results\n- **Reranker**: Enabled\n\n### üîç How it works:\n1. Searches for similar past conversations\n2. Retrieves top 20 matches\n3. Re-ranks by relevance\n4. Provides context to AI\n\n### ‚ö° Performance: \n~50ms average retrieval time\n\n### üíæ Storage:\nQdrant cloud or self-hosted"
        },
        "typeVersion": 1
      },
      {
        "id": "33b1f48b-9700-4edb-a73b-5889316e7cdf",
        "name": "OpenAI Chat Model",
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "position": [
          432,
          816
        ],
        "parameters": {
          "model": {
            "__rl": true,
            "mode": "list",
            "value": "gpt-4o-mini"
          },
          "options": {
            "maxTokens": 2000,
            "temperature": 0.7
          }
        },
        "credentials": {
          "openAiApi": {
            "id": "uHrKvsqlQYyImnjO",
            "name": "openai - einarcesar@gmail.com"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "866bf74b-dc5b-4bf9-b01d-8fbc2da442c1",
        "name": "Structured Output Parser",
        "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
        "position": [
          544,
          112
        ],
        "parameters": {
          "autoFix": true,
          "jsonSchemaExample": "{\n    \"sessionId\": \"unique-session-identifier\",\n    \"chatInput\": \"User's message\",\n    \"output\": \"AI's response\",\n    \"timestamp\": \"2024-01-01T12:00:00Z\",\n    \"relevanceScore\": 0.95\n}"
        },
        "typeVersion": 1.3
      },
      {
        "id": "130381f8-4d66-4a5c-b233-5079e3630f71",
        "name": "Sticky Note 8",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          848,
          48
        ],
        "parameters": {
          "color": 4,
          "width": 340,
          "height": 344,
          "content": "## üìê OUTPUT FORMATTER\n\nEnsures AI responses follow a consistent structure for storage.\n\n### üéØ Schema includes:\n- Session ID (conversation tracking)\n- User input & AI output\n- Timestamp (temporal retrieval)\n- Relevance score (optimization)\n\n### ‚úÖ Auto-fix: \nEnabled to handle schema violations"
        },
        "typeVersion": 1
      },
      {
        "id": "6d7eb364-5c8f-4d6a-9ef6-51e3a1fc45bd",
        "name": "Format Response",
        "type": "n8n-nodes-base.set",
        "position": [
          1504,
          -32
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "fdd39640-54c5-4ed7-9f37-c8cd4302a212",
                "name": "output",
                "type": "string",
                "value": "={{ $('AI Agent').first().json.output.output }}"
              }
            ]
          }
        },
        "executeOnce": true,
        "typeVersion": 3.4
      },
      {
        "id": "cdc23122-cf49-4e54-922e-4990f5a2a5ee",
        "name": "Sticky Note 9",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          1696,
          -64
        ],
        "parameters": {
          "width": 340,
          "height": 304,
          "content": "## üé® RESPONSE FORMATTER\n\nExtracts and formats the AI response for the chat interface.\n\n### üì§ Output: \nClean response without metadata\n\n### üí° Purpose:\nEnsures users only see the actual message, not the underlying structure"
        },
        "typeVersion": 1
      },
      {
        "id": "98430332-8de1-48f9-b883-017e7ee35983",
        "name": "AI Agent",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "position": [
          144,
          432
        ],
        "parameters": {
          "options": {
            "systemMessage": "# AI Assistant with Long-Term Memory\n\nYou are an AI assistant equipped with a sophisticated long-term memory system. Your RAG_MEMORY tool allows you to recall past conversations, user preferences, and contextual information across sessions.\n\n## Core Capabilities:\n1. **Context Retention**: Remember and reference previous conversations\n2. **User Personalization**: Adapt responses based on learned preferences\n3. **Knowledge Accumulation**: Build upon past interactions\n4. **Intelligent Retrieval**: Access relevant historical context\n\n## Memory Usage Protocol:\n\n### Before Each Response:\n1. Query RAG_MEMORY for relevant past interactions\n2. Analyze retrieved context for applicable information\n3. Integrate historical knowledge into your response\n4. Maintain consistency with previous conversations\n\n### Memory Query Strategies:\n- Use specific keywords from the current conversation\n- Search for user preferences and patterns\n- Look for related topics discussed previously\n- Check for unresolved questions or follow-ups\n\n## Response Guidelines:\n1. **Acknowledge Continuity**: Reference previous conversations when relevant\n2. **Build on History**: Use past context to provide more informed responses\n3. **Maintain Consistency**: Ensure responses align with established facts\n4. **Update Understanding**: Evolve your knowledge based on new information\n\n## Privacy & Ethics:\n- Only reference information from this user's history\n- Respect conversation boundaries\n- Maintain appropriate context separation\n\n## Example Interaction Flow:\n```\nUser: \"What was that book you recommended last week?\"\n1. Query RAG_MEMORY for \"book recommendation\"\n2. Retrieve relevant conversation\n3. Provide specific book title and context\n4. Offer additional related suggestions\n```\n\nRemember: Your memory makes you more than just an AI - you're a continuous conversation partner who learns and grows with each interaction."
          },
          "hasOutputParser": true
        },
        "typeVersion": 2
      },
      {
        "id": "ef4a29b4-68f4-491e-b44b-3345455907a6",
        "name": "Sticky Note 10",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          48,
          -112
        ],
        "parameters": {
          "width": 360,
          "height": 516,
          "content": "## üß† INTELLIGENT AI AGENT\n\n### üéØ Core Features:\n- Long-term memory integration\n- Context-aware responses\n- Tool usage (RAG_MEMORY)\n- Structured output generation\n\n### üìã System Prompt:\n- Defines memory usage protocol\n- Sets behavioral guidelines\n- Ensures privacy compliance\n\n### ‚ö° Performance:\n- Avg response time: 2-3 seconds\n- Memory queries: 1-3 per response\n- Context window: Effectively unlimited\n\n### üí∞ Cost:\n- ~$0.15/$0.60 per 1M tokens (in/out)"
        },
        "typeVersion": 1
      },
      {
        "id": "db4e8e6b-0aee-4a93-8a01-bf38b7de9d98",
        "name": "Store Conversation",
        "type": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
        "position": [
          832,
          448
        ],
        "parameters": {
          "mode": "insert",
          "options": {},
          "qdrantCollection": {
            "__rl": true,
            "mode": "list",
            "value": "ltm",
            "cachedResultName": "ltm"
          }
        },
        "credentials": {
          "qdrantApi": {
            "id": "IMqj7iGvb0Ko0nCj",
            "name": "Qdrant - einar.qzz.io"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "13c42bd9-273d-4c9e-9e69-a324963f3f4f",
        "name": "Sticky Note 11",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          1248,
          304
        ],
        "parameters": {
          "color": 2,
          "width": 340,
          "height": 496,
          "content": "## üíæ MEMORY STORAGE\n\n### üì• What gets stored:\n- User input\n- AI response\n- Conversation metadata\n- Session information\n\n### üîß Configuration:\n- **Collection**: 'ltm'\n- **Batch size**: 100 (for efficiency)\n\n### üìà Storage metrics:\n- Avg storage time: 100ms\n- Vector dimensions: 1024\n- Retention: Unlimited*\n\n### ‚ö†Ô∏è Production tip:\nImplement cleanup policies for scalability"
        },
        "typeVersion": 1
      },
      {
        "id": "4237b604-513f-463c-b891-cb5bd4d588a6",
        "name": "GPT-4o-mini (Main)",
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "position": [
          32,
          576
        ],
        "parameters": {
          "model": {
            "__rl": true,
            "mode": "list",
            "value": "gpt-4o-mini",
            "cachedResultName": "gpt-4o-mini"
          },
          "options": {
            "topP": 0.7,
            "temperature": 0.2,
            "presencePenalty": 0.3,
            "frequencyPenalty": 0.6
          }
        },
        "credentials": {
          "openAiApi": {
            "id": "uHrKvsqlQYyImnjO",
            "name": "openai - einarcesar@gmail.com"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "1a882e59-d391-4923-9c18-68dfe99d6b47",
        "name": "Workflow Overview",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -944,
          160
        ],
        "parameters": {
          "color": 7,
          "width": 460,
          "height": 972,
          "content": "## üöÄ WORKFLOW OVERVIEW\n\n### Long-Term Memory for AI Assistants\n\nThis workflow implements a sophisticated memory system that allows AI assistants to remember conversations across sessions.\n\n### üîë Key Benefits:\n1. **Persistent Context**: No more repeating yourself\n2. **Personalization**: AI learns user preferences\n3. **Cost Efficiency**: Reduces token usage over time\n4. **Scalability**: Handles unlimited conversations\n\n### üìä Architecture:\n- **Vector Database**: Qdrant for semantic search\n- **LLM**: OpenAI GPT-4o-mini\n- **Embeddings**: text-embedding-3-small\n- **Reranking**: Cohere for accuracy\n\n### üõ†Ô∏è Setup Requirements:\n1. OpenAI API key\n2. Qdrant instance (cloud or self-hosted)\n3. Cohere API key (optional)\n4. n8n instance\n\n### üí° Use Cases:\n- Customer support bots\n- Personal AI assistants\n- Knowledge management systems\n- Educational tutors\n\n### üìà Performance Metrics:\n- Response time: 2-3 seconds\n- Memory recall: 95%+ accuracy\n- Cost: ~$0.01 per conversation\n\n### üîó Resources:\n- [Documentation](https://docs.n8n.io)\n- [Qdrant Setup](https://qdrant.tech)\n- [OpenAI Pricing](https://openai.com/pricing)"
        },
        "typeVersion": 1
      }
    ],
    "active": false,
    "pinData": {},
    "settings": {
      "executionOrder": "v1"
    },
    "versionId": "6b90a41f-8415-4e59-9082-48bf175e4804",
    "connections": {
      "AI Agent": {
        "main": [
          [
            {
              "node": "Store Conversation",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "RAG_MEMORY": {
        "ai_tool": [
          [
            {
              "node": "AI Agent",
              "type": "ai_tool",
              "index": 0
            }
          ]
        ]
      },
      "Reranker Cohere": {
        "ai_reranker": [
          [
            {
              "node": "RAG_MEMORY",
              "type": "ai_reranker",
              "index": 0
            }
          ]
        ]
      },
      "Embeddings OpenAI": {
        "ai_embedding": [
          [
            {
              "node": "Store Conversation",
              "type": "ai_embedding",
              "index": 0
            }
          ]
        ]
      },
      "OpenAI Chat Model": {
        "ai_languageModel": [
          [
            {
              "node": "Structured Output Parser",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "GPT-4o-mini (Main)": {
        "ai_languageModel": [
          [
            {
              "node": "AI Agent",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Store Conversation": {
        "main": [
          [
            {
              "node": "Format Response",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Default Data Loader": {
        "ai_document": [
          [
            {
              "node": "Store Conversation",
              "type": "ai_document",
              "index": 0
            }
          ]
        ]
      },
      "Embeddings for Retrieval": {
        "ai_embedding": [
          [
            {
              "node": "RAG_MEMORY",
              "type": "ai_embedding",
              "index": 0
            }
          ]
        ]
      },
      "Structured Output Parser": {
        "ai_outputParser": [
          [
            {
              "node": "AI Agent",
              "type": "ai_outputParser",
              "index": 0
            }
          ]
        ]
      },
      "When chat message received": {
        "main": [
          [
            {
              "node": "AI Agent",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Recursive Character Text Splitter": {
        "ai_textSplitter": [
          [
            {
              "node": "Default Data Loader",
              "type": "ai_textSplitter",
              "index": 0
            }
          ]
        ]
      }
    }
  },
  "lastUpdatedBy": 29,
  "workflowInfo": {
    "nodeCount": 25,
    "nodeTypes": {
      "n8n-nodes-base.set": {
        "count": 1
      },
      "n8n-nodes-base.stickyNote": {
        "count": 12
      },
      "@n8n/n8n-nodes-langchain.agent": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.chatTrigger": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
        "count": 2
      },
      "@n8n/n8n-nodes-langchain.rerankerCohere": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.embeddingsOpenAi": {
        "count": 2
      },
      "@n8n/n8n-nodes-langchain.vectorStoreQdrant": {
        "count": 2
      },
      "@n8n/n8n-nodes-langchain.outputParserStructured": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.documentDefaultDataLoader": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter": {
        "count": 1
      }
    }
  },
  "user": {
    "name": "Einar C√©sar Santos",
    "username": "einarcesar",
    "bio": "",
    "verified": true,
    "links": [
      "https://www.linkedin.com/in/einar-cesar"
    ],
    "avatar": "https://gravatar.com/avatar/35126b116ce06ceb68ee7fd3b6fd2193a7998a9eaa6a26857d125301ec33ad2a?r=pg&d=retro&size=200"
  },
  "nodes": [
    {
      "id": 38,
      "icon": "fa:pen",
      "name": "n8n-nodes-base.set",
      "codex": {
        "data": {
          "alias": [
            "Set",
            "JS",
            "JSON",
            "Filter",
            "Transform",
            "Map"
          ],
          "resources": {
            "generic": [
              {
                "url": "https://n8n.io/blog/learn-to-automate-your-factorys-incident-reporting-a-step-by-step-guide/",
                "icon": "üè≠",
                "label": "Learn to Automate Your Factory's Incident Reporting: A Step by Step Guide"
              },
              {
                "url": "https://n8n.io/blog/2021-the-year-to-automate-the-new-you-with-n8n/",
                "icon": "‚òÄÔ∏è",
                "label": "2021: The Year to Automate the New You with n8n"
              },
              {
                "url": "https://n8n.io/blog/automatically-pulling-and-visualizing-data-with-n8n/",
                "icon": "üìà",
                "label": "Automatically pulling and visualizing data with n8n"
              },
              {
                "url": "https://n8n.io/blog/database-monitoring-and-alerting-with-n8n/",
                "icon": "üì°",
                "label": "Database Monitoring and Alerting with n8n"
              },
              {
                "url": "https://n8n.io/blog/automatically-adding-expense-receipts-to-google-sheets-with-telegram-mindee-twilio-and-n8n/",
                "icon": "üßæ",
                "label": "Automatically Adding Expense Receipts to Google Sheets with Telegram, Mindee, Twilio, and n8n"
              },
              {
                "url": "https://n8n.io/blog/no-code-ecommerce-workflow-automations/",
                "icon": "store",
                "label": "6 e-commerce workflows to power up your Shopify s"
              },
              {
                "url": "https://n8n.io/blog/how-to-build-a-low-code-self-hosted-url-shortener/",
                "icon": "üîó",
                "label": "How to build a low-code, self-hosted URL shortener in 3 steps"
              },
              {
                "url": "https://n8n.io/blog/automate-your-data-processing-pipeline-in-9-steps-with-n8n/",
                "icon": "‚öôÔ∏è",
                "label": "Automate your data processing pipeline in 9 steps"
              },
              {
                "url": "https://n8n.io/blog/how-to-get-started-with-crm-automation-and-no-code-workflow-ideas/",
                "icon": "üë•",
                "label": "How to get started with CRM automation (with 3 no-code workflow ideas"
              },
              {
                "url": "https://n8n.io/blog/5-tasks-you-can-automate-with-notion-api/",
                "icon": "‚ö°Ô∏è",
                "label": "5 tasks you can automate with the new Notion API "
              },
              {
                "url": "https://n8n.io/blog/automate-google-apps-for-productivity/",
                "icon": "üí°",
                "label": "15 Google apps you can combine and automate to increase productivity"
              },
              {
                "url": "https://n8n.io/blog/how-uproc-scraped-a-multi-page-website-with-a-low-code-workflow/",
                "icon": " üï∏Ô∏è",
                "label": "How uProc scraped a multi-page website with a low-code workflow"
              },
              {
                "url": "https://n8n.io/blog/building-an-expense-tracking-app-in-10-minutes/",
                "icon": "üì±",
                "label": "Building an expense tracking app in 10 minutes"
              },
              {
                "url": "https://n8n.io/blog/the-ultimate-guide-to-automate-your-video-collaboration-with-whereby-mattermost-and-n8n/",
                "icon": "üìπ",
                "label": "The ultimate guide to automate your video collaboration with Whereby, Mattermost, and n8n"
              },
              {
                "url": "https://n8n.io/blog/5-workflow-automations-for-mattermost-that-we-love-at-n8n/",
                "icon": "ü§ñ",
                "label": "5 workflow automations for Mattermost that we love at n8n"
              },
              {
                "url": "https://n8n.io/blog/learn-to-build-powerful-api-endpoints-using-webhooks/",
                "icon": "üß∞",
                "label": "Learn to Build Powerful API Endpoints Using Webhooks"
              },
              {
                "url": "https://n8n.io/blog/how-a-membership-development-manager-automates-his-work-and-investments/",
                "icon": "üìà",
                "label": "How a Membership Development Manager automates his work and investments"
              },
              {
                "url": "https://n8n.io/blog/a-low-code-bitcoin-ticker-built-with-questdb-and-n8n-io/",
                "icon": "üìà",
                "label": "A low-code bitcoin ticker built with QuestDB and n8n.io"
              },
              {
                "url": "https://n8n.io/blog/how-to-set-up-a-ci-cd-pipeline-with-no-code/",
                "icon": "üé°",
                "label": "How to set up a no-code CI/CD pipeline with GitHub and TravisCI"
              },
              {
                "url": "https://n8n.io/blog/benefits-of-automation-and-n8n-an-interview-with-hubspots-hugh-durkin/",
                "icon": "üéñ",
                "label": "Benefits of automation and n8n: An interview with HubSpot's Hugh Durkin"
              },
              {
                "url": "https://n8n.io/blog/how-goomer-automated-their-operations-with-over-200-n8n-workflows/",
                "icon": "üõµ",
                "label": "How Goomer automated their operations with over 200 n8n workflows"
              },
              {
                "url": "https://n8n.io/blog/aws-workflow-automation/",
                "label": "7 no-code workflow automations for Amazon Web Services"
              }
            ],
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.set/"
              }
            ]
          },
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Data Transformation"
            ]
          }
        }
      },
      "group": "[\"input\"]",
      "defaults": {
        "name": "Modifier les champs"
      },
      "iconData": {
        "icon": "pen",
        "type": "icon"
      },
      "displayName": "Edit Fields (Set)",
      "typeVersion": 3,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 565,
      "icon": "fa:sticky-note",
      "name": "n8n-nodes-base.stickyNote",
      "codex": {
        "data": {
          "alias": [
            "Comments",
            "Notes",
            "Sticky"
          ],
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"input\"]",
      "defaults": {
        "name": "Note collante",
        "color": "#FFD233"
      },
      "iconData": {
        "icon": "sticky-note",
        "type": "icon"
      },
      "displayName": "Sticky Note",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Agent IA",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1141,
      "icon": "file:openAiLight.svg",
      "name": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsopenai/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Embeddings"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Embeddings OpenAI"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "Embeddings OpenAI",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1153,
      "icon": "file:openAiLight.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Mod√®le de chat OpenAI"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "OpenAI Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1179,
      "icon": "fa:code",
      "name": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "codex": {
        "data": {
          "alias": [
            "json",
            "zod"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Output Parsers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Analyseur de sortie structur√©"
      },
      "iconData": {
        "icon": "code",
        "type": "icon"
      },
      "displayName": "Structured Output Parser",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1191,
      "icon": "fa:grip-lines-vertical",
      "name": "@n8n/n8n-nodes-langchain.textSplitterRecursiveCharacterTextSplitter",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.textsplitterrecursivecharactertextsplitter/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Text Splitters"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Diviseur de texte de caract√®re r√©cursif"
      },
      "iconData": {
        "icon": "grip-lines-vertical",
        "type": "icon"
      },
      "displayName": "Recursive Character Text Splitter",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1243,
      "icon": "file:binary.svg",
      "name": "@n8n/n8n-nodes-langchain.documentDefaultDataLoader",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentdefaultdataloader/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Document Loaders"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Chargeur de donn√©es par d√©faut"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI3NjgiIGhlaWdodD0iMTAyNCI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTAgOTYwVjY0aDU3NmwxOTIgMTkydjcwNHptNzA0LTY0MEw1MTIgMTI4SDY0djc2OGg2NDB6TTMyMCA1MTJIMTI4VjI1NmgxOTJ6bS02NC0xOTJoLTY0djEyOGg2NHptMCA0NDhoNjR2NjRIMTI4di02NGg2NFY2NDBoLTY0di02NGgxMjh6bTI1Ni0zMjBoNjR2NjRIMzg0di02NGg2NFYzMjBoLTY0di02NGgxMjh6bTY0IDM4NEgzODRWNTc2aDE5MnptLTY0LTE5MmgtNjR2MTI4aDY0eiIvPjwvc3ZnPg=="
      },
      "displayName": "Default Data Loader",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1247,
      "icon": "fa:comments",
      "name": "@n8n/n8n-nodes-langchain.chatTrigger",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
              }
            ]
          },
          "categories": [
            "Core Nodes",
            "Langchain"
          ]
        }
      },
      "group": "[\"trigger\"]",
      "defaults": {
        "name": "Lorsque le message de chat est re√ßu"
      },
      "iconData": {
        "icon": "comments",
        "type": "icon"
      },
      "displayName": "Chat Trigger",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1248,
      "icon": "file:qdrant.svg",
      "name": "@n8n/n8n-nodes-langchain.vectorStoreQdrant",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreqdrant/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Vector Stores",
              "Tools",
              "Root Nodes"
            ],
            "Tools": [
              "Other Tools"
            ],
            "Vector Stores": [
              "Other Vector Stores"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Magasin vectoriel Qdrant"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "Qdrant Vector Store",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1305,
      "icon": "file:cohere.svg",
      "name": "@n8n/n8n-nodes-langchain.rerankerCohere",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.rerankercohere/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Rerankers"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Reranker Cohere"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAiIGhlaWdodD0iNDAiIHZpZXdCb3g9IjAgMCA0MCA0MCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xMi45NiAyMy44NEMxNC4wMjY3IDIzLjg0IDE2LjE2IDIzLjc4NjcgMTkuMTQ2NyAyMi41NkMyMi42MTMzIDIxLjEyIDI5LjQ0IDE4LjU2IDM0LjQgMTUuODkzM0MzNy44NjY3IDE0LjAyNjcgMzkuMzYgMTEuNTczMyAzOS4zNiA4LjI2NjY3QzM5LjM2IDMuNzMzMzMgMzUuNjggMCAzMS4wOTMzIDBIMTEuODkzM0M1LjMzMzMzIDAgMCA1LjMzMzMzIDAgMTEuODkzM0MwIDE4LjQ1MzMgNS4wMTMzMyAyMy44NCAxMi45NiAyMy44NFoiIGZpbGw9IiMzOTU5NEQiLz4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xNi4yMTM0IDMxLjk5OTlDMTYuMjEzNCAyOC43OTk5IDE4LjEzMzQgMjUuODY2NiAyMS4xMiAyNC42Mzk5TDI3LjE0NjcgMjIuMTMzM0MzMy4yOCAxOS42MjY2IDQwIDI0LjEwNjYgNDAgMzAuNzE5OUM0MCAzNS44Mzk5IDM1Ljg0IDM5Ljk5OTkgMzAuNzIgMzkuOTk5OUgyNC4xNkMxOS43ODY3IDM5Ljk5OTkgMTYuMjEzNCAzNi40MjY2IDE2LjIxMzQgMzEuOTk5OVoiIGZpbGw9IiNEMThFRTIiLz4KPHBhdGggZD0iTTYuODggMjUuMzg2N0MzLjA5MzMzIDI1LjM4NjcgMCAyOC40ODAxIDAgMzIuMjY2N1YzMy4xNzM0QzAgMzYuOTA2NyAzLjA5MzMzIDQwLjAwMDEgNi44OCA0MC4wMDAxQzEwLjY2NjcgNDAuMDAwMSAxMy43NiAzNi45MDY3IDEzLjc2IDMzLjEyMDFWMzIuMjEzNEMxMy43MDY3IDI4LjQ4MDEgMTAuNjY2NyAyNS4zODY3IDYuODggMjUuMzg2N1oiIGZpbGw9IiNGRjc3NTkiLz4KPC9zdmc+Cg=="
      },
      "displayName": "Reranker Cohere",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ],
  "categories": [
    {
      "id": 5,
      "name": "Ing√©nierie"
    },
    {
      "id": 48,
      "name": "IA RAG"
    }
  ],
  "image": []
}