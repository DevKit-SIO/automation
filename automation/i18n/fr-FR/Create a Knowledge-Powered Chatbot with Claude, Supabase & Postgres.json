{
  "id": 7381,
  "name": "Créer un chatbot alimenté par la connaissance avec Claude, Supabase et Postgres",
  "views": 180,
  "recentViews": 2,
  "totalViews": 180,
  "createdAt": "2025-08-14T12:20:23.845Z",
  "description": "# Chatbot intelligent avec base de connaissances personnalisée\n## Pour qui est-ce\nEntreprises, développeurs et organisations qui ont besoin d'un chatbot IA personnalisable pour l'accès à la documentation interne, le support client, l'assistance e-commerce, ou tout cas d'utilisation nécessitant une conversation intelligente avec accès à des bases de connaissances spécifiques.\n## Ce qu'il fait\nCe flux de travail crée un chatbot IA entièrement personnalisable qui peut être déployé sur n'importe quelle plateforme prenant en charge les déclencheurs webhook (sites web, Slack, Teams, etc.). Le chatbot accède à une base de connaissances personnalisée stockée dans Supabase et peut effectuer des actions avancées comme l'envoi d'emails, la planification de rendez-vous ou la mise à jour de bases de données au-delà d'une simple conversation.\n## Comment ça fonctionne\nLe flux de travail combine plusieurs composants puissants :\n\nDéclencheur Webhook : Accepte les messages de toute plateforme prenant en charge les webhooks\nAgent IA : Traite les requêtes des utilisateurs avec une personnalité et des instructions personnalisables\nBase de données vectorielle : Recherche des informations pertinentes dans votre base de connaissances Supabase\nSystème de mémoire : Maintient l'historique des conversations pour le contexte et la traçabilité\nOutils d'action : Effectue des tâches supplémentaires comme l'envoi d'emails ou la réservation de calendriers\n\n## Architecture technique\n\nLe déclencheur de chat se connecte directement à l'Agent IA\nLe modèle de langage, la mémoire et le magasin vectoriel se connectent tous comme outils/composants à l'Agent IA\nLes embeddings se connectent spécifiquement au Magasin Vectoriel Supabase pour la recherche de similarité\n\n## Exigences\n\nCompte et projet Supabase\nClé API du modèle IA (tout fournisseur LLM de votre choix)\nClé API OpenAI (pour les embeddings - cela est couvert dans le tutoriel de Cole Medin)\nAccès PostgreSQL intégré d'n8n (pour la mémoire de conversation)\nConfiguration de webhook spécifique à la plateforme (facultatif)\n\n## Comment configurer\n### Étape 1 : Configurez votre déclencheur\n\nLe modèle utilise le déclencheur de chat par défaut d'n8n\nPour les plateformes externes : Remplacez par un déclencheur webhook et configurez l'URL webhook de votre plateforme\nPlateformes prises en charge : Tout service avec des capacités de webhook (sites web, Slack, Teams, Discord, etc.)\n\n### Étape 2 : Configurez votre base de connaissances\nPour créer et gérer votre base de données vectorielle, suivez ce guide complet :\n\nRegardez le tutoriel de Cole Medin sur la vectorisation de documents\nCette vidéo montre comment construire une base de connaissances complète sur Supabase\nLe tutoriel couvre le traitement des documents, la création d'embeddings et l'optimisation de la base de données\nImportant : La vidéo explique la configuration des embeddings OpenAI requise pour la recherche vectorielle\n\n### Étape 3 : Configurez l'agent IA\n\nDéfinissez votre prompt : Personnalisez la personnalité et le rôle de l'agent\n\nExemple : \"Vous êtes l'assistant virtuel pour exemple.com. Aidez les utilisateurs en répondant à leurs questions sur nos produits et services.\"\n\n\nSélectionnez votre modèle de langage : Choisissez tout fournisseur IA que vous préférez (OpenAI, Anthropic, Google, etc.)\nDéfinissez les paramètres de comportement : Définissez le style de réponse, le ton et les limitations\n\n### Étape 4 : Connectez le Magasin Vectoriel Supabase\n\nAjoutez l'outil \"Magasin Vectoriel Supabase\" à votre agent\nConfigurez les identifiants de votre projet Supabase\nMode : Réglez sur \"retrieve-as-tool\" pour une intégration automatique de l'agent\nDescription de l'outil : Personnalisez la description (par défaut : \"Base de données\") pour décrire votre base de connaissances\nConfiguration de la table :\n\nSpécifiez la table contenant votre base de connaissances (l'exemple montre \"growth_ai_documents\")\nAssurez-vous que le nom de votre table correspond à la structure réelle de votre base de connaissances\nTables multiples : Vous pouvez connecter plusieurs tables pour une structure de données organisée\n\n\nL'agent décidera automatiquement quand rechercher dans la base de connaissances en fonction des requêtes des utilisateurs\n\n### Étape 5 : Configurez la mémoire de conversation (recommandé)\n\nUtilisez \"Mémoire de Chat Postgres\" avec les identifiants PostgreSQL intégrés d'n8n\nConfigurez le nom de la table : Choisissez un nom pour votre table d'historique de chat (sera auto-créée)\nLongueur de la fenêtre contextuelle : Réglez sur 20 messages par défaut (ajustable en fonction de vos besoins)\nAvantages :\n\nTraçabilité et analyses de conversation\nConservation du contexte à travers les messages\nIdentifiants de conversation uniques pour les sessions utilisateur\nStocké dans la base de données d'n8n, pas dans Supabase\n\n\n\n## Comment personnaliser le flux de travail\n### Fonctionnalités de conversation de base\n\nStyle de réponse : Modifiez les prompts pour changer la personnalité et le ton\nPortée des connaissances : Mettez à jour les tables Supabase pour étendre ou concentrer la base de connaissances\nSupport linguistique : Configurez pour plusieurs langues\nLongueur de réponse : Définissez des limites pour des réponses concises ou détaillées\nConservation de la mémoire : Ajustez la longueur de la fenêtre contextuelle pour une mémoire de conversation plus longue ou plus courte\n\n### Capacités d'action avancées\nLe chatbot peut être étendu avec des outils supplémentaires pour :\n\nAutomatisation des emails : Envoyez des emails de support lorsque les utilisateurs demandent de l'aide\nIntégration de calendrier : Réservez des rendez-vous directement dans Google Calendar\nMises à jour de base de données : Modifiez Airtable ou d'autres bases de données en fonction des interactions des utilisateurs\nIntégrations API : Connectez-vous à des services et systèmes externes\nGestion de fichiers : Traitez et analysez les documents téléchargés\n\n### Déploiements spécifiques à la plateforme\n#### Intégration de site web\n\nRemplacez le déclencheur de chat par un déclencheur webhook\nConfigurez le widget de chat de votre site web pour envoyer des messages à l'URL webhook d'n8n\nGérez le formatage des réponses pour votre interface de chat spécifique\n\n#### Déploiement Slack/Teams\n\nConfigurez le déclencheur webhook avec l'URL webhook Slack/Teams\nConfigurez le formatage des réponses pour les structures de messages spécifiques à la plateforme\nAjoutez des fonctionnalités spécifiques à la plateforme (mentions, canaux, etc.)\n\n#### Intégration e-commerce\n\nConnectez-vous aux bases de données de produits\nAjoutez des capacités de suivi des commandes\nIntégrez-vous aux systèmes de paiement\nConfigurez la création de tickets de support\n\n## Interprétation des résultats\n### Gestion de la conversation\n\nHistorique des chats : Toutes les conversations sont stockées dans la base de données PostgreSQL d'n8n avec des ID uniques\nSuivi du contexte : L'agent maintient le flux de conversation et fait référence aux messages précédents\nPotentiel d'analytique : Données historiques disponibles pour analyse et amélioration\n\n### Récupération des connaissances\n\nRecherche sémantique : La base de données vectorielle renvoie les informations les plus pertinentes en fonction du sens, pas seulement des mots-clés\nDécision automatique : L'agent détermine automatiquement quand rechercher dans la base de connaissances\nSuivi des sources : Capacité de retracer les réponses jusqu'aux documents sources\nAmélioration de la précision : Affinez continuellement la base de connaissances en fonction des requêtes des utilisateurs\n\n## Cas d'utilisation\n### Applications internes\n\nDocumentation pour développeurs : Accès rapide aux guides techniques et API\nSupport RH : Questions sur le manuel de l'employé et les politiques\nAssistance IT : Guides de dépannage et informations système\nAssistant de formation : Matériaux d'apprentissage et orientation des procédures\n\n### Service client externe\n\nSupport e-commerce : Informations sur les produits et assistance aux commandes\nSupport technique : Manuels d'utilisation et dépannage\nAssistance aux ventes : Recommandations de produits et tarification\nAutomatisation des FAQ : Questions courantes et réponses instantanées\n\n### Implémentations spécialisées\n\nQualification des leads : Rassembler des informations sur les clients et planifier des appels de vente\nRéservation de rendez-vous : Rendez-vous de santé, de conseil ou de service\nTraitement des commandes : Prendre des commandes et mettre à jour les systèmes d'inventaire\nSupport multilingue : Service client mondial avec détection de langue\n\n## Limitations du flux de travail\n\nDépendance à la base de connaissances : La qualité dépend de la documentation source et de la configuration des embeddings\nStockage de mémoire : Nécessite une connexion PostgreSQL active d'n8n pour l'historique des conversations\nRestrictions de plateforme : Certaines plateformes peuvent avoir des limitations de webhook\nTemps de réponse : La recherche vectorielle peut ajouter un léger délai aux réponses\nLimites de jetons : De grandes fenêtres contextuelles peuvent augmenter les coûts API\nCoûts d'embedding : Les embeddings OpenAI sont requis pour la fonctionnalité de recherche vectorielle",
  "workflow": {
    "meta": {
      "instanceId": "393ca9e36a1f81b0f643c72792946a5fe5e49eb4864181ba4032e5a408278263",
      "templateCredsSetupCompleted": true
    },
    "nodes": [
      {
        "id": "480327a5-b4d1-4b33-a916-b3e8e00e0a01",
        "name": "AI Agent",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "position": [
          320,
          -16
        ],
        "parameters": {
          "options": {
            "systemMessage": "You are a helpful assistant"
          }
        },
        "typeVersion": 2.2
      },
      {
        "id": "67ee572c-648c-42aa-a87b-f54a427676e8",
        "name": "Anthropic Chat Model",
        "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
        "position": [
          -48,
          736
        ],
        "parameters": {
          "model": {
            "__rl": true,
            "mode": "list",
            "value": "claude-sonnet-4-20250514",
            "cachedResultName": "Claude 4 Sonnet"
          },
          "options": {}
        },
        "credentials": {
          "anthropicApi": {
            "id": "WXQf5QsxCs3AyxlW",
            "name": "Anthropic account"
          }
        },
        "typeVersion": 1.3
      },
      {
        "id": "8f42d1b6-bb2a-4413-a067-b029af99c30e",
        "name": "Postgres Chat Memory",
        "type": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
        "position": [
          608,
          736
        ],
        "parameters": {},
        "credentials": {
          "postgres": {
            "id": "Bs4YHHIz76Yg6LAA",
            "name": "Postgres account - Sigma"
          }
        },
        "typeVersion": 1.3
      },
      {
        "id": "af4b62d7-e68d-48f6-95a1-476f22c0c8a2",
        "name": "Supabase Vector Store",
        "type": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
        "position": [
          1056,
          256
        ],
        "parameters": {
          "mode": "retrieve-as-tool",
          "options": {},
          "tableName": {
            "__rl": true,
            "mode": "id",
            "value": "=Your_database"
          },
          "toolDescription": "Data base"
        },
        "credentials": {
          "supabaseApi": {
            "id": "H0kInY9i7zSLf3eu",
            "name": "IDR"
          }
        },
        "typeVersion": 1.3
      },
      {
        "id": "c4adc458-83dd-4fdd-a90b-afd7f64b4e14",
        "name": "Embeddings OpenAI",
        "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
        "position": [
          1680,
          288
        ],
        "parameters": {
          "options": {}
        },
        "credentials": {
          "openAiApi": {
            "id": "Wk5dyBYFy6HDwml2",
            "name": "OpenAi account"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "057a14db-e155-4612-ba4d-2bca36615613",
        "name": "Sticky Note",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -560,
          -96
        ],
        "parameters": {
          "width": 480,
          "height": 224,
          "content": "# Chat trigger"
        },
        "typeVersion": 1
      },
      {
        "id": "437859f1-984a-43e0-9793-ea36aa901b3e",
        "name": "Chat trigger",
        "type": "@n8n/n8n-nodes-langchain.chatTrigger",
        "position": [
          -384,
          -16
        ],
        "webhookId": "9ce2709c-faa0-4977-a3ce-5e9adb6d62f1",
        "parameters": {
          "options": {}
        },
        "typeVersion": 1.3
      },
      {
        "id": "dfc9591e-58df-4434-9d58-5e3aac5c5dda",
        "name": "Sticky Note1",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -560,
          160
        ],
        "parameters": {
          "width": 480,
          "height": 352,
          "content": "### Role: Entry point for all user interactions\n\n### Function:\n\nReceives incoming messages from users via webhook\nInitiates the conversation flow for each user query\nHandles multiple concurrent conversations simultaneously\nProvides secure endpoint for chat interface integration\n\n### What you need to configure:\n\nSet up the webhook URL in your chat interface\nEnsure proper security settings for public access\nConfigure any rate limiting if needed"
        },
        "typeVersion": 1
      },
      {
        "id": "21aa7507-a959-4f3d-8c18-7bd93d2fa9c6",
        "name": "Sticky Note2",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          160,
          -96
        ],
        "parameters": {
          "color": 2,
          "width": 480,
          "height": 224,
          "content": "# AI Agent"
        },
        "typeVersion": 1
      },
      {
        "id": "de90b230-1d56-431d-ba35-220052cd7ffe",
        "name": "Sticky Note3",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          160,
          160
        ],
        "parameters": {
          "color": 2,
          "width": 480,
          "height": 384,
          "content": "### Role: Central orchestrator and conversation manager\n\n### Function:\n\nCoordinates all system components to generate responses\nManages the conversation flow and context switching\nDecides when to use tools like the knowledge base search\nIntegrates multiple AI capabilities into coherent responses\nMaintains conversation coherence across multiple exchanges\n\n### Critical success factors:\n\nWrite a comprehensive system prompt that defines the agent's personality, expertise, and behavior\nDefine clear instructions for when and how to use available tools\nEstablish conversation boundaries and appropriate response styles\nInclude specific domain knowledge and response guidelines\n\n"
        },
        "typeVersion": 1
      },
      {
        "id": "05c58432-7c3f-4cf4-a08b-5bb71335450b",
        "name": "Sticky Note4",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -240,
          656
        ],
        "parameters": {
          "color": 3,
          "width": 480,
          "height": 224,
          "content": "# Anthropic Chat Model"
        },
        "typeVersion": 1
      },
      {
        "id": "db58fda4-7c44-4938-bbc7-e298680a0276",
        "name": "Sticky Note5",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -240,
          912
        ],
        "parameters": {
          "color": 3,
          "width": 480,
          "height": 416,
          "content": "### Role: Primary language processing engine\n\n### Function:\n\nGenerates human-like responses with advanced reasoning capabilities\nUnderstands context and nuance in user queries\nProvides high-quality text generation for complex topics\nHandles multi-turn conversations with sophisticated understanding\nProcesses complex instructions and maintains consistent personality\n\n### Why this model:\n\nSuperior reasoning and analysis capabilities\nExcellent context retention across long conversations\nStrong performance with technical and professional content\nReliable safety and alignment features\n\n"
        },
        "typeVersion": 1
      },
      {
        "id": "15fef62a-870d-4f9c-8b22-8a8a643e5b2d",
        "name": "Sticky Note6",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          400,
          656
        ],
        "parameters": {
          "color": 4,
          "width": 480,
          "height": 224,
          "content": "# Postgres Chat Memory"
        },
        "typeVersion": 1
      },
      {
        "id": "4ad56b77-386c-4889-ae85-d08a35f0b292",
        "name": "Sticky Note7",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          400,
          912
        ],
        "parameters": {
          "color": 4,
          "width": 480,
          "height": 416,
          "content": "### Role: Conversation history and context retention\n\n### Function:\n\nStores conversation history for each user session\nMaintains context across multiple interactions\nEnables personalized responses based on previous conversations\nProvides continuity in long-form discussions\nHandles user preferences and conversation state\n\n### Setup requirements:\n\nConfigure PostgreSQL database connection\nEnsure proper table structure for conversation storage\nSet up appropriate retention policies for data management\nImplement user session management"
        },
        "typeVersion": 1
      },
      {
        "id": "83d9952b-0754-46a9-bbb5-f127927b8d36",
        "name": "Sticky Note8",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          944,
          192
        ],
        "parameters": {
          "color": 5,
          "width": 480,
          "height": 224,
          "content": "# Supabase Vector Store"
        },
        "typeVersion": 1
      },
      {
        "id": "e6bc04eb-0ae6-4d5d-8910-8e384f101dcc",
        "name": "Sticky Note9",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          944,
          448
        ],
        "parameters": {
          "color": 5,
          "width": 480,
          "height": 448,
          "content": "### Role: Knowledge base and intelligent document retrieval\n\n### Function:\n\nStores your proprietary knowledge in searchable vector format\nPerforms semantic search to find relevant information\nRetrieves contextually appropriate documents and data\nEnables RAG (Retrieval Augmented Generation) capabilities\nProvides tool functionality for the AI agent to access knowledge\n\n### Critical success factors:\n\nCurate high-quality source documents that are comprehensive and accurate\nOrganize content logically with clear structure and formatting\nInclude diverse content types covering your domain expertise\nRegularly update the knowledge base with new information\nEnsure document quality - well-written, factual, and relevant content\nUse descriptive metadata to improve search accuracy\n\n"
        },
        "typeVersion": 1
      },
      {
        "id": "f8788f28-5a17-4190-98db-f704401bed00",
        "name": "Sticky Note10",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          1472,
          192
        ],
        "parameters": {
          "color": 6,
          "width": 480,
          "height": 224,
          "content": "# OpenAI Embeddings"
        },
        "typeVersion": 1
      },
      {
        "id": "3e4bcf71-9884-4e2f-9dfe-c9fb4afa9191",
        "name": "Sticky Note11",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          1472,
          448
        ],
        "parameters": {
          "color": 6,
          "width": 480,
          "height": 448,
          "content": "### Role: Text vectorization engine for knowledge search\n\n### Function:\n\nConverts text into numerical vectors for semantic search\nEnables similarity matching between user queries and knowledge base\nPowers the search functionality of the vector store\nProvides consistent encoding for both queries and stored documents\n\n### Technical considerations:\n\nUses OpenAI's embedding model for high-quality vector representations\nHandles multiple languages effectively\nProvides stable and consistent embeddings for reliable search\n\n"
        },
        "typeVersion": 1
      },
      {
        "id": "feae8c69-ea1e-4f39-879b-43f32b928663",
        "name": "Sticky Note12",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -1760,
          -192
        ],
        "parameters": {
          "color": 7,
          "width": 992,
          "height": 1728,
          "content": "# System Prompt Development\nEssential elements for the AI Agent:\n\nDefine the agent's role and expertise area clearly\nEstablish personality and communication style\nSet behavioral guidelines for professional interactions\nSpecify when to use the knowledge base tool\nInclude fallback instructions for unknown topics\nDefine response formatting and structure preferences\n\n## Example structure:\nYou are an expert [domain] consultant with [X years] experience.\nYour role is to provide accurate, helpful information about [topic area].\n\n## Guidelines:\n- Always search the knowledge base before providing detailed answers\n- Maintain a professional but approachable tone\n- If information isn't in the knowledge base, clearly state this\n- Provide specific, actionable advice when possible\n\n### Knowledge Base Optimization\nContent preparation:\n\nStructure documents with clear headings and sections\nInclude comprehensive coverage of your domain topics\nUse consistent terminology throughout all documents\nAdd context and examples to improve understanding\nUpdate regularly with new insights and information\n\n## Document types to include:\n\nProduct or service documentation\nFAQ responses and common questions\nIndustry best practices and guidelines\nCase studies and examples\nTechnical specifications and procedures\n\n### Conversation Management\nMemory optimization:\n\nConfigure appropriate session lengths\nSet up user identification for personalized experiences\nImplement conversation reset capabilities\nMonitor conversation quality and adjust prompts accordingly\n\n## Expected User Experience\n### What users can do:\n\nAsk questions about your domain expertise\nGet personalized responses based on conversation history\nAccess your knowledge base through natural language queries\nHave multi-turn conversations with context retention\nReceive accurate information backed by your curated content\n\n### What the system provides:\n✅ Intelligent responses powered by advanced AI\n✅ Access to your proprietary knowledge base\n✅ Conversation memory and personalization\n✅ Professional, consistent communication style\n✅ Reliable information retrieval and synthesis\n✅ Scalable support for multiple concurrent users\n## Success Metrics and Optimization\nMonitor these key indicators:\n\nResponse accuracy and relevance\nUser satisfaction with answers\nKnowledge base search effectiveness\nConversation completion rates\nSystem response times\n\nContinuous improvement strategies:\n\nRegularly review conversation logs\nUpdate system prompts based on user interactions\nExpand knowledge base with frequently asked topics\nOptimize vector search performance\nRefine agent instructions for better tool usage\n"
        },
        "typeVersion": 1
      }
    ],
    "pinData": {},
    "connections": {
      "Chat trigger": {
        "main": [
          [
            {
              "node": "AI Agent",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Embeddings OpenAI": {
        "ai_embedding": [
          [
            {
              "node": "Supabase Vector Store",
              "type": "ai_embedding",
              "index": 0
            }
          ]
        ]
      },
      "Anthropic Chat Model": {
        "ai_languageModel": [
          [
            {
              "node": "AI Agent",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "Postgres Chat Memory": {
        "ai_memory": [
          [
            {
              "node": "AI Agent",
              "type": "ai_memory",
              "index": 0
            }
          ]
        ]
      },
      "Supabase Vector Store": {
        "ai_tool": [
          [
            {
              "node": "AI Agent",
              "type": "ai_tool",
              "index": 0
            }
          ]
        ]
      }
    }
  },
  "lastUpdatedBy": 29,
  "workflowInfo": {
    "nodeCount": 19,
    "nodeTypes": {
      "n8n-nodes-base.stickyNote": {
        "count": 13
      },
      "@n8n/n8n-nodes-langchain.agent": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.chatTrigger": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.lmChatAnthropic": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.embeddingsOpenAi": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.memoryPostgresChat": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.vectorStoreSupabase": {
        "count": 1
      }
    }
  },
  "user": {
    "name": "Growth AI",
    "username": "growthai",
    "bio": "",
    "verified": true,
    "links": [
      "https://www.agence-n8n.com/"
    ],
    "avatar": "https://gravatar.com/avatar/e93e43e1e71be1aee89eb849a5396be04c95604624b155a29298b9209e2534c3?r=pg&d=retro&size=200"
  },
  "nodes": [
    {
      "id": 565,
      "icon": "fa:sticky-note",
      "name": "n8n-nodes-base.stickyNote",
      "codex": {
        "data": {
          "alias": [
            "Comments",
            "Notes",
            "Sticky"
          ],
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"input\"]",
      "defaults": {
        "name": "Note autocollante",
        "color": "#FFD233"
      },
      "iconData": {
        "icon": "sticky-note",
        "type": "icon"
      },
      "displayName": "Sticky Note",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Agent IA",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1141,
      "icon": "file:openAiLight.svg",
      "name": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.embeddingsopenai/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Embeddings"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Embeddings OpenAI"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "Embeddings OpenAI",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1145,
      "icon": "file:anthropic.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "codex": {
        "data": {
          "alias": [
            "claude",
            "sonnet",
            "opus"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatanthropic/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Modèle de chat Anthropic"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0NiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iIzdEN0Q4NyIgZD0iTTMyLjczIDBoLTYuOTQ1TDM4LjQ1IDMyaDYuOTQ1ek0xMi42NjUgMCAwIDMyaDcuMDgybDIuNTktNi43MmgxMy4yNWwyLjU5IDYuNzJoNy4wODJMMTkuOTI5IDB6bS0uNzAyIDE5LjMzNyA0LjMzNC0xMS4yNDYgNC4zMzQgMTEuMjQ2eiIvPjwvc3ZnPg=="
      },
      "displayName": "Anthropic Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1231,
      "icon": "file:supabase.svg",
      "name": "@n8n/n8n-nodes-langchain.vectorStoreSupabase",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoresupabase/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Vector Stores",
              "Tools",
              "Root Nodes"
            ],
            "Tools": [
              "Other Tools"
            ],
            "Vector Stores": [
              "Other Vector Stores"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Magasin Vectoriel Supabase"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMDkiIGhlaWdodD0iMTEzIiBmaWxsPSJub25lIj48cGF0aCBmaWxsPSJ1cmwoI2EpIiBkPSJNNjMuNzA4IDExMC4yODRjLTIuODYgMy42MDEtOC42NTggMS42MjgtOC43MjctMi45N2wtMS4wMDctNjcuMjUxaDQ1LjIyYzguMTkgMCAxMi43NTggOS40NiA3LjY2NSAxNS44NzR6Ii8+PHBhdGggZmlsbD0idXJsKCNiKSIgZmlsbC1vcGFjaXR5PSIuMiIgZD0iTTYzLjcwOCAxMTAuMjg0Yy0yLjg2IDMuNjAxLTguNjU4IDEuNjI4LTguNzI3LTIuOTdsLTEuMDA3LTY3LjI1MWg0NS4yMmM4LjE5IDAgMTIuNzU4IDkuNDYgNy42NjUgMTUuODc0eiIvPjxwYXRoIGZpbGw9IiMzRUNGOEUiIGQ9Ik00NS4zMTcgMi4wNzFjMi44Ni0zLjYwMSA4LjY1Ny0xLjYyOCA4LjcyNiAyLjk3bC40NDIgNjcuMjUxSDkuODNjLTguMTkgMC0xMi43NTktOS40Ni03LjY2NS0xNS44NzV6Ii8+PGRlZnM+PGxpbmVhckdyYWRpZW50IGlkPSJhIiB4MT0iNTMuOTc0IiB4Mj0iOTQuMTYzIiB5MT0iNTQuOTc0IiB5Mj0iNzEuODI5IiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSI+PHN0b3Agc3RvcC1jb2xvcj0iIzI0OTM2MSIvPjxzdG9wIG9mZnNldD0iMSIgc3RvcC1jb2xvcj0iIzNFQ0Y4RSIvPjwvbGluZWFyR3JhZGllbnQ+PGxpbmVhckdyYWRpZW50IGlkPSJiIiB4MT0iMzYuMTU2IiB4Mj0iNTQuNDg0IiB5MT0iMzAuNTc4IiB5Mj0iNjUuMDgxIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSI+PHN0b3AvPjxzdG9wIG9mZnNldD0iMSIgc3RvcC1vcGFjaXR5PSIwIi8+PC9saW5lYXJHcmFkaWVudD48L2RlZnM+PC9zdmc+"
      },
      "displayName": "Supabase Vector Store",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1247,
      "icon": "fa:comments",
      "name": "@n8n/n8n-nodes-langchain.chatTrigger",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
              }
            ]
          },
          "categories": [
            "Core Nodes",
            "Langchain"
          ]
        }
      },
      "group": "[\"trigger\"]",
      "defaults": {
        "name": "Lorsque le message de chat est reçu"
      },
      "iconData": {
        "icon": "comments",
        "type": "icon"
      },
      "displayName": "Chat Trigger",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1267,
      "icon": "file:postgres.svg",
      "name": "@n8n/n8n-nodes-langchain.memoryPostgresChat",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorypostgreschat/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Memory"
            ],
            "Memory": [
              "Other memories"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Mémoire de chat Postgres"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" fill="#fff" fill-rule="evenodd" stroke="#000" stroke-linecap="round" stroke-linejoin="round" viewBox="0 0 79 81"><use xlink:href="#a" x=".5" y=".5"/><symbol id="a" overflow="visible"><g fill-rule="nonzero" stroke="none"><path fill="#000" d="M77.391 47.922c-.466-1.412-1.688-2.396-3.268-2.632-.745-.111-1.598-.064-2.608.144-1.76.363-3.065.501-4.018.528 3.596-6.072 6.521-12.997 8.204-19.515 2.722-10.54 1.268-15.341-.432-17.513C70.77 3.185 64.206.097 56.287.002c-4.224-.052-7.933.782-9.867 1.382a37 37 0 0 0-5.77-.528c-3.809-.061-7.174.77-10.05 2.476a46 46 0 0 0-7.098-1.782C16.561.411 10.968 1.299 6.876 4.19 1.922 7.689-.375 13.77.05 22.262c.135 2.696 1.643 10.9 4.018 18.68 1.365 4.472 2.82 8.185 4.326 11.038 2.135 4.046 4.419 6.428 6.984 7.284 1.438.479 4.049.814 6.797-1.473a6 6 0 0 0 1.429 1.23c.783.494 1.74.897 2.696 1.136 3.446.862 6.674.646 9.427-.561l.041 1.362.06 1.899c.163 4.064.44 7.223 1.259 9.434.045.122.105.307.169.503.409 1.251 1.092 3.346 2.83 4.987 1.8 1.699 3.978 2.22 5.972 2.22 1 0 1.955-.131 2.792-.311 2.984-.639 6.373-1.614 8.824-5.104 2.318-3.3 3.444-8.27 3.648-16.101l.074-.634.048-.414.546.048.141.01c3.039.138 6.755-.506 9.037-1.566 1.803-.837 7.582-3.888 6.221-8.007"/><path fill="#336791" d="M72.195 48.723c-9.036 1.864-9.657-1.195-9.657-1.195 9.541-14.157 13.529-32.127 10.087-36.525C63.235-.994 46.981 4.68 46.71 4.827l-.087.016c-1.785-.371-3.783-.591-6.029-.628-4.089-.067-7.19 1.072-9.544 2.857 0 0-28.995-11.945-27.647 15.023.287 5.737 8.223 43.41 17.689 32.031 3.46-4.161 6.803-7.679 6.803-7.679 1.66 1.103 3.648 1.666 5.732 1.463l.162-.137a6.3 6.3 0 0 0 .065 1.62c-2.439 2.725-1.722 3.203-6.597 4.206-4.933 1.017-2.035 2.826-.143 3.299 2.294.574 7.6 1.386 11.185-3.633l-.143.573c.956.765 1.626 4.978 1.514 8.797s-.188 6.441.565 8.489 1.503 6.656 7.912 5.282c5.355-1.148 8.13-4.121 8.516-9.081.274-3.526.894-3.005.933-6.158l.497-1.493c.573-4.78.091-6.322 3.39-5.605l.802.07c2.428.11 5.606-.391 7.471-1.257 4.016-1.864 6.398-4.976 2.438-4.158"/><path d="M32.747 24.66c-.814-.113-1.552-.008-1.925.274a.7.7 0 0 0-.292.47c-.047.336.188.707.333.898.409.542 1.006.915 1.598.997a2 2 0 0 0 .256.018c.986 0 1.883-.768 1.962-1.335.099-.71-.932-1.183-1.931-1.322m26.975.022c-.078-.556-1.068-.715-2.007-.584s-1.848.554-1.772 1.112c.061.434.844 1.174 1.771 1.174q.117 0 .237-.016c.619-.086 1.073-.479 1.288-.705.329-.345.518-.73.484-.98m15.477 23.828c-.345-1.042-1.453-1.377-3.296-.997-5.471 1.129-7.43.347-8.073-.127 4.252-6.478 7.75-14.308 9.637-21.614.894-3.461 1.388-6.675 1.428-9.294.045-2.876-.445-4.988-1.455-6.279-4.072-5.203-10.048-7.994-17.283-8.07-4.973-.056-9.175 1.217-9.99 1.575a25 25 0 0 0-5.622-.722c-3.734-.06-6.961.834-9.633 2.655a43 43 0 0 0-7.828-2.052c-6.342-1.021-11.381-.248-14.978 2.3-4.291 3.04-6.272 8.475-5.888 16.152.129 2.583 1.601 10.529 3.923 18.139 3.057 10.016 6.38 15.686 9.877 16.852a4.4 4.4 0 0 0 1.402.232c1.276 0 2.839-.575 4.466-2.531a161 161 0 0 1 6.156-6.966 9.9 9.9 0 0 0 4.429 1.191l.01.121c-.31.368-.564.69-.781.965-1.07 1.358-1.293 1.641-4.738 2.351-.98.202-3.582.738-3.62 2.563-.041 1.993 3.076 2.83 3.431 2.919 1.238.31 2.43.463 3.568.463 2.766 0 5.2-.909 7.145-2.668-.06 7.106.236 14.107 1.089 16.241.699 1.746 2.406 6.014 7.798 6.014.791 0 1.662-.092 2.62-.297 5.627-1.207 8.071-3.694 9.016-9.177.506-2.93 1.374-9.928 1.782-13.682.862.269 1.971.392 3.17.392 2.501 0 5.387-.531 7.197-1.372 2.033-.944 5.702-3.261 5.037-5.274zM61.8 23.147c-.019 1.108-.171 2.114-.333 3.164-.174 1.129-.354 2.297-.399 3.715-.045 1.379.128 2.814.294 4.2.337 2.801.682 5.685-.655 8.531a11 11 0 0 1-.592-1.218c-.166-.403-.527-1.05-1.027-1.946-1.944-3.487-6.497-11.652-4.167-14.984.694-.992 2.456-2.011 6.879-1.463zM56.439 4.374c6.482.143 11.609 2.568 15.24 7.207 2.784 3.558-.282 19.749-9.158 33.716l-.269-.339-.112-.14c2.294-3.788 1.845-7.536 1.446-10.859-.164-1.364-.319-2.652-.28-3.861.041-1.283.21-2.382.374-3.446.202-1.311.407-2.667.35-4.265a1.8 1.8 0 0 0 .037-.601c-.144-1.533-1.894-6.12-5.462-10.273-1.951-2.271-4.797-4.813-8.682-6.527a29.3 29.3 0 0 1 6.515-.612zM20.167 53.298c-1.793 2.155-3.031 1.742-3.438 1.607-2.653-.885-5.73-6.491-8.444-15.382-2.348-7.693-3.72-15.428-3.829-17.597-.343-6.86 1.32-11.641 4.943-14.21 5.896-4.181 15.589-1.679 19.484-.409l-.17.163c-6.391 6.455-6.24 17.483-6.224 18.157a22 22 0 0 0 .051 1.135c.11 1.855.315 5.307-.232 9.217-.508 3.633.612 7.189 3.072 9.756q.383.398.795.75a164 164 0 0 0-6.008 6.814zm6.83-9.113c-1.983-2.069-2.884-4.947-2.471-7.896.577-4.13.364-7.727.25-9.659l-.039-.694c.934-.828 5.261-3.146 8.346-2.439 1.408.323 2.266 1.281 2.623 2.931 1.846 8.539.244 12.098-1.043 14.957-.265.589-.516 1.146-.73 1.722l-.166.445c-.42 1.126-.811 2.173-1.053 3.167-2.108-.006-4.159-.907-5.718-2.534zm.324 11.516a5 5 0 0 1-1.494-.642c.271-.128.754-.301 1.591-.474 4.052-.834 4.678-1.423 6.045-3.158.313-.398.669-.849 1.16-1.398.733-.821 1.068-.682 1.676-.43.493.204.972.821 1.167 1.501.092.321.195.93-.143 1.404-2.855 3.997-7.015 3.946-10.003 3.198zm21.207 19.735c-4.957 1.062-6.713-1.467-7.869-4.359-.747-1.867-1.113-10.285-.853-19.582a1.1 1.1 0 0 0-.048-.356 5 5 0 0 0-.139-.657c-.387-1.353-1.331-2.484-2.462-2.953-.45-.186-1.275-.528-2.267-.274.212-.871.578-1.855.976-2.921l.167-.448c.188-.505.423-1.029.673-1.583 1.347-2.992 3.192-7.091 1.19-16.35-.75-3.468-3.254-5.161-7.05-4.768-2.276.235-4.358 1.154-5.396 1.68q-.334.169-.618.329c.29-3.494 1.385-10.024 5.481-14.156 2.579-2.601 6.014-3.886 10.199-3.817 8.246.135 13.534 4.367 16.518 7.893 2.571 3.039 3.964 6.1 4.52 7.751-4.179-.425-7.022.4-8.463 2.46-3.135 4.481 1.715 13.178 4.046 17.358.427.766.796 1.428.912 1.709.759 1.839 1.742 3.067 2.459 3.964.22.275.433.541.596.774-1.266.365-3.539 1.208-3.332 5.422-.167 2.115-1.356 12.016-1.959 15.514-.797 4.621-2.497 6.343-7.279 7.368zm20.693-23.68c-1.294.601-3.46 1.052-5.518 1.148-2.273.107-3.43-.255-3.702-.477-.128-2.626.85-2.901 1.884-3.191.163-.046.321-.09.474-.144a4 4 0 0 0 .313.23c1.827 1.206 5.085 1.336 9.685.386l.05-.01c-.62.58-1.682 1.359-3.187 2.058z"/></g></symbol></svg>"
      },
      "displayName": "Postgres Chat Memory",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ],
  "categories": [
    {
      "id": 40,
      "name": "Chatbot de support"
    },
    {
      "id": 51,
      "name": "IA multimodale"
    }
  ],
  "image": []
}