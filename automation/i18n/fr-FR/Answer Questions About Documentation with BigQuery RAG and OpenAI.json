{
  "id": 8220,
  "name": "Répondre aux questions sur la documentation avec BigQuery RAG et OpenAI",
  "views": 100,
  "recentViews": 4,
  "totalViews": 100,
  "createdAt": "2025-09-03T14:07:49.001Z",
  "description": "# BigQuery RAG avec OpenAI Embeddings\n\nCe flux de travail démontre comment utiliser **Retrieval-Augmented Generation (RAG)** avec **BigQuery** et **OpenAI**.  \nPar défaut, vous ne pouvez pas utiliser directement les modèles Cloud d'OpenAI dans BigQuery.\n\n### Essayez-le\n\n*Ce modèle est livré avec un accès à une **table BigQuery publique** qui stocke une partie de la documentation n8n (concernant les nœuds et les déclencheurs), vous permettant d'essayer le flux de travail immédiatement :  \n[`n8n-docs-rag.n8n_docs.n8n_docs_embeddings`](https://console.cloud.google.com/bigquery?ws=!1m5!1m4!4m3!1sn8n-docs-rag!2sn8n_docs!3sn8n_docs_embeddings)*\n\n*⚠️ **Important :** BigQuery utilise le modèle *requester pays*.*\n*La table est petite (~40 Mo), et BigQuery fournit **1 To de traitement gratuit par mois**. Exécuter 3 à 4 requêtes pour des tests devrait rester dans la limite gratuite, à moins que votre projet ait déjà consommé son quota.  \nPlus d'infos ici : [Tarification BigQuery](https://cloud.google.com/bigquery/pricing?hl=fr)*\n\n\n## Pourquoi ce flux de travail ?\n\nDe nombreuses organisations utilisent déjà BigQuery pour stocker des données d'entreprise et OpenAI pour des cas d'utilisation de LLM.  \nEn ce qui concerne RAG, l'approche courante consiste à s'appuyer sur des bases de données vectorielles dédiées telles que **Qdrant**, **Pinecone**, **Weaviate**, ou PostgreSQL avec **pgvector**.  \nCe sont de bons choix, mais dans les cas où une organisation utilise déjà et est familière avec BigQuery, il peut être plus efficace de tirer parti de ses capacités vectorielles intégrées pour RAG.\n\nPuis vient la question du LLM. Si OpenAI est le fournisseur choisi, les équipes sont souvent frustrées qu'il ne soit pas directement compatible avec BigQuery.  \nCe flux de travail résout cette limitation.\n\n## Prérequis\n\nPour utiliser ce flux de travail, vous aurez besoin de :\n* Une bonne compréhension de BigQuery et de ses capacités vectorielles  \n* Une table BigQuery contenant des documents et une colonne d'embeddings  \n  * La colonne d'embeddings doit être de type **FLOAT** et de mode **REPEATED** (pour stocker des tableaux)  \n* Un pipeline de données qui **génère des embeddings avec l'API OpenAI** et les stocke dans BigQuery\n\nCe modèle est livré avec une table publique qui stocke une partie de la **documentation n8n** (concernant les nœuds et les déclencheurs), afin que vous puissiez l'essayer :  \n`n8n-docs-rag.n8n_docs.n8n_docs_embeddings`\n\n## Comment ça fonctionne\n\nLe système se compose de deux flux de travail :\n* **Flux de travail principal** → Héberge l'Agent IA, qui se connecte à un sous-flux de travail pour RAG  \n* **Sous-flux de travail** → Interroge la table vectorielle BigQuery. Les documents récupérés sont ensuite utilisés par l'Agent IA pour générer une réponse pour l'utilisateur.\n\n\n",
  "workflow": {
    "id": "",
    "meta": {
      "instanceId": ""
    },
    "name": "BigQuery RAG With OpenAI Embedding",
    "tags": [],
    "nodes": [
      {
        "id": "69f19613-1e74-43dc-9f2e-c95c2db385e3",
        "name": "AI Agent",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "position": [
          -960,
          64
        ],
        "parameters": {
          "options": {
            "systemMessage": "You are an assistant specialized in answering questions about **n8n**.  \nUse the connected vector store to retrieve relevant documentation and generate clear, structured, and helpful answers.\n\n## Instructions\n\n1. **Document Retrieval**  \n   - Query the connected vector store to gather information from the n8n documentation.  \n   - Base every answer on the retrieved content.  \n\n2. **Answer Formatting**  \n   - Write all answers in **Markdown**.  \n   - Structure responses with clear sections, bullet points, or lists when useful.  \n   - Provide direct excerpts or explanations from the retrieved documents.  \n\n3. **Images**  \n   - Include screenshots from the documentation when they provide value to the user.  \n   - Use Markdown syntax for images.  \n   - Focus on images that illustrate functionality or clarify instructions.  \n\n4. **Code**  \n   - Present code snippets as **Markdown code blocks**.  \n   - Preserve the original content of the snippet.  \n   - Add language hints when available (e.g., ` ```javascript `).  \n\n5. **Completeness**  \n   - Provide accurate, context-aware answers.  \n   - Indicate clearly when the retrieved documents do not contain enough information. "
          }
        },
        "typeVersion": 2.2
      },
      {
        "id": "e198291b-f8b0-455e-8c40-bf5a9cadef70",
        "name": "When chat message received",
        "type": "@n8n/n8n-nodes-langchain.chatTrigger",
        "position": [
          -1408,
          64
        ],
        "webhookId": "dc7d2421-f489-4eea-b3fb-6b69ede9beed",
        "parameters": {
          "options": {}
        },
        "typeVersion": 1.3
      },
      {
        "id": "53c039bc-4788-49f3-afc8-354498da9e44",
        "name": "OpenAI Chat Model",
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "position": [
          -1152,
          400
        ],
        "parameters": {
          "model": {
            "__rl": true,
            "mode": "list",
            "value": "gpt-4.1-mini",
            "cachedResultName": "gpt-4.1-mini"
          },
          "options": {}
        },
        "credentials": {
          "openAiApi": {
            "id": "",
            "name": "OpenAi Account"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "e9a99d6d-e191-4ecf-a271-1a9ebb07e02a",
        "name": "Simple Memory",
        "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "position": [
          -848,
          400
        ],
        "parameters": {},
        "typeVersion": 1.3
      },
      {
        "id": "8acb8e42-c6e3-4254-a53d-077bbf9f4065",
        "name": "When Executed by Another Workflow",
        "type": "n8n-nodes-base.executeWorkflowTrigger",
        "position": [
          -1488,
          1264
        ],
        "parameters": {
          "workflowInputs": {
            "values": [
              {
                "name": "vector_search_question"
              }
            ]
          }
        },
        "typeVersion": 1.1
      },
      {
        "id": "c97a255c-3328-4837-bf45-7a3f5cc7c5b7",
        "name": "BigQuery RAG OpenAI",
        "type": "@n8n/n8n-nodes-langchain.toolWorkflow",
        "position": [
          -512,
          384
        ],
        "parameters": {
          "workflowId": {
            "__rl": true,
            "mode": "list",
            "value": "7tqwzCyxnnu8Svq3",
            "cachedResultName": "BigQuery RAG With OpenAI Embedding"
          },
          "description": "Call this tool to get documents from the vector databas",
          "workflowInputs": {
            "value": {
              "vector_search_question": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('vector_search_question', `A natural language question used to query the vector database containing the documentation.\n`, 'string') }}"
            },
            "schema": [
              {
                "id": "vector_search_question",
                "type": "string",
                "display": true,
                "required": false,
                "displayName": "vector_search_question",
                "defaultMatch": false,
                "canBeUsedToMatch": true
              }
            ],
            "mappingMode": "defineBelow",
            "matchingColumns": [
              "vector_search_question"
            ],
            "attemptToConvertTypes": false,
            "convertFieldsToString": false
          }
        },
        "typeVersion": 2.2
      },
      {
        "id": "dde0a97a-4495-42c2-837d-f5596f2bfbfe",
        "name": "Sticky Note",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -1536,
          -128
        ],
        "parameters": {
          "color": 3,
          "width": 384,
          "height": 432,
          "content": "## When Chat Message Received\n\nWhen a chat message is received, it triggers the workflow.  \nThe message is then forwarded to the **AI Agent**.\n"
        },
        "typeVersion": 1
      },
      {
        "id": "62bfaf5a-5b7f-430d-9bf6-c1d745e6a2c3",
        "name": "Sticky Note1",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -1120,
          -128
        ],
        "parameters": {
          "color": 7,
          "width": 544,
          "height": 432,
          "content": "## AI Agent\n\nThe AI Agent receives the user input.  \nIt is configured with a system prompt that instructs it to use the connected tool (**BigQuery RAG OpenAI**) to query the vector database.  \nUsing the retrieved documents, it then generates an answer and formats the response in **Markdown**.\n"
        },
        "typeVersion": 1
      },
      {
        "id": "dc49cd0c-3b52-475c-a423-7d8fd3914b4c",
        "name": "Sticky Note2",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -1248,
          368
        ],
        "parameters": {
          "color": 7,
          "width": 288,
          "height": 480,
          "content": "\n\n\n\n\n\n\n\n\n\n\n\n## OpenAI Chat Model\n\nThe default model is **gpt-4.1-mini**, chosen for its cost efficiency.\n"
        },
        "typeVersion": 1
      },
      {
        "id": "5a6c7c06-2021-4ad3-9e16-482e230b298d",
        "name": "Sticky Note3",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -928,
          368
        ],
        "parameters": {
          "color": 7,
          "width": 288,
          "height": 480,
          "content": "\n\n\n\n\n\n\n\n\n\n\n\n\n## Simple Memory\n\nProvides the AI Agent with context from the ongoing conversation.  \n\nFor production use, this node can be replaced with a more robust option, such as [Postgres Chat Memory](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorypostgreschat/).\n"
        },
        "typeVersion": 1
      },
      {
        "id": "7257c13a-e3f1-4602-807a-2ade1b14bcfc",
        "name": "Sticky Note4",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -608,
          368
        ],
        "parameters": {
          "color": 7,
          "width": 288,
          "height": 480,
          "content": "\n\n\n\n\n\n\n\n\n\n\n\n\n## BigQuery RAG OpenAI\n\nThis tool, used by the AI Agent, triggers a subworkflow that retrieves documents from the BigQuery vector store.  \n\nIt takes **`vector_search_question`** as input — the natural language question formulated by the AI Agent.  \nThis input is queried against the BigQuery vector store to fetch relevant documents, which are then used to generate the final answer.\n"
        },
        "typeVersion": 1
      },
      {
        "id": "3d718a18-8cb5-4a8b-b968-fb58502852bb",
        "name": "Sticky Note5",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -1568,
          912
        ],
        "parameters": {
          "color": 3,
          "width": 288,
          "height": 512,
          "content": "## When Executed by Another Workflow\n\nThis subworkflow is triggered when the AI Agent calls the **BigQuery RAG OpenAI** tool.  \nIt takes **`vector_search_question`** as input — the natural language query sent to the vector database to retrieve documents and answer the user’s question.\n"
        },
        "typeVersion": 1
      },
      {
        "id": "a61ba929-9efc-404e-8457-39c273aeaeb6",
        "name": "Sticky Note6",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -1248,
          912
        ],
        "parameters": {
          "color": 7,
          "width": 288,
          "height": 512,
          "content": "## Set Field – Question\n\nThis node assigns the value of **`vector_search_question`** to the field **`question`**.  \n\nIt is not strictly necessary in this version of the workflow, but it can be extended to set additional fields in future versions.\n"
        },
        "typeVersion": 1
      },
      {
        "id": "14298572-7b25-4d0a-8360-8f36c5d3ee0e",
        "name": "Set field - question",
        "type": "n8n-nodes-base.set",
        "position": [
          -1152,
          1264
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "5635b058-5ab3-49fc-be4c-51bfc07630c7",
                "name": "question",
                "type": "string",
                "value": "={{ $json.vector_search_question }}"
              }
            ]
          }
        },
        "typeVersion": 3.4
      },
      {
        "id": "7166cd84-5c7b-4e10-aa40-d919c9f6387d",
        "name": "OpenAI - Create Embedding",
        "type": "n8n-nodes-base.httpRequest",
        "position": [
          -832,
          1264
        ],
        "parameters": {
          "url": "https://api.openai.com/v1/embeddings",
          "method": "POST",
          "options": {},
          "sendBody": true,
          "authentication": "predefinedCredentialType",
          "bodyParameters": {
            "parameters": [
              {
                "name": "input",
                "value": "={{ $json.question }}"
              },
              {
                "name": "model",
                "value": "text-embedding-3-large"
              }
            ]
          },
          "nodeCredentialType": "openAiApi"
        },
        "credentials": {
          "openAiApi": {
            "id": "",
            "name": "OpenAi Account"
          }
        },
        "typeVersion": 4.2
      },
      {
        "id": "00247057-0cc0-4216-b299-115d9637c8b7",
        "name": "Sticky Note7",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -928,
          912
        ],
        "parameters": {
          "color": 7,
          "width": 288,
          "height": 512,
          "content": "## OpenAI – Create Embedding\n\nThis node calls the OpenAI API to generate an **embedding**, which is a vector representation of the input question.  \nThe embedding is then used to query the BigQuery vector store and retrieve relevant documents.  \n\nIn this template, the embedding model used is **`text-embedding-3-large`**."
        },
        "typeVersion": 1
      },
      {
        "id": "c6517110-de28-475c-82eb-d109ed99501c",
        "name": "Sticky Note8",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -608,
          912
        ],
        "parameters": {
          "color": 7,
          "width": 288,
          "height": 512,
          "content": "## Set Field – Embedding\n\nThis node assigns the **`embedding`** field using the data returned by the previous API call (**OpenAI – Create Embedding**).  \nThe embedding is then passed to the next API call (**BigQuery**) to perform the vector search."
        },
        "typeVersion": 1
      },
      {
        "id": "79a780d1-8646-4927-93be-54168d920f85",
        "name": "BigQuery - Vector Retriever - n8n docs",
        "type": "n8n-nodes-base.httpRequest",
        "position": [
          0,
          1264
        ],
        "parameters": {
          "url": "https://bigquery.googleapis.com/bigquery/v2/projects/<YOUR-PROJECT-ID>/queries",
          "method": "POST",
          "options": {},
          "sendBody": true,
          "authentication": "predefinedCredentialType",
          "bodyParameters": {
            "parameters": [
              {
                "name": "query",
                "value": "=WITH query AS (\n  SELECT ARRAY(\n    SELECT CAST(x AS FLOAT64)\n    FROM UNNEST([{{ $json.embedding.join(',') }}]) AS x\n  ) AS embedding\n)\nSELECT\n  t.base.text,\n  t.base.metadata,\n  t.distance   AS cosine_distance\nFROM VECTOR_SEARCH(\n  TABLE `n8n-docs-rag.n8n_docs.n8n_docs_embeddings`,\n  'embedding',\n  TABLE query,\n  top_k => 10,\n  distance_type => 'COSINE',\n  options => '{\"use_brute_force\": true}'\n) AS t\nORDER BY t.distance;"
              },
              {
                "name": "useLegacySql",
                "value": "false"
              }
            ]
          },
          "nodeCredentialType": "googleBigQueryOAuth2Api"
        },
        "credentials": {
          "googleBigQueryOAuth2Api": {
            "id": "",
            "name": "Google BigQuery account"
          }
        },
        "typeVersion": 4.2
      },
      {
        "id": "32f2544c-8e36-41a3-97c4-f6264d418be6",
        "name": "Sticky Note9",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -288,
          912
        ],
        "parameters": {
          "color": 7,
          "width": 736,
          "height": 512,
          "content": "## BigQuery – Vector Retriever – n8n docs\n\nThis node queries the BigQuery vector table that contains part of the n8n documentation:  \n`n8n-docs-rag.n8n_docs.n8n_docs_embeddings`.\n\nIn the **URL field**, replace **`<YOUR-PROJECT-ID>`** with your own project ID.  \n\nThis is a small table (~40 MB), but keep in mind that BigQuery uses the *requester pays* model.  \nWhen you test the workflow, the query cost is billed to your project.  \nRunning 3–4 queries should be inexpensive, as BigQuery provides **1 TB of free processing per month**, unless the project has already consumed its free quota.  \nMore info here: [BigQuery Pricing](https://cloud.google.com/bigquery/pricing?hl=en)\n"
        },
        "typeVersion": 1
      },
      {
        "id": "bb368d56-96a4-4bf0-b3bc-703354258d1d",
        "name": "Documents retrieved",
        "type": "n8n-nodes-base.set",
        "position": [
          576,
          1264
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "3a887578-7e34-4406-b44a-17695e5b5ab4",
                "name": "documents",
                "type": "string",
                "value": "={{ $json.rows.toJsonString() }}"
              }
            ]
          }
        },
        "typeVersion": 3.4
      },
      {
        "id": "1523c1b9-e81e-4c11-87dc-f67a687965e5",
        "name": "Sticky Note10",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          480,
          912
        ],
        "parameters": {
          "color": 7,
          "width": 288,
          "height": 512,
          "content": "## Documents Retrieved\n\nThis node stores the **documents retrieved from BigQuery** (10 by default).  \nThe results are then passed to the **AI Agent** to generate the final answer.  \n\nThe number of documents retrieved can be adjusted by changing the value of **`top_k`** in the SQL query.\n"
        },
        "typeVersion": 1
      },
      {
        "id": "3f7c43ba-b4f1-4284-a896-c320769b9a2a",
        "name": "Sticky Note11",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -288,
          1440
        ],
        "parameters": {
          "color": 5,
          "width": 736,
          "height": 752,
          "content": "## BigQuery – Vector Retriever – n8n docs  \n*Technical details*\n\nThis node runs a SQL query on the BigQuery vector database that stores part of the n8n documentation (nodes and triggers).  \nReplace the sample table with the one you created for your own use case.\n\n```sql\nWITH query AS (\n  SELECT ARRAY(\n    SELECT CAST(x AS FLOAT64)\n    FROM UNNEST([{{ $json.embedding.join(',') }}]) AS x\n  ) AS embedding\n)\nSELECT\n  t.base.text,\n  t.base.metadata,\n  t.distance AS cosine_distance\nFROM VECTOR_SEARCH(\n  TABLE `n8n-docs-rag.n8n_docs.n8n_docs_embeddings`,\n  'embedding',\n  TABLE query,\n  top_k => 10,\n  distance_type => 'COSINE',\n  options => '{\"use_brute_force\": true}'\n) AS t\nORDER BY t.distance;\n```\n* Since this table is small (fewer than ~5,000 rows and under ~10 MB), BigQuery does not use a vector index and automatically falls back to brute‐force search.  \nIncluding `options => '{\"use_brute_force\": true}'` explicitly enforces this mode, although BigQuery would default to it in this scenario.\n\n* The field **`distance`** represents the cosine similarity score — lower values mean the document is more relevant to the query.\n\n* `top_k => 10` retrieves the 10 documents most relevant to the user’s question. These documents are then passed to the AI Agent to generate the final answer."
        },
        "typeVersion": 1
      },
      {
        "id": "5da46a82-d97a-4c8b-8f3a-51286c677a1a",
        "name": "Sticky Note12",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -2928,
          -128
        ],
        "parameters": {
          "color": 7,
          "width": 1344,
          "height": 1200,
          "content": "# BigQuery RAG with OpenAI Embeddings\n\nThis workflow demonstrates how to use **Retrieval-Augmented Generation (RAG)** with **BigQuery** and **OpenAI**.  \nBy default, you cannot directly use OpenAI Cloud Models within BigQuery.\n\n## Why this workflow?\n\nMany organizations already use BigQuery to store enterprise data, and OpenAI for LLM use cases.  \nWhen it comes to RAG, the common approach is to rely on dedicated vector databases such as **Qdrant**, **Pinecone**, **Weaviate**, or PostgreSQL with **pgvector**.  \nThose are good choices, but in cases where an organization already uses and is familiar with BigQuery, it can be more efficient to leverage its built-in vector capabilities for RAG.\n\nThen comes the question of the LLM. If OpenAI is the chosen provider, teams are often frustrated that it is not directly compatible with BigQuery.  \nThis workflow solves that limitation.\n\n## Prerequisites\n\nTo use this workflow, you will need:\n* A good understanding of BigQuery and its vector capabilities  \n* A BigQuery table containing documents and an embeddings column  \n  * The embeddings column must be of type **FLOAT** and mode **REPEATED** (to store arrays)  \n* A data pipeline that **generates embeddings with the OpenAI API** and stores them in BigQuery\n\nThis template comes with a public table that stores part of the **n8n documentation** (about nodes and triggers), so you can try it out:  \n`n8n-docs-rag.n8n_docs.n8n_docs_embeddings`\n\n## How it works\n\nThe system consists of two workflows:\n* **Main workflow** → Hosts the AI Agent, which connects to a subworkflow for RAG  \n* **Subworkflow** → Queries the BigQuery vector table. The retrieved documents are then used by the AI Agent to generate an answer for the user.\n\n## Try it\n\nYou can test this workflow using the public table [`n8n-docs-rag.n8n_docs.n8n_docs_embeddings`](https://console.cloud.google.com/bigquery?ws=!1m5!1m4!4m3!1sn8n-docs-rag!2sn8n_docs!3sn8n_docs_embeddings).  \n\n⚠️ **Important:** BigQuery uses the *requester pays* model. This table is small (~40 MB), and BigQuery includes 1 TB of free processing each month. Running 3–4 queries for testing should not incur any noticeable cost.\n"
        },
        "typeVersion": 1
      },
      {
        "id": "92d2b05f-e8a3-4c64-ab65-4c64a2bc0297",
        "name": "Set Field - Embedding",
        "type": "n8n-nodes-base.set",
        "position": [
          -512,
          1264
        ],
        "parameters": {
          "options": {},
          "assignments": {
            "assignments": [
              {
                "id": "8abb7285-f4e4-46d7-a660-cd75104d8bbd",
                "name": "embedding",
                "type": "array",
                "value": "={{ $json.data[0].embedding }}"
              }
            ]
          }
        },
        "typeVersion": 3.4
      }
    ],
    "active": false,
    "pinData": {
      "When Executed by Another Workflow": [
        {
          "json": {
            "vector_search_question": "How does the n8n Webhook Trigger work?"
          }
        }
      ]
    },
    "settings": {
      "executionOrder": "v1"
    },
    "versionId": "",
    "connections": {
      "Simple Memory": {
        "ai_memory": [
          [
            {
              "node": "AI Agent",
              "type": "ai_memory",
              "index": 0
            }
          ]
        ]
      },
      "OpenAI Chat Model": {
        "ai_languageModel": [
          [
            {
              "node": "AI Agent",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "BigQuery RAG OpenAI": {
        "ai_tool": [
          [
            {
              "node": "AI Agent",
              "type": "ai_tool",
              "index": 0
            }
          ]
        ]
      },
      "Set field - question": {
        "main": [
          [
            {
              "node": "OpenAI - Create Embedding",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Set Field - Embedding": {
        "main": [
          [
            {
              "node": "BigQuery - Vector Retriever - n8n docs",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "OpenAI - Create Embedding": {
        "main": [
          [
            {
              "node": "Set Field - Embedding",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "When chat message received": {
        "main": [
          [
            {
              "node": "AI Agent",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "When Executed by Another Workflow": {
        "main": [
          [
            {
              "node": "Set field - question",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "BigQuery - Vector Retriever - n8n docs": {
        "main": [
          [
            {
              "node": "Documents retrieved",
              "type": "main",
              "index": 0
            }
          ]
        ]
      }
    }
  },
  "lastUpdatedBy": 29,
  "workflowInfo": {
    "nodeCount": 24,
    "nodeTypes": {
      "n8n-nodes-base.set": {
        "count": 3
      },
      "n8n-nodes-base.stickyNote": {
        "count": 13
      },
      "n8n-nodes-base.httpRequest": {
        "count": 2
      },
      "@n8n/n8n-nodes-langchain.agent": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.chatTrigger": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.toolWorkflow": {
        "count": 1
      },
      "n8n-nodes-base.executeWorkflowTrigger": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.memoryBufferWindow": {
        "count": 1
      }
    }
  },
  "user": {
    "name": "Dataki",
    "username": "dataki",
    "bio": "I am passionate about transforming complex processes into seamless automations with n8n. My expertise spans across creating ETL pipelines, sales automations, and data & AI-driven workflows. As an avid problem solver, I thrive on optimizing workflows to drive efficiency and innovation.",
    "verified": true,
    "links": [
      "https://www.linkedin.com/in/nicolas-aknin/"
    ],
    "avatar": "https://gravatar.com/avatar/0437c659b1ec6916896ebb30cc237391f0e1de89df5465c103e12d2cb12ce42d?r=pg&d=retro&size=200"
  },
  "nodes": [
    {
      "id": 19,
      "icon": "file:httprequest.svg",
      "name": "n8n-nodes-base.httpRequest",
      "codex": {
        "data": {
          "alias": [
            "API",
            "Request",
            "URL",
            "Build",
            "cURL"
          ],
          "resources": {
            "generic": [
              {
                "url": "https://n8n.io/blog/2021-the-year-to-automate-the-new-you-with-n8n/",
                "icon": "☀️",
                "label": "2021: The Year to Automate the New You with n8n"
              },
              {
                "url": "https://n8n.io/blog/why-business-process-automation-with-n8n-can-change-your-daily-life/",
                "icon": "🧬",
                "label": "Why business process automation with n8n can change your daily life"
              },
              {
                "url": "https://n8n.io/blog/automatically-pulling-and-visualizing-data-with-n8n/",
                "icon": "📈",
                "label": "Automatically pulling and visualizing data with n8n"
              },
              {
                "url": "https://n8n.io/blog/learn-how-to-automatically-cross-post-your-content-with-n8n/",
                "icon": "✍️",
                "label": "Learn how to automatically cross-post your content with n8n"
              },
              {
                "url": "https://n8n.io/blog/automatically-adding-expense-receipts-to-google-sheets-with-telegram-mindee-twilio-and-n8n/",
                "icon": "🧾",
                "label": "Automatically Adding Expense Receipts to Google Sheets with Telegram, Mindee, Twilio, and n8n"
              },
              {
                "url": "https://n8n.io/blog/running-n8n-on-ships-an-interview-with-maranics/",
                "icon": "🛳",
                "label": "Running n8n on ships: An interview with Maranics"
              },
              {
                "url": "https://n8n.io/blog/what-are-apis-how-to-use-them-with-no-code/",
                "icon": " 🪢",
                "label": "What are APIs and how to use them with no code"
              },
              {
                "url": "https://n8n.io/blog/5-tasks-you-can-automate-with-notion-api/",
                "icon": "⚡️",
                "label": "5 tasks you can automate with the new Notion API "
              },
              {
                "url": "https://n8n.io/blog/world-poetry-day-workflow/",
                "icon": "📜",
                "label": "Celebrating World Poetry Day with a daily poem in Telegram"
              },
              {
                "url": "https://n8n.io/blog/automate-google-apps-for-productivity/",
                "icon": "💡",
                "label": "15 Google apps you can combine and automate to increase productivity"
              },
              {
                "url": "https://n8n.io/blog/automate-designs-with-bannerbear-and-n8n/",
                "icon": "🎨",
                "label": "Automate Designs with Bannerbear and n8n"
              },
              {
                "url": "https://n8n.io/blog/how-uproc-scraped-a-multi-page-website-with-a-low-code-workflow/",
                "icon": " 🕸️",
                "label": "How uProc scraped a multi-page website with a low-code workflow"
              },
              {
                "url": "https://n8n.io/blog/building-an-expense-tracking-app-in-10-minutes/",
                "icon": "📱",
                "label": "Building an expense tracking app in 10 minutes"
              },
              {
                "url": "https://n8n.io/blog/5-workflow-automations-for-mattermost-that-we-love-at-n8n/",
                "icon": "🤖",
                "label": "5 workflow automations for Mattermost that we love at n8n"
              },
              {
                "url": "https://n8n.io/blog/how-to-use-the-http-request-node-the-swiss-army-knife-for-workflow-automation/",
                "icon": "🧰",
                "label": "How to use the HTTP Request Node - The Swiss Army Knife for Workflow Automation"
              },
              {
                "url": "https://n8n.io/blog/learn-how-to-use-webhooks-with-mattermost-slash-commands/",
                "icon": "🦄",
                "label": "Learn how to use webhooks with Mattermost slash commands"
              },
              {
                "url": "https://n8n.io/blog/how-a-membership-development-manager-automates-his-work-and-investments/",
                "icon": "📈",
                "label": "How a Membership Development Manager automates his work and investments"
              },
              {
                "url": "https://n8n.io/blog/a-low-code-bitcoin-ticker-built-with-questdb-and-n8n-io/",
                "icon": "📈",
                "label": "A low-code bitcoin ticker built with QuestDB and n8n.io"
              },
              {
                "url": "https://n8n.io/blog/how-to-set-up-a-ci-cd-pipeline-with-no-code/",
                "icon": "🎡",
                "label": "How to set up a no-code CI/CD pipeline with GitHub and TravisCI"
              },
              {
                "url": "https://n8n.io/blog/automations-for-activists/",
                "icon": "✨",
                "label": "How Common Knowledge use workflow automation for activism"
              },
              {
                "url": "https://n8n.io/blog/creating-scheduled-text-affirmations-with-n8n/",
                "icon": "🤟",
                "label": "Creating scheduled text affirmations with n8n"
              },
              {
                "url": "https://n8n.io/blog/how-goomer-automated-their-operations-with-over-200-n8n-workflows/",
                "icon": "🛵",
                "label": "How Goomer automated their operations with over 200 n8n workflows"
              },
              {
                "url": "https://n8n.io/blog/aws-workflow-automation/",
                "label": "7 no-code workflow automations for Amazon Web Services"
              }
            ],
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/"
              }
            ]
          },
          "categories": [
            "Development",
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"output\"]",
      "defaults": {
        "name": "Demande HTTP",
        "color": "#0004F5"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNDAiIGhlaWdodD0iNDAiIHZpZXdCb3g9IjAgMCA0MCA0MCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00MCAyMEM0MCA4Ljk1MzE0IDMxLjA0NjkgMCAyMCAwQzguOTUzMTQgMCAwIDguOTUzMTQgMCAyMEMwIDMxLjA0NjkgOC45NTMxNCA0MCAyMCA0MEMzMS4wNDY5IDQwIDQwIDMxLjA0NjkgNDAgMjBaTTIwIDM2Ljk0NThDMTguODg1MiAzNi45NDU4IDE3LjEzNzggMzUuOTY3IDE1LjQ5OTggMzIuNjk4NUMxNC43OTY0IDMxLjI5MTggMTQuMTk2MSAyOS41NDMxIDEzLjc1MjYgMjcuNjg0N0gyNi4xODk4QzI1LjgwNDUgMjkuNTQwMyAyNS4yMDQ0IDMxLjI5MDEgMjQuNTAwMiAzMi42OTg1QzIyLjg2MjIgMzUuOTY3IDIxLjExNDggMzYuOTQ1OCAyMCAzNi45NDU4Wk0xMi45MDY0IDIwQzEyLjkwNjQgMjEuNjA5NyAxMy4wMDg3IDIzLjE2NCAxMy4yMDAzIDI0LjYzMDVIMjYuNzk5N0MyNi45OTEzIDIzLjE2NCAyNy4wOTM2IDIxLjYwOTcgMjcuMDkzNiAyMEMyNy4wOTM2IDE4LjM5MDMgMjYuOTkxMyAxNi44MzYgMjYuNzk5NyAxNS4zNjk1SDEzLjIwMDNDMTMuMDA4NyAxNi44MzYgMTIuOTA2NCAxOC4zOTAzIDEyLjkwNjQgMjBaTTIwIDMuMDU0MTlDMjEuMTE0OSAzLjA1NDE5IDIyLjg2MjIgNC4wMzA3OCAyNC41MDAxIDcuMzAwMzlDMjUuMjA2NiA4LjcxNDA4IDI1LjgwNzIgMTAuNDA2NyAyNi4xOTIgMTIuMzE1M0gxMy43NTAxQzE0LjE5MzMgMTAuNDA0NyAxNC43OTQyIDguNzEyNTQgMTUuNDk5OCA3LjMwMDY0QzE3LjEzNzcgNC4wMzA4MyAxOC44ODUxIDMuMDU0MTkgMjAgMy4wNTQxOVpNMzAuMTQ3OCAyMEMzMC4xNDc4IDE4LjQwOTkgMzAuMDU0MyAxNi44NjE3IDI5LjgyMjcgMTUuMzY5NUgzNi4zMDQyQzM2LjcyNTIgMTYuODQyIDM2Ljk0NTggMTguMzk2NCAzNi45NDU4IDIwQzM2Ljk0NTggMjEuNjAzNiAzNi43MjUyIDIzLjE1OCAzNi4zMDQyIDI0LjYzMDVIMjkuODIyN0MzMC4wNTQzIDIzLjEzODMgMzAuMTQ3OCAyMS41OTAxIDMwLjE0NzggMjBaTTI2LjI3NjcgNC4yNTUxMkMyNy42MzY1IDYuMzYwMTkgMjguNzExIDkuMTMyIDI5LjM3NzQgMTIuMzE1M0gzNS4xMDQ2QzMzLjI1MTEgOC42NjggMzAuMTA3IDUuNzgzNDYgMjYuMjc2NyA0LjI1NTEyWk0xMC42MjI2IDEyLjMxNTNINC44OTI5M0M2Ljc1MTQ3IDguNjY3ODQgOS44OTM1MSA1Ljc4MzQxIDEzLjcyMzIgNC4yNTUxM0MxMi4zNjM1IDYuMzYwMjEgMTEuMjg5IDkuMTMyMDEgMTAuNjIyNiAxMi4zMTUzWk0zLjA1NDE5IDIwQzMuMDU0MTkgMjEuNjAzIDMuMjc3NDMgMjMuMTU3NSAzLjY5NDg0IDI0LjYzMDVIMTAuMTIxN0M5Ljk0NjE5IDIzLjE0MiA5Ljg1MjIyIDIxLjU5NDMgOS44NTIyMiAyMEM5Ljg1MjIyIDE4LjQwNTcgOS45NDYxOSAxNi44NTggMTAuMTIxNyAxNS4zNjk1SDMuNjk0ODRDMy4yNzc0MyAxNi44NDI1IDMuMDU0MTkgMTguMzk3IDMuMDU0MTkgMjBaTTI2LjI3NjYgMzUuNzQyN0MyNy42MzY1IDMzLjYzOTMgMjguNzExIDMwLjg2OCAyOS4zNzc0IDI3LjY4NDdIMzUuMTA0NkMzMy4yNTEgMzEuMzMyMiAzMC4xMDY4IDM0LjIxNzkgMjYuMjc2NiAzNS43NDI3Wk0xMy43MjM0IDM1Ljc0MjdDOS44OTM2OSAzNC4yMTc5IDYuNzUxNTUgMzEuMzMyNCA0Ljg5MjkzIDI3LjY4NDdIMTAuNjIyNkMxMS4yODkgMzAuODY4IDEyLjM2MzUgMzMuNjM5MyAxMy43MjM0IDM1Ljc0MjdaIiBmaWxsPSIjM0E0MkU5Ii8+Cjwvc3ZnPgo="
      },
      "displayName": "HTTP Request",
      "typeVersion": 4,
      "nodeCategories": [
        {
          "id": 5,
          "name": "Development"
        },
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 38,
      "icon": "fa:pen",
      "name": "n8n-nodes-base.set",
      "codex": {
        "data": {
          "alias": [
            "Set",
            "JS",
            "JSON",
            "Filter",
            "Transform",
            "Map"
          ],
          "resources": {
            "generic": [
              {
                "url": "https://n8n.io/blog/learn-to-automate-your-factorys-incident-reporting-a-step-by-step-guide/",
                "icon": "🏭",
                "label": "Learn to Automate Your Factory's Incident Reporting: A Step by Step Guide"
              },
              {
                "url": "https://n8n.io/blog/2021-the-year-to-automate-the-new-you-with-n8n/",
                "icon": "☀️",
                "label": "2021: The Year to Automate the New You with n8n"
              },
              {
                "url": "https://n8n.io/blog/automatically-pulling-and-visualizing-data-with-n8n/",
                "icon": "📈",
                "label": "Automatically pulling and visualizing data with n8n"
              },
              {
                "url": "https://n8n.io/blog/database-monitoring-and-alerting-with-n8n/",
                "icon": "📡",
                "label": "Database Monitoring and Alerting with n8n"
              },
              {
                "url": "https://n8n.io/blog/automatically-adding-expense-receipts-to-google-sheets-with-telegram-mindee-twilio-and-n8n/",
                "icon": "🧾",
                "label": "Automatically Adding Expense Receipts to Google Sheets with Telegram, Mindee, Twilio, and n8n"
              },
              {
                "url": "https://n8n.io/blog/no-code-ecommerce-workflow-automations/",
                "icon": "store",
                "label": "6 e-commerce workflows to power up your Shopify s"
              },
              {
                "url": "https://n8n.io/blog/how-to-build-a-low-code-self-hosted-url-shortener/",
                "icon": "🔗",
                "label": "How to build a low-code, self-hosted URL shortener in 3 steps"
              },
              {
                "url": "https://n8n.io/blog/automate-your-data-processing-pipeline-in-9-steps-with-n8n/",
                "icon": "⚙️",
                "label": "Automate your data processing pipeline in 9 steps"
              },
              {
                "url": "https://n8n.io/blog/how-to-get-started-with-crm-automation-and-no-code-workflow-ideas/",
                "icon": "👥",
                "label": "How to get started with CRM automation (with 3 no-code workflow ideas"
              },
              {
                "url": "https://n8n.io/blog/5-tasks-you-can-automate-with-notion-api/",
                "icon": "⚡️",
                "label": "5 tasks you can automate with the new Notion API "
              },
              {
                "url": "https://n8n.io/blog/automate-google-apps-for-productivity/",
                "icon": "💡",
                "label": "15 Google apps you can combine and automate to increase productivity"
              },
              {
                "url": "https://n8n.io/blog/how-uproc-scraped-a-multi-page-website-with-a-low-code-workflow/",
                "icon": " 🕸️",
                "label": "How uProc scraped a multi-page website with a low-code workflow"
              },
              {
                "url": "https://n8n.io/blog/building-an-expense-tracking-app-in-10-minutes/",
                "icon": "📱",
                "label": "Building an expense tracking app in 10 minutes"
              },
              {
                "url": "https://n8n.io/blog/the-ultimate-guide-to-automate-your-video-collaboration-with-whereby-mattermost-and-n8n/",
                "icon": "📹",
                "label": "The ultimate guide to automate your video collaboration with Whereby, Mattermost, and n8n"
              },
              {
                "url": "https://n8n.io/blog/5-workflow-automations-for-mattermost-that-we-love-at-n8n/",
                "icon": "🤖",
                "label": "5 workflow automations for Mattermost that we love at n8n"
              },
              {
                "url": "https://n8n.io/blog/learn-to-build-powerful-api-endpoints-using-webhooks/",
                "icon": "🧰",
                "label": "Learn to Build Powerful API Endpoints Using Webhooks"
              },
              {
                "url": "https://n8n.io/blog/how-a-membership-development-manager-automates-his-work-and-investments/",
                "icon": "📈",
                "label": "How a Membership Development Manager automates his work and investments"
              },
              {
                "url": "https://n8n.io/blog/a-low-code-bitcoin-ticker-built-with-questdb-and-n8n-io/",
                "icon": "📈",
                "label": "A low-code bitcoin ticker built with QuestDB and n8n.io"
              },
              {
                "url": "https://n8n.io/blog/how-to-set-up-a-ci-cd-pipeline-with-no-code/",
                "icon": "🎡",
                "label": "How to set up a no-code CI/CD pipeline with GitHub and TravisCI"
              },
              {
                "url": "https://n8n.io/blog/benefits-of-automation-and-n8n-an-interview-with-hubspots-hugh-durkin/",
                "icon": "🎖",
                "label": "Benefits of automation and n8n: An interview with HubSpot's Hugh Durkin"
              },
              {
                "url": "https://n8n.io/blog/how-goomer-automated-their-operations-with-over-200-n8n-workflows/",
                "icon": "🛵",
                "label": "How Goomer automated their operations with over 200 n8n workflows"
              },
              {
                "url": "https://n8n.io/blog/aws-workflow-automation/",
                "label": "7 no-code workflow automations for Amazon Web Services"
              }
            ],
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.set/"
              }
            ]
          },
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Data Transformation"
            ]
          }
        }
      },
      "group": "[\"input\"]",
      "defaults": {
        "name": "Modifier les champs"
      },
      "iconData": {
        "icon": "pen",
        "type": "icon"
      },
      "displayName": "Edit Fields (Set)",
      "typeVersion": 3,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 565,
      "icon": "fa:sticky-note",
      "name": "n8n-nodes-base.stickyNote",
      "codex": {
        "data": {
          "alias": [
            "Comments",
            "Notes",
            "Sticky"
          ],
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"input\"]",
      "defaults": {
        "name": "Note autocollante",
        "color": "#FFD233"
      },
      "iconData": {
        "icon": "sticky-note",
        "type": "icon"
      },
      "displayName": "Sticky Note",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 837,
      "icon": "fa:sign-out-alt",
      "name": "n8n-nodes-base.executeWorkflowTrigger",
      "codex": {
        "data": {
          "resources": {
            "generic": [],
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executeworkflowtrigger/"
              }
            ]
          },
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"trigger\"]",
      "defaults": {
        "name": "Lorsqu'exécuté par un autre flux de travail",
        "color": "#ff6d5a"
      },
      "iconData": {
        "icon": "sign-out-alt",
        "type": "icon"
      },
      "displayName": "Execute Workflow Trigger",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Agent IA",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1153,
      "icon": "file:openAiLight.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Modèle de chat OpenAI"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "OpenAI Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1163,
      "icon": "fa:database",
      "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Memory"
            ],
            "Memory": [
              "For beginners"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Mémoire simple"
      },
      "iconData": {
        "icon": "database",
        "type": "icon"
      },
      "displayName": "Simple Memory",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1205,
      "icon": "fa:network-wired",
      "name": "@n8n/n8n-nodes-langchain.toolWorkflow",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.toolworkflow/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Tools"
            ],
            "Tools": [
              "Recommended Tools"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Appeler l'outil de flux de travail n8n"
      },
      "iconData": {
        "icon": "network-wired",
        "type": "icon"
      },
      "displayName": "Call n8n Workflow Tool",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1247,
      "icon": "fa:comments",
      "name": "@n8n/n8n-nodes-langchain.chatTrigger",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
              }
            ]
          },
          "categories": [
            "Core Nodes",
            "Langchain"
          ]
        }
      },
      "group": "[\"trigger\"]",
      "defaults": {
        "name": "Lorsqu'un message de chat est reçu"
      },
      "iconData": {
        "icon": "comments",
        "type": "icon"
      },
      "displayName": "Chat Trigger",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ],
  "categories": [
    {
      "id": 42,
      "name": "Wiki interne"
    },
    {
      "id": 48,
      "name": "IA RAG"
    }
  ],
  "image": []
}