{
  "id": 6816,
  "name": "Créer des modèles de raisonnement personnalisés pour les agents IA avec GraphRAG et l'ontologie des connaissances",
  "views": 253,
  "recentViews": 1,
  "totalViews": 253,
  "createdAt": "2025-08-01T16:29:18.234Z",
  "description": "## Apprenez à votre agent IA COMMENT penser, pas QUOI penser\n\n[![Tutoriel vidéo](https://img.youtube.com/vi/jhqBb3nuyAY/sddefault.jpg)](https://www.youtube.com/watch?v=jhqBb3nuyAY)\n\nCe flux de travail démontre comment vous pouvez construire un agent IA dans n8n qui utilise la logique de raisonnement que vous définissez. Ainsi, un LLM apprend une façon de penser, que vous pouvez ensuite appliquer à plusieurs problèmes : \n\n- Créez un **chatbot IA qui sait comment convaincre n'importe qui** en utilisant la méthode \"Getting to Yes\"\n- Construisez un **flux de travail LLM qui utilise les principes de Ray Dalio** pour repérer des opportunités d'investissement\n- Créez un équipage d'agents IA de **penseurs interdisciplinaires** : par exemple, un spécialiste en psychologie qui donne des conseils sur les programmes éducatifs.\n\n![Graphique de connaissances InfraNodus](https://infranodus.com/images/front/blog/reasoning-knowledge-graph-infranodus.png)\n\n\n## Comment ça fonctionne\nCe modèle utilise le nœud d'agent IA n8n comme un agent d'orchestration qui a accès à une certaine logique de raisonnement définie par un [graphique de connaissances InfraNodus](https://infranodus.com).\n\nCe graphique contient une liste de règles de raisonnement (ontologie), qui est extraite pour fournir un conseil pertinent par rapport à la demande originale. Il utilise GraphRAG en arrière-plan pour parcourir les parties du graphique pertinentes à la requête.\n\nCe conseil et la logique de raisonnement extraite sont ensuite utilisés par l'agent IA pour générer une réponse qui est pertinente par rapport à la requête de l'utilisateur mais qui utilise la logique de raisonnement fournie par le graphique.\n\nVoici une description étape par étape :\n\n- L'utilisateur soumet une question en utilisant le chatbot IA (interface n8n, dans ce cas, un formulaire web qui peut être intégré à n'importe quel site web, ou un webhook qui peut être connecté à un bot Telegram / WhatsApp)\n- Le nœud d'agent IA accède aux nœuds HTTP de logique de raisonnement InfraNodus. La description de l'agent IA et la description du nœud de raisonnement InfraNodus fournissent à l'agent une compréhension de la manière de reformuler la question originale pour récupérer la logique de raisonnement pertinente.\n- La demande est envoyée au nœud InfraNodus. Il fournit une réponse contenant la logique de raisonnement nécessaire pour répondre à la question.\n- Cette logique de raisonnement est ensuite renvoyée à un LLM avec la requête originale pour produire la réponse.\n\n\nInfraNodus utilise **[GraphRAG](https://infranodus.com/docs/graph-rag-knowledge-graph)** en arrière-plan : \n- convertir la requête utilisateur en graphique\n- trouver le chevauchement avec le graphique de raisonnement (en utilisant n=1 ou plusieurs sauts pour inclure plus de relations)\n- utiliser la recherche de similarité pour obtenir des parties supplémentaires du graphique\n- générer une réponse basée sur cette intersection ainsi que sur le contexte fourni\n- fournir des informations sur la structure sous-jacente\n\n## Comment utiliser\n\nVous avez besoin d'un [compte InfraNodus](https://infranodus.com/use-case/ai-knowledge-graphs) pour utiliser ce flux de travail. \n\n- Créez un compte InfraNodus\n- Obtenez la clé API sur [https://infranodus.com/api-access](https://infranodus.com/api-access) et créez une clé d'autorisation Bearer pour les nœuds HTTP InfraNodus.\n- Créez un graphique de connaissances séparé pour la logique de raisonnement\n- Utilisez le [créateur d'ontologie IA](https://infranodus.com/import/ai-ontologies) pour générer une ontologie pour un certain sujet ou texte en utilisant l'IA. Ensuite, complétez-la avec vos propres données. Consultez notre [article d'aide sur la création d'ontologies](https://support.noduslabs.com/hc/en-us/articles/18301655686172-Generate-Knowledge-Graphs-and-Ontologies-in-Plain-Text) pour des instructions détaillées\n- Pour chaque graphique, allez au flux de travail, collez le nom du graphique dans le champ `name` du JSON de la requête `body`.\n- Modifiez l'invite système dans le nœud d'agent IA pour refléter la nature de votre logique de raisonnement. Par exemple, si c'est un expert en interactions, vous le spécifiez, si c'est un expert en psychologie, vous devez également le spécifier.\n- Modifiez la description du nœud de raisonnement (outil HTTP). Utilisez les boutons `summary` et `Project Notes` &gt; `RAG prompt` d'InfraNodus pour générer une description de la logique de raisonnement, que vous pouvez ensuite réutiliser dans votre flux de travail.\n- Ajoutez la clé LLM au nœud OpenAI (ou au modèle de votre choix) et lancez le flux de travail\n\n## Exigences\n\n- Un compte et une clé API [InfraNodus](https://infranodus.com/use-case/ai-knowledge-graphs)\n- Une clé API OpenAI (ou tout autre LLM)\n\n\n## Personnalisation de ce flux de travail\n\nVous pouvez utiliser ce même flux de travail avec un bot Telegram, afin d'interagir avec lui en utilisant Telegram. Il existe de nombreuses autres personnalisations disponibles. \n\nConsultez le **guide complet** à [https://support.noduslabs.com/hc/en-us/articles/21429518472988-Using-Knowledge-Graphs-as-Reasoning-Experts](https://support.noduslabs.com/hc/en-us/articles/21429518472988-Using-Knowledge-Graphs-as-Reasoning-Experts)\n\nConsultez également le **tutoriel vidéo** avec une démonstration :\n\n[![Tutoriel vidéo](https://img.youtube.com/vi/jhqBb3nuyAY/sddefault.jpg)](https://www.youtube.com/watch?v=jhqBb3nuyAY)\n\n\n\n\n",
  "workflow": {
    "id": "a31fIa8ZmGBq07CK",
    "meta": {
      "instanceId": "2a26454b0172ffcb8d70ba77c235b1209f92cd71bf06c79ba609c7173b416d68",
      "templateCredsSetupCompleted": true
    },
    "name": "Reasoning Expert with Graph RAG Knowledge Ontology",
    "tags": [],
    "nodes": [
      {
        "id": "aa3aae5b-5652-4bd8-a1bf-986eb9765ab3",
        "name": "When chat message received",
        "type": "@n8n/n8n-nodes-langchain.chatTrigger",
        "position": [
          -480,
          -220
        ],
        "webhookId": "2dfe79eb-bbb0-49ed-83c9-cb3e2a49602f",
        "parameters": {
          "options": {}
        },
        "typeVersion": 1.1
      },
      {
        "id": "7c700795-faff-412e-aecb-4624439c1246",
        "name": "OpenAI Chat Model",
        "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
        "position": [
          -360,
          200
        ],
        "parameters": {
          "model": {
            "__rl": true,
            "mode": "list",
            "value": "gpt-4o-mini"
          },
          "options": {}
        },
        "credentials": {
          "openAiApi": {
            "id": "07wFa8Wa4mMRCHAj",
            "name": "OpenAi account 2"
          }
        },
        "typeVersion": 1.2
      },
      {
        "id": "4a09a841-6743-4d8f-8cbc-33b64b2d21bb",
        "name": "Simple Memory",
        "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
        "position": [
          -160,
          200
        ],
        "parameters": {},
        "typeVersion": 1.3
      },
      {
        "id": "c388dd69-24a6-422b-a08c-4a2046a75997",
        "name": "Interaction Dynamics Expert",
        "type": "n8n-nodes-base.httpRequestTool",
        "position": [
          200,
          200
        ],
        "parameters": {
          "url": "https://infranodus.com/api/v1/graphAndAdvice?doNotSave=true&addStats=true&optimize=develop&includeStatements=true&includeGraphSummary=true&includeGraph=false",
          "method": "POST",
          "options": {},
          "sendBody": true,
          "authentication": "genericCredentialType",
          "bodyParameters": {
            "parameters": [
              {
                "name": "name",
                "value": "eightos_system"
              },
              {
                "name": "requestMode",
                "value": "response"
              },
              {
                "name": "prompt",
                "value": "={{ /*n8n-auto-generated-fromAI-override*/ $fromAI('parameters2_Value', `User query to send to the expert`, 'string') }}"
              },
              {
                "name": "aiTopics",
                "value": "true"
              }
            ]
          },
          "genericAuthType": "httpBearerAuth",
          "toolDescription": "You are an expert in interaction dynamics who provides advice on the best way to interact with people and situations. You receive information about the dynamics of an interaction and then provide advice for what to do next based on these dynamics.\n\n<MainConcepts>: \n[[escalation]], [[adaptive_strategy]], [[metastability]], [[polysingularity]]\n</MainConcepts>\n\n\n<MainTopics>: \n1. Tension Dynamics: [[escalation]] [[engagement]] [[tension_release]] \n2. Synergistic Growth: [[synergy]] [[assimilation]] [[common_good]] \n3. Ethical Narratives: [[∞os_private_ethics]] [[narrative_activation_formula]] [[environment]] \n4. Chaotic Stability: [[metastability]] [[chaotic_itinerancy]] [[dynamic_stability]] \n5. Adaptive Fluidity: [[adaptive_strategy]] [[fluidity]] [[environmental_input]] \n6. Diverse Governance: [[polysingularity]] [[hedging_preset]] [[holocracy]] \n</MainTopics>\n\n<TopicalGap>: \n4. Chaotic Stability: [[metastability]] [[chaotic_itinerancy]] \n6. Diverse Governance: [[polysingularity]] [[hedging_preset]] \n</TopicalGap>\n\n<ConceptualGateways> \n[[common_good]] [[chaotic_itinerancy]] [[hedging_preset]] [[environmental_input]] [[synergy]] [[narrative_activation_formula]] [[∞os_private_ethics]] [[environment]] [[fluidity]] [[holocracy]] [[assimilation]] [[panarchy]] [[discipline_preset]] \n</ConceptualGateways>\n\n\n<Relations>: \n1) [[dissipation]] [[tension_release]]\n2) [[dissipation]] [[a_r_d_method]]\n3) [[common_good]] [[synergy]]\n4) [[oscillatory_progress]] [[pendulation]]\n5) [[assimilation]] [[energy_absorption]]\n6) [[feedback_escalation]] [[feedback_loop]]\n7) [[metastability]] [[chaotic_itinerancy]]\n8) [[polysingularity]] [[diversity]]\n9) [[oscillatory_pattern]] [[synchronization]]\n10) [[fluidity]] [[adaptive_strategy]]\n11) [[tension_increase]] [[tension_release]]\n12) [[escalation]] [[adaptive_strategy]]\n</Relations>\n\nSentiment (wink):\npositive: 15%, negative: 18%, neutral: 68%\n\n"
        },
        "credentials": {
          "httpBearerAuth": {
            "id": "zVdEF7tjCSMRkhDJ",
            "name": "InfraNodus Experts Account"
          }
        },
        "typeVersion": 4.2
      },
      {
        "id": "1bf99f65-00fb-49f3-b576-b21acc14e2ae",
        "name": "Reasoning Agent",
        "type": "@n8n/n8n-nodes-langchain.agent",
        "position": [
          -200,
          -60
        ],
        "parameters": {
          "options": {
            "systemMessage": "You are a reasoning agent. You have access to a dynamic interaction expert that provides you advice on how to continue your interaction. When you send a request to this expert, you need to give it an interpretation of the previous interaction and its dynamics (your interpretation of the conversation) using the language and concepts that the reasoning agent will understand. \n\nUse the response from the expert as an instruction to improve your response to the user's query. Give the utmost importance to the expert's advice to improve your standard response to the client's original query."
          }
        },
        "typeVersion": 1.9
      },
      {
        "id": "61106e92-7c6a-4e93-8afb-180f00123f2e",
        "name": "Sticky Note",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          -220,
          -240
        ],
        "parameters": {
          "width": 380,
          "height": 320,
          "content": "## 1. Reasoning Agent \n\nHere you add a system prompt that tell the agent to augment the original prompt using its knowledge about the reasoning ontology. "
        },
        "typeVersion": 1
      },
      {
        "id": "7b409287-758d-46e8-b828-69776ce5f56d",
        "name": "Sticky Note1",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          60,
          120
        ],
        "parameters": {
          "width": 340,
          "height": 560,
          "content": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 2. Reasoning Ontology\n\nHere you add an [InfraNodus](https://infranodus.com) knowledge graph that will contain the reasoning ontology you want to use. \n\n1. Specify it in the `name` field\n\n2. Add a description and topical summary (generated in `Project Notes` > `prompt augmentation for RAG` on the graph's page)"
        },
        "typeVersion": 1
      },
      {
        "id": "06e7c099-dd74-4f46-bb3b-b7639c3fc3ea",
        "name": "Sticky Note2",
        "type": "n8n-nodes-base.stickyNote",
        "position": [
          400,
          120
        ],
        "parameters": {
          "width": 420,
          "height": 560,
          "content": "\n\n\n\n\n\n\n\n\n\n### Knowledge Graph: Reasoning Ontology\n\nYou can auto-generate the reasoning ontology using the [https://infranodus.com/import/ai-ontologies](https://infranodus.com/import/ai-ontologies) interface and / or edit it manually using the [[wiki links]] for nodes and [tags] for relationship types. \n\n[![InfraNodus knowledge graph](https://infranodus.com/images/front/blog/reasoning-knowledge-graph-infranodus.png)](https://support.noduslabs.com/hc/en-us/articles/21429518472988-Using-Knowledge-Graphs-as-Reasoning-Experts)\n\n**[Learn more on the InfraNodus support portal](https://support.noduslabs.com/hc/en-us/articles/21429518472988-Using-Knowledge-Graphs-as-Reasoning-Experts)**\n"
        },
        "typeVersion": 1
      }
    ],
    "active": false,
    "pinData": {},
    "settings": {
      "executionOrder": "v1"
    },
    "versionId": "02353b90-13a1-4624-bc39-391a0dd4a1b0",
    "connections": {
      "Simple Memory": {
        "ai_memory": [
          [
            {
              "node": "Reasoning Agent",
              "type": "ai_memory",
              "index": 0
            }
          ]
        ]
      },
      "Reasoning Agent": {
        "main": [
          []
        ]
      },
      "OpenAI Chat Model": {
        "ai_languageModel": [
          [
            {
              "node": "Reasoning Agent",
              "type": "ai_languageModel",
              "index": 0
            }
          ]
        ]
      },
      "When chat message received": {
        "main": [
          [
            {
              "node": "Reasoning Agent",
              "type": "main",
              "index": 0
            }
          ]
        ]
      },
      "Interaction Dynamics Expert": {
        "ai_tool": [
          [
            {
              "node": "Reasoning Agent",
              "type": "ai_tool",
              "index": 0
            }
          ]
        ]
      }
    }
  },
  "lastUpdatedBy": 29,
  "workflowInfo": {
    "nodeCount": 8,
    "nodeTypes": {
      "n8n-nodes-base.stickyNote": {
        "count": 3
      },
      "@n8n/n8n-nodes-langchain.agent": {
        "count": 1
      },
      "n8n-nodes-base.httpRequestTool": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.chatTrigger": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.lmChatOpenAi": {
        "count": 1
      },
      "@n8n/n8n-nodes-langchain.memoryBufferWindow": {
        "count": 1
      }
    }
  },
  "user": {
    "name": "InfraNodus",
    "username": "infranodus",
    "bio": "I'm Dmitry, the founder of InfraNodus — an AI text network analysis tool. I'm passionate about networks and data visualization and its ability to reveal what everyone else is missing and to highlight different perspectives. I'm sharing the n8n templates that make use of this unique capability of InfraNodus for multiple scenarios.",
    "verified": true,
    "links": [
      "https://infranodus.com"
    ],
    "avatar": "https://gravatar.com/avatar/2c4026bed17ffbab6bc63bfd88f3a7375e83f7f2b1c92859a092f8bb3abbbc30?r=pg&d=retro&size=200"
  },
  "nodes": [
    {
      "id": 565,
      "icon": "fa:sticky-note",
      "name": "n8n-nodes-base.stickyNote",
      "codex": {
        "data": {
          "alias": [
            "Comments",
            "Notes",
            "Sticky"
          ],
          "categories": [
            "Core Nodes"
          ],
          "nodeVersion": "1.0",
          "codexVersion": "1.0",
          "subcategories": {
            "Core Nodes": [
              "Helpers"
            ]
          }
        }
      },
      "group": "[\"input\"]",
      "defaults": {
        "name": "Note autocollante",
        "color": "#FFD233"
      },
      "iconData": {
        "icon": "sticky-note",
        "type": "icon"
      },
      "displayName": "Sticky Note",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        }
      ]
    },
    {
      "id": 1119,
      "icon": "fa:robot",
      "name": "@n8n/n8n-nodes-langchain.agent",
      "codex": {
        "data": {
          "alias": [
            "LangChain",
            "Chat",
            "Conversational",
            "Plan and Execute",
            "ReAct",
            "Tools"
          ],
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Agents",
              "Root Nodes"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Agent IA",
        "color": "#404040"
      },
      "iconData": {
        "icon": "robot",
        "type": "icon"
      },
      "displayName": "AI Agent",
      "typeVersion": 2,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1153,
      "icon": "file:openAiLight.svg",
      "name": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Language Models",
              "Root Nodes"
            ],
            "Language Models": [
              "Chat Models (Recommended)"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Modèle de chat OpenAI"
      },
      "iconData": {
        "type": "file",
        "fileBuffer": "data:image/svg+xml;base64,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"
      },
      "displayName": "OpenAI Chat Model",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1163,
      "icon": "fa:database",
      "name": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/"
              }
            ]
          },
          "categories": [
            "AI",
            "Langchain"
          ],
          "subcategories": {
            "AI": [
              "Memory"
            ],
            "Memory": [
              "For beginners"
            ]
          }
        }
      },
      "group": "[\"transform\"]",
      "defaults": {
        "name": "Mémoire simple"
      },
      "iconData": {
        "icon": "database",
        "type": "icon"
      },
      "displayName": "Simple Memory",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 25,
          "name": "AI"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    },
    {
      "id": 1247,
      "icon": "fa:comments",
      "name": "@n8n/n8n-nodes-langchain.chatTrigger",
      "codex": {
        "data": {
          "resources": {
            "primaryDocumentation": [
              {
                "url": "https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-langchain.chattrigger/"
              }
            ]
          },
          "categories": [
            "Core Nodes",
            "Langchain"
          ]
        }
      },
      "group": "[\"trigger\"]",
      "defaults": {
        "name": "Lorsque le message de chat est reçu"
      },
      "iconData": {
        "icon": "comments",
        "type": "icon"
      },
      "displayName": "Chat Trigger",
      "typeVersion": 1,
      "nodeCategories": [
        {
          "id": 9,
          "name": "Core Nodes"
        },
        {
          "id": 26,
          "name": "Langchain"
        }
      ]
    }
  ],
  "categories": [
    {
      "id": 5,
      "name": "Ingénierie"
    },
    {
      "id": 48,
      "name": "IA RAG"
    }
  ],
  "image": []
}